\documentclass[a4paper, twoside, 11pt, openright]{article}
\usepackage[utf8]{inputenc}
\usepackage{polski}
\usepackage{float}
\usepackage[T1]{fontenc}

\usepackage{url}
\usepackage{longtable}
\usepackage{a4wide}
\raggedbottom
\usepackage{tabularx, booktabs}

\usepackage[left=3.0cm, right=2.0cm, top=2.5cm, bottom=2.5cm]{geometry}


% PERSONAL data about the thesis
\newcommand{\myTitle}{Metodyka porównania algorytmów prognozy do wspomagania decyzji giełdowych}
\newcommand{\myName}{Nikodem Wiśniewski}
\newcommand{\myNumber}{260907}
\newcommand{\myThesisType}{Praca dyplomowa magisterska}
\newcommand{\myCourse}{Informatyka}
\newcommand{\myProf}{dr hab. inż. Jerzy Balicki, profesor PW}
\newcommand{\myFaculty}{Wydział Matematyki i Nauk Informacyjnych}
\newcommand{\myUni}{Politechnika Warszawska}
\newcommand{\myLocation}{Warszawa}
\newcommand{\myYear}{2019}
\newcommand{\myKeywords}{}
\newcommand{\myKeywordsPL}{}



% DOCUMENT settings


\usepackage{graphicx}
\usepackage{multirow}
\usepackage{indentfirst}
\usepackage{wrapfig}
\usepackage[font=footnotesize, % equivalent to 9 pt font
			labelfont=bf, 
			justification=justified, 
			singlelinecheck=false]{caption} 
%\usepackage[justification=centering]{subcaption} % two images side by side captions
\usepackage{tabularx, booktabs} % pretty LaTeX tables
\usepackage{siunitx} % units SI e.g. \SI{10}{\kilogram\per\meter\square}
\usepackage{mathtools} % amsmath, symbols such as brackets, arrows, equation numbering only for referrenced eqs.
%\usepackage[parfill]{parskip} % spacing between paragraphs instead of indent
%\parfillskip 0pt plus 0.75\textwidth % get rid of widows at the end of paragraphs
\frenchspacing % for "Polish" spaces after the sentence
\usepackage{polski} % Polish rules of hyphenation
\usepackage{dashrule} % for dotted lines in declarations page
\usepackage{emptypage} % removes headers on empty pages
\usepackage{fancyhdr} % header and footer settings
\usepackage{subfigure}
\usepackage{cleveref}


\pagestyle{fancy}
\fancyhf{}
\newcommand{\fncyfront}{%
	\fancyhead[RO]{}
	\fancyfoot[RO]{}
	\fancyhead[LE]{}
	\fancyfoot[LE]{}
	\fancyhead[RE,LO]{}
	\fancyfoot[C]{}
	\renewcommand{\headrulewidth}{0pt}}
\newcommand{\fncymain}{%
	\fancyhead[RO]{{\footnotesize \rightmark}}
	\fancyfoot[RO]{\thepage}
	\fancyhead[LE]{{\footnotesize \leftmark}}
	\fancyfoot[LE]{\thepage}
	\fancyfoot[C]{}
	\renewcommand{\headrulewidth}{0.3pt}}
	
\renewcommand*{\tablename}{Tabela} 
	
\newcolumntype{P}[1]{>{\centering\arraybackslash}p{#1}}
\newcolumntype{M}[1]{>{\centering\arraybackslash}m{#1}}



% FONT settings
\usepackage[T1]{fontenc}

%\renewcommand{\familydefault}{\sfdefault} % change font to sans serif
\usepackage{amsfonts} % mathematical fonts
\usepackage{inconsolata} % monospaced font in urls and \texttt
%\usepackage{url}
%\urlstyle{same}

% DEBUG
\usepackage{lipsum}
\usepackage{etoolbox} % removes page number in table of contents
\patchcmd{\chapter}{plain}{empty}{}{}


\begin{document}
\fncyfront
%*******************************************************
% Titlepage
%*******************************************************
\begin{titlepage}
\begingroup
\begin{center}		
			\includegraphics[width=1.0\textwidth]{img/pw_header}
			
			\vspace{1.0cm}
			\fontsize{24}{30}\selectfont\myThesisType
			\fontsize{12}{14}\selectfont
			
			\vspace{0.5cm}
			na kierunku \myCourse \\
			\vspace{1cm}
			{\fontsize{14}{18}\selectfont \myTitle} \\ 
			
			\vspace{1.5cm}
			\fontsize{21}{25}\selectfont \myName \\
			\fontsize{12}{14}\selectfont
			Numer albumu \myNumber \\

			\vspace{6.5cm}
			promotor \\
			\myProf \\
			\vspace{0.5cm}
			\vfill 
			Warszawa, \myYear
        \vfill                      
\end{center}
\endgroup
\end{titlepage}

\cleardoublepage

\begingroup
\fontsize{12pt}{14.4pt}\selectfont


\begin{abstract}


Giełda jest miejscem przyciągającym rzesze inwestorów pragnących pomnożyć swój kapitał. Właściwy handel instrumentami finansowymi na giełdzie pozwala na osiąganie zysków przekraczających zyski z alternatywnych inwestycji takich jak na przykład nieruchomości. Wiąże się to oczywiście z pewnym ryzykiem. W niniejszej pracy opisano charakterystykę giełdy, dostępne dane giełdowe oraz różne podejścia do tematu przewidywania cen na giełdzie. Ponadto podjęto próbę stworzenia algorytmów do prognozowania za pomocą modeli z dziedziny uczenia maszynowego. Następnie, w celu dalszej oceny skuteczności, utworzone modele zostały wykorzystane w symulacji zautomatyzowanego handlu na giełdzie. 

\bigskip

	\noindent \textbf{Słowa kluczowe:} giełda, predykcja, klasyfikacja, sieci neuronowe, SVM, las losowy, Light GBM, uczenie maszynowe, wspomaganie decyzji giełdowych
\end{abstract}

\cleardoublepage


\hfill
\begin{table}[b]
\centering
\begin{tabular}[t]{ccc}
............................................. & \hspace*{100pt} & .............................................\\
podpis promotora & \hspace*{100pt} & podpis autora
\end{tabular}
\end{table}

\fncymain



\cleardoublepage

\tableofcontents

\cleardoublepage

\section{Wprowadzenie}

Giełda z definicji jest miejscem wymiany towarów przez sprzedawców i kupców. Giełdy można podzielić na giełdy towarowe, pieniężne lub usługowe. Wymiany na tradycyjnych giełdach przebiegają przede wszystkim podczas sesji, które są organizowane w określonych dniach i godzinach. Najpopularniejszym rodzajem giełd są giełdy pieniężne, a w szczególności giełdy papierów wartościowych. Największymi giełdami papierów wartościowych są \textit{NYSE (New York Stock Exchange)}\cite{nyse}, \textit{NASDAQ}\cite{nasdaq} oraz \textit{JPX (Japan Exchange Group)}\cite{jpx}. Na każdej z tych giełd w dniach, w których prowadzone są sesje, dochodzi do transakcji opiewających na łączną kwotę rzędu miliardów dolarów amerykańskich.

\bigskip

 Jednym z wymienianych na giełdzie towarów są akcje różnorodnych spółek. Każda spółka, która jest obecna na giełdzie ma przypisany do siebie symbol giełdowy (\textit{ticker}). Symbol giełdowy jest skrótowym kodem do identyfikowania spółek na określonej giełdzie (przykładowe symbole: \textit{GOOGL}, \textit{MSFT}, \textit{AMZN}). Podczas każdej sesji dokonywane są transakcje milionów akcji, których cena regulowana jest przez wolny rynek. Wynikiem tego jest duża zmienność cen i nieprzewidywalność akcji. Jest ona spowodowana między innymi: spekulacjami inwestorów, upublicznianiem informacji o konkretnej spółce (np. raportów finansowych) lub wydarzeniami na arenie politycznej (np. ustawy wpływające na działalność spólek z konkretnego sektora). Poprawne przewidywanie zmian cen giełdowych oznacza dla inwestora możliwość wypracowania zysków na kupnie i sprzedaży akcji.
 
\bigskip

%TODO dotychczasowe pejpery traktujące o temacie


\section{Modele prognozy na giełdzie oraz kryteria ich oceny}

Poniżej opisane zostały dane giełdowe pochodzące z wielu źródeł, zróżnicowane sposoby na predykcje cen na giełdzie oraz różnorodne kryteria oceny modeli predykcyjnych. 

\subsection{Dane giełdowe}

Istnieje wiele rodzajów danych, które są w większym lub mniejszym stopniu powiązane z giełdą papierów wartościowych. Zbiór informacji, które można wykorzystywać w przewidywaniu cen akcji jest bardzo szeroki, począwszy od cech bezpośrednio opisujących akcje na giełdzie, przez dane opisujące finansową sytuację spółek emitujących akcje, wskaźniki będące statystycznym odzwierciedleniem zmian cen na giełdzie, aż po dane alternatywne takie jak sentyment powiązany z wiadomościami na temat spółek oraz giełdy.

\subsubsection{Dane podstawowe}

Podstawowymi (dziennymi) danymi wynikającymi bezpośrednio z funkcjonowania giełdy są:

\begin{itemize}
\item{Data}
\item{Cena zamknięcia} - cena akcji pod koniec dnia
\item{Cena otwarcia} - cena akcji na początku dnia
\item{Liczba akcji w obrocie danego dnia}
\item{Najniższa cena akcji danego dnia}
\item{Najwyższa cena akcji danego dnia}
\end{itemize}

 Przy korzystaniu z wartości cen akcji należy również uwzględnić podział akcji(tak zwany \textit{split}). Gdy jakaś spółka decyduje się na podział swoich akcji oznacza to, że każda z akcji dzieli się na dwie akcje o cenie wynoszącej połowę pierwotnej ceny. Taki zabieg pozwala na zmniejszenie ceny pojedynczej akcji dzięki czemu może stać się ona dostępna dla większej liczby inwestorów. 
 
\bigskip

Powyższe dane nie wnoszą jednak zbyt wiele informacji ponieważ są odzwierciedleniem powstałego obrotu akcji na giełdzie, a nie jego przyczyną. W związku z dużą losowością ruchów giełdowych, są niewystarczające aby skutecznie przewidzieć zmiany cen akcji. Zawodowi maklerzy do podejmowania swoich decyzji wspomagają się dodatkowo dwoma technikami: \textbf{analizą fundamentalną} oraz \textbf{analizą techniczną}.

\subsubsection{Analiza fundamentalna \cite{fundamentalanalysis}}

Analiza fundamentalna spółek jest analizą kondycji ekonomicznej spółek w zestawieniu z wartością ich akcji. Ten rodzaj analizy ma odpowiedzieć na pytanie czy cena akcji konkretnej spółki odpowiada jej sytuacji na rynku. Przy takim badaniu spółki brane jest pod uwagę wiele różnych czynników, takich jak:
\begin{itemize}
\item{analiza finansowa spółki}
\item{analiza sektorowa}
\item{analiza makroekonomiczna}
\item{analiza ogólnej sytuacji spółki}
\end{itemize}

Ten rodzaj badania spółek jest niezwykle czasochłonny i często wymaga eksperckiej wiedzy w dziedzinie finansów. Dodatkowo analiza fundamentalna wymaga posiadania danych, publicznych aczkolwiek czasami ciężko dostępnych, o spółkach i sektorach, w których się znajdują. Analizę fundamentalną stosuje się w szczególności przy inwestycjach długoterminowych (np. kilka miesięcy).

Najsłynniejszym analitykiem technicznym świata jest \textit{Warren Buffet} prezes amerykańskiego holdingu \textit{Berkshire Hathaway \cite{berkeshire}}. 

\subsubsection{Analiza techniczna \cite{technicalanalysis}}

Analiza techniczna jest zbiorem technik mających na celu wspomaganie inwestora w podejmowaniu decyzji na podstawie historycznych danych giełdowych. Analiza ta bada zachowania rynku oraz poszukuje trendów np. poprzez analizę kształtów wykresów giełdowych. Szczególnie istotne są liczne wskaźniki techniczne oraz narzędzia analizy statystycznej.
Najpopularniejsze wskaźniki techniczne obejmują:
\begin{itemize}
\item{\textbf{SMA}} - średnia krocząca. Jest to średnia cen z kilku ostatnich dni (np. 3, 7, 14, 30),
\item{\textbf{EMA}} - wykładnicza średnia krocząca. Jest to wykładnicza średnia cen z kilku ostatnich dni (np. 3, 7, 14, 30),
\item{\textbf{MACD}} -  miara zbieżności i rozbieżności średnich ruchomych,
\item{\textbf{RSI}} -  wskaźnik siły względnej określający siłę trendu,
\item{\textbf{oscylator stochastyczny}} -  wskaźnik momentum i siły trendu.
\end{itemize}

\subsubsection{Źródło danych}

W pracy zostało wykorzystane darmowe źródło danych giełdowych \textit{Alpha Vantage} \cite{alphavantage}. Jest to API pozwalające na pobranie historycznych danych giełdowych dla konkretnej spółki poprzez podanie odpowiedniego symbolu giełdowego. Dostępne są zarówno podstawowe dane giełdowe jak i wskaźniki analizy technicznej. 

\bigskip

Na giełdach papierów wartościowych są obecne tysiące spółek. Ze względu na ograniczone zasoby obliczeniowe oraz dostępność danych badania zostały przeprowadzone na spółkach z giełdy \textit{NASDAQ} o największej kapitalizacji.

\subsection{Predykcja}

Na rysunku \ref{img:alphabet_history} widoczne są zmiany cen akcji spółki \textit{Alphabet Inc.} w latach 2004-2018. Analizując ten wykres z łatwością można wskazać daty, w których opłacalnym było zainwestowanie w akcje, aby następnie je sprzedać w póżniejszym terminie by osiągnąć zysk. Niestety stwierdzenie czy wartość akcji w przyszłości spadnie, czy wzrośnie, nie jest tak trywialne jak odczytywanie danych historycznych. Przewidywanie przyszłych cen akcji jest głównym zajęciem zarówno inwestorów indywidualnych jak i instytucjonalnych. Skuteczne odgadywanie przyszłych wzrostów lub spadków cen pozwoliłoby na osiąganie ponadprzeciętnych zysków i unikanie strat. O trudności tego zadania mogą świadczyć takie teorie jak \textit{hipoteza błądzenia losowego} czy też \textit{hipoteza rynku efektywnego}. Zgodnie z \textit{hipotezą błądzenia losowego} \cite{randwalk}, krótkoterminowo, ceny akcji zmieniają się według nieprzewidywalnych schematów. Zmiany minutowe cen akcji są więc dużo trudniejsze do przewidzenia niż zmiany dobowe. \textit{Hipoteza rynku efektywnego} \cite{efficientmarket} opiera się na założeniu iż ceny obecne na giełdzie całkowicie odwzorowują wszystkie dostępne informacje na rynku. Oznacza to, że próby wyprzedzenia innych inwestorów na podstawie szybkiej reakcji na pojawiające się informacje nie będą skuteczne. Obie te hipotezy mają zarówno swoich zwolenników jak i krytyków.

\begin{figure}[H]
\centering \includegraphics[scale=0.9]{img/GOOGL_adj_close.png}
\caption{Wykres cen akcji spółki \textit{Alphabet Inc} (opracowanie własne)}
\label{img:alphabet_history}
\end{figure}

Rysunek \ref{img:alphabet_history} ilustruje fakt, że ceny zamknięcia akcji tworzą szereg czasowy. Dotyczy to także pozostałych charakterystyk akcji, takich jak cena otwarcia, liczba akcji w obrocie danego dnia, najniższa cena akcji czy najwyższa cena akcji danego dnia. Fakt ten ma istotny wpływ na sposób używania i przetwarzania danych giełdowych.

\subsubsection{Zakres prognozy}

Przed przystąpieniem do konstruowania modeli predykcyjnych należy zdefiniować co tak naprawdę warto przewidywać, każda akcja ma bowiem kilka atrybutów. Najbardziej pożytecznym parametrem akcji, którego wykorzystanie daje inwestorowi największe szanse na zysk jest \textbf{cena zamknięcia}. Znajomość ceny zamknięcia z kolejnego dnia daje inwestorowi cały czas trwania sesji giełdowej na podjęcie skutecznych decyzji inwestycyjnych. Jest to najczęściej wybierany parametr akcji przy przewidywaniu ceny. Przykładem parametru, który nie jest istotny jest liczba akcji w obrocie z kolejnych dni, ta liczba sama w sobie nie niesie informacji o spadku lub wzroście cen.

\bigskip

Po wybraniu celu prognozy należy również określić jej przedział czasowy. Ceny na giełdzie można przewidywać dla dowolnego przedziału czasu. Może to być zarówno okres jednej minuty jak i kilku miesięcy. Przy gwarancji doskonałych prognoz, im większa częstotliwość dokładnego przewidywania ceny tym lepiej. Wynika to z tego iż inwestor może szybciej reagować na zachodzące zmiany i w większym stopniu wykorzystywać pozyskaną wiedzę zwiększając zyski. Z drugiej strony opierając się na \textit{hipotezie błądzenia losowego} można zauważyć, że zmiany w małych przedziałach czasowych są dużo bardziej zaburzone przez losowe wahania ceny. To z kolei sprawia iż krótkoterminowe ruchy cen mogą okazać się nie do przewidzenia. W celu utrzymania kompromisu pomiędzy użytecznością modelu, a jego odpornością na losowość giełdy, za okres predykcji został wybrany \textbf{jeden dzień}.
 
\subsubsection{Prognozowanie - regresja czy klasyfikacja?}

Do tematu prognozowania cen akcji można podejść na dwa sposoby:
\begin{itemize}
\item{\textbf{dokładny}, przewidywanie konkretnych wartości cen akcji,}
\item{\textbf{binarny}, predykcja wzrostu lub spadku ceny - tak zwana predykcja trendu.}
\end{itemize}

Potencjalnie korzystniejszym podejściem jest przewidywanie dokładnych cen akcji, gdyż jest to dokładniejsze aproksymowanie ceny. Jednakże z perspektywy inwestora istotniejszym od dokładnych wartości ceny są trendy. To właśnie różnice w cenach akcji pozwalają zarobić na ich obrocie. Wobec tego zamiast przewidywania dokładnej ceny zamknięcia warto przewidywać wzrosty oraz spadki cen. W przeciwieństwie do danych ciągłych, wyjściowe dane dyskretne  dają jasny sygnał o działaniach jakie należy podjąć aby zarobić. Z tego powodu jako podstawowe wyjście z modeli predykcyjnych wybrany został \textbf{trend binarny}.

\bigskip

Ze względu na to jak przebiega obrót akcjami, binarne przewidywanie z dnia na dzień może jednak okazać się niedostosowane do rzeczywistości. Akcje kupuje i sprzedaje się za pomocą domu maklerskiego, który pobiera prowizje za każdą transakcję. Obecnie najniższe prowizje na polskim rynku są na poziomie $0,19\%$ za transakcję. Pojedyncza operacja dająca zarobić na przewidzianej cenie wymaga kupienia, a następnie sprzedania akcji, wobec czego łączna prowizja wyniesie przy zaokrągleniu $0,4\%$. Wszystkie wahania cen poniżej tej wartości są teoretycznie bez znaczenia dla inwestora, ponieważ nie da się na nich zarobić. W związku z powyższym wnioskowaniem należy zastosować model dyskretny, będący rozwinięciem modelu binarnego o dodatkową klasę - klasę utrzymania ceny w pewnych ramach. Wyszczególnione są wówczas trzy klasy:
\begin{itemize}
\item spadek ceny poniżej $0,4\%$
\item wzrost ceny powyżej $0,4\%$
\item utrzymanie zmiany ceny w przedziale $(-0,4; 0,4)\%$
\end{itemize}

Dla potwierdzenia zasadności takiego modelu, należy upewnić się że dzienne wahania cen na giełdzie są wystarczające. Na rysunku \ref{img:googl_pct_change_last_30} można zaobserwować, iż zmiany w kursie często przekraczają $0,4\%$ w związku z czym transakcje przynoszące zysk można wykonywać regularnie. Ten wniosek potwierdza zasadność takiej konstrukcji modeli. W związku z większym stopniem złożoności takiej klasyfikacji, może okazać się iż dane wejściowe nie pozwalają na odseparowanie tych trzech klas. 

%TODO dodać paski -0.4%   +0.4% do wykresu
\begin{figure}[H]
\centering \includegraphics[scale=0.9]{img/googl_pct_change_last_30}
\caption{Dzeinna zmiana ceny akcji spółki \textit{GOOGL} z 30 dni (opracowanie własne)}
\label{img:googl_pct_change_last_30}
\end{figure}

\subsection{Kryteria oceny modeli predykcji}

Porównywanie jakości i wydajności jest nierozłącznym elementem tworzenia i testowania metod uczenia maszynowego. Istnieje wiele sposobów na realizację tego nietrywialnego zadania, które jak się okazuje, często wymaga porównywania modeli na kilku płaszczyznach. Najpopularniejszymi miarami porównawczymi są:
\begin{itemize}
\item procent prawidłowych klasyfikacji
\item pole AUC pod krzywą ROC
\item częściowy indeks Gini
\item metryka F1
\item współczynnik Briera
\item statystyka Kołomogrowa-Smirnova
\end{itemize}

\subsubsection{Macierz błędu}

W przypadku klasyfikacji dwuklasowej na klasy A i B każdą predykcję można przypisać do jednej z 4 grup:
\begin{itemize}
\item True Positive (TP) - gdy przewidziano klasę A dla etykiety A
\item False Negative (FN) - gdy przewidziano klasę B dla etykiety A
\item False Positive (FP) - gdy przewidziano klasę A dla etykiety B
\item True Negative (TN) - gdy przewidziano klasę B dla etykiety B
\end{itemize}

Graficzną reprezentację podziału klasyfikacji na powyższe kategorie nazywamy \textit{macierzą błędu}. Zastosowanie miar opartych o tablicę błędów dla problemów z większą liczbą klas wymaga dodatkowych kroków. W celu policzenia wartości TP, FN, FP i TN należy wyróżnić konkretną klasę, a pozostałe klasy należy zagregować w sztuczną klasę przeciwną. W ten sposób należy wyliczyć konkretną miarę tyle razy ile jest klas. Ostatecznym krokiem w celu uzyskania jednolitej oceny modelu jest na przykład wyliczenie średniej ważonej z wyników dla każdej z klas.


\subsubsection{Procent prawidłowych klasyfikacji}

Jednym z najprostszych sposobów do oceny dokładności klasyfikatorów jest określenie procentu prawidłowych przypisań przykładu do klasy. Metoda ta potrafi dawać złudzenie zadowalających wyników, w których występują duże różnice w licznościach poszczególnych klas. Rozważmy dla takiego zadania naiwny model przypisujący do każdego postawionego przykładu klasę, której liczność jest największa. Wówczas wyniki procentowe prawidłowej klasyfikacji będą wprost proporcjonalne do różnicy w liczności klasy największej w stosunku do innych klas. W większości przypadków pomimo dobrego wyniku taki model będzie uznany za bezużyteczny. Wobec tego tę miarę jakości należy stosować wraz z innymi miarami, które nie są podatne na tego typu zaburzenia.

\subsubsection{Pole AUC pod krzywą ROC \cite{roc}}

Krzywa ROC (ang. receiver operating characteristic) jest narzędziem, która opisuje dokładność klasyfikatora za pomocą oceny jego czułości i precyzji. Precyzją modelu nazywa się stosunek $\frac{TP}{TP+FP}$, zaś czułość jest oznaczona przez $\frac{TP}{TP+FN}$.

\bigskip

Zdefiniujmy wartości \textit{True Positive Rate (TPR)} oraz \textit{False\ Positive\ Rate (FPR)}:

$$ TPR = \frac{TP}{TP+FN}\ \ \ \ \ \ \ \ FPR = \frac{FP}{FP+TN} $$

Klasyfikatory w większości przypadków nie zwracają dokładnego wyniku przypisania przykładu do klasy. Zazwyczaj wynikiem klasyfikacji jest liczba rzeczywista z przedziału $[0, 1]$, którą można identyfikować jako prawdopodobieństwo. Można przyjąć że jeżeli klasyfikator zwróci $0$ oznacza to przypisanie do klasy A, zaś $1$ oznacza przypisanie do klasy B. Dla wartości z zakresu $(0, 1)$ przypisuje się pewną wartość progową rozgraniczającą obie klasy. Dla tego progu mniejsze od niego wartości przypisujemy do klasy A, zaś resztę do klasy B. Intuicyjnie jest to zazwyczaj połowa przedziału czyli $0.5$.

Krzywa ROC jest graficzną reprezentacją skuteczności modelu klasyfikacyjnego. Jest ona skonstruowana poprzez wykreślenie stosunku $TPR$ do $FPR$ dla różnych progów rozgraniczających klasy. Na rysunku \ref{img:roc} widać przykładowe krzywe ROC dla klasyfikatorów różnej jakości.


%source: https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5
\begin{figure}[H]%
\centering
\subfigure[Krzywa ROC dla modelu, który nie jest w stanie rozdzielić klas]{%
\includegraphics[scale=0.55]{img/roc_1.png}}%
\qquad
\subfigure[Krzywa ROC przykładowego klasyfikatora]{%
\includegraphics[scale=0.55]{img/roc_2.png}}%
\qquad
\subfigure[Krzywa ROC dla modelu idealnego]{%
\includegraphics[scale=0.55]{img/roc_3.png}}%
\caption{Przykładowe krzywe ROC \cite{roccurves} }% (źródło: https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5).}
\label{img:roc}
\end{figure}


Porównanie różnych klasyfikatorów za pomocą krzywej ROC odbywa się poprzez porównanie pola pod krzywymi. Im większe pole pod krzywą ROC dla danego klasyfikatora tym lepsza jest jego jakość. Pole pod krzywą dla modelu idealnego wynosi $1$, zaś dla modelu losowego $0.5$. Warto zauważyć że dla wartości pola poniżej 0.5  korzystnym zabiegiem jest zamiana przedziałów dla klas.


\subsubsection{Częściowy indeks Gini} %TODO bibliografia

Częściowy indeks Gini jest innym sposobem na analizę jakości modelu predykcyjnego za pomocą krzywej ROC. Otrzymuje się go poprzez wyliczenie pola powierzchni pomiędzy krzywą ROC dla modelu predykcyjnego, a krzywą ROC dla modelu losowego, w stosunku do pola powierzchni między krzywą ROC modelu idealnego, a krzywą ROC modelu losowego. Dla modelu losowego wynosi 0, zaś dla modelu idealnego wartość indeksu wynosi 1. W ten sposób otrzymana wartość indeksu Gini może być interpretowana jako procent idealności modelu.

\subsubsection{F1} %TODO bibliografia

Metryka F1 jest średnią harmoniczną metryk czułości i precyzji (wyrażona wzorem $F1=2*\frac{precyzja*czulosc}{precyzja+czulosc}$). Metryka ta jest dobrym narzędziem pozwalającym określić za pomocą jednej wartości jakość modelu, biorąc pod uwagę precyzję jak i czułość modelu. Osiąga ona w najlepszym przypadku wartość 1, zaś w najgorszym wartość 0. 

\subsubsection{Współczynnik Briera \cite{brier}}

Współczynnik Briera (ang. Brier score) jest metodą oceny modeli klasyfikujących opisana wzorem:

$$	BS=\frac{1}{N} \sum_{t=1}^{N} \sum_{i=1}^{R}(f_{ti}-o_{ti})^2 $$

\begin{itemize}
\item $N$ to liczba predykcji,
\item $R$  to liczba możliwych klas
\item $f_{ti}$ to prawdopodobieństwo, które wyznaczył klasyfikator, przypisania przykładu $t$ do klasy $i$,
\item $o_{ti}$ to rzeczywiste przypisanie przykładu do danej klasy (0 gdy przykład nie jest tej klasy, oraz 1 gdy przykład należy do tej klasy).
\end{itemize}

W związku z powyższą definicją, miara ta może zostać wykorzystana w przypadku modeli, które na swoim wyjściu zwracają prawdopodobieństwo przypisania przykładu do każdej z klas. Wobec tego nie każdy model można ocenić tą metryką. Istotnym spostrzeżeniem jest fakt iż w przeciwieństwie do innych metryk, współczynnik Briera modelu idealnego wynosi $0$, zaś im gorszy model tym większy współczynnik.


%TODO źródło do poniższego
\subsubsection{Statystyka Kołmogorowa-Smirnova}

Statystyka Kołmogorowa-Smirnova (ang. Kolmogrow-Smirnov Test) pozwala ocenić jakość klasyfikatora binarnego na podstawie stopnia separacji rozkładu dwóch klas. Ocena dokonywana jest przez zmierzenie maksymalnej odległości między wkyresami dystrybuant rozkładu jednej i drugiej klasy. Niech $F(x)$ to dystrybuanta rozkład klasy 1, zaś $G(x)$ to dystrybuanta rozkładu klasy 2. Wówczas statystyka Kołmogorowa-Smirnova opisana jest wzorem:

$$D_{n,m}=\sup_x|F(x)-G(x)|$$

Metryka ta daje wartość 100 dla modelu idealnego, zaś 0 dla modelu losowego.

\subsubsection{Dobór metryki}

Porównanie modeli klasyfikujących jest zadaniem trywialnym tylko dla specyficznych problemów. W tych przypadkach można wykorzystać procent prawidłowych klasyfikacji jako jedyną miarę jakości modeli. W bardziej złożonych przypadkach, gdy dochodzi do dysproporcji w licznościach klas, ta podstawowa miara zostaje w pewien sposób zafałszowana. Innym aspektem, który może być brany pod uwagę przy ocenie klasyfikatorów jest różnica w wadze błędu z grupy \textit{FP}, względem błędu z grupy \textit{FN}. Te problemy należy rozwiązywać poprzez używanie różnorodnych miar do porównywania modeli. Używanie wielu metryk może być przydatne w szczególności gdy dwa modele mają podobne wartości dla jednej z miar.

\bigskip

W zagadnieniu predykcji giełdowych sprowadzonym do klasyfikacji, można posłużyć się \textit{procentem prawidłowych klasyfikacji} jako podstawową miarą porównawczą. Wynika to z faktu, iż dla większości spółek różnica w licznościach klas mieści się w granicach kilku do kilkunastu procent całego zbioru danych. Taka dysproporcja jest jednak na tyle znacząca, że dla porównywania modeli o bliskich wynikach trzeba stosować dodatkową miarę porównawczą. Ze względu na niewrażliwość na dysproporcje w licznościach klas oraz swoją popularność, jako drugą metrykę wykorzystano \textit{pole AUC pod krzywą ROC}.


\subsection{Uczenie modeli - specyfika szeregów czasowych}

Każdy proces uczenia modeli sztucznej inteligencji zwieńczony jest analizą jakości. Zazwyczaj taką analizę przeprowadza się poprzez wydzielenie pewnej części zbioru danych i oznaczenia jej jako zbioru testowego. Reszta zbioru danych zwana jest zbiorem treningowym (rysunek \ref{img:train_test_split}). Taki podział wszystkich próbek pozwala na używanie części treningowej do nauki modelu, zaś części testowej do jego oceny. Ocena modelu na podstawie próbek, któych model nie widział podczas procesu uczenia daje wiarygodne wyniki.

\begin{figure}[H]
\centering 
\includegraphics[scale=0.5]{img/train_test_split.png}
\caption{Podział danych na zbiór treningowy i testowy \cite{train_test_split}}
\label{img:train_test_split}
\end{figure}

Ten model podziału jest najbardziej powszechny pośród zagadnień klasyfikacyjnych ze względu na swoją prostotę i odporność na zjawisko przeuczenia (ang. overfitting). Dane giełdowe jako szeregi czasowe posiadają dodatkową cechę - umiejscowienie próbek na osi czasu. Wykorzystanie faktu, iż kolejne próbki danych pojawiają się stopniowo wraz z upływem czasu, pozwala na udoskonalenie metody doboru danych do uczenia się. Uczenie i ocena metodą kroczącą (ang. walk forward) polega na stopniowym powiększaniu zbioru danych treningowych o kolejne próbki ze zbioru testowego podczas procesu oceny jakości. 

\textit{Przykład:} podczas oceny jakości model przewiduje cenę za pomocą próbki z dnia $t$ mając do uprzedniej nauki wszystkie próbki od $t_0$ do $t-1$. Po tej predykcji próbka z dnia $t$ zostaje wcielona do zbioru uczącego. Model może, ale nie musi, zostać ponownie poddany procesowi uczenia przed przystąpieniem do oceny jakości dla predykcji kolejnej próbki $t+1$. Proces ten zobrazowany jest na rysunku \ref{img:train_test_split_time_series}. Na niebiesko oznaczono próbki zbioru treningowego, na czerwono zaś próbkę zbioru testowego podlegającą ocenie.

\begin{figure}[H]
\centering 
\includegraphics[scale=0.75]{img/train_test_split_time_series.png}
\caption{Podział danych na zbiór treningowy i testowy metodą kroczącą \cite{train_test_split_time_series}}
\label{img:train_test_split_time_series}
\end{figure}

Wykorzystanie metody kroczącej do podziału zbioru danych pozwala zmaksymalizować ilość informacji przekazanych do modelu podczas procesu uczenia, a tym samym poprawia końcowe wyniki klasyfikacji. 


\subsection{Wnioski i uwagi}

Do zagadnienia predykcji cen na giełdzie można podchodzić na kilka sposobów. Najbardziej intuicyjnym rozwiązaniem z perspektywy początkującego inwestora, jest model, który na wyjściu wyznacza jaką akcję powinien wykonać inwestor w stosunku do akcji konkretnej spółki. Doświadczony makler do wyznaczania cen zapewne wybrałby model regresyjny, który poza określeniem trendu daje możliwość oceny jak duże są wahania ceny. Dzięki temu mógłby dobrać spółki, dla których wzrost cen będzie największy. Przy ocenie jakości regresji błąd jest zazwyczaj określany za pomocą odległości przewidywanej wartości ceny od rzeczywistej wartości ceny. Informacja że dany model aproksymuje wartość ceny z błędem $\pm 5 \$$ jest ciężka do zinterpretowania wprost. Na podstawie takiej oceny makler nie jest w stanie bezpośrednio stwierdzić czy taki model nadaje się do użycia na giełdzie. Dla zagadnienia klasyfikacji błąd jest określony jako $\%$ prawidłowych klasyfikacji, więc daje dużo lepsze wyobrażenie na temat jakości i możliwości wykorzystania modelu do obrotu akcjami.

\bigskip



\newpage

\section{Analiza i przetworzenie danych}

Przed przystąpieniem do wyboru modeli należy zastanowić się nad danymi jakie będą służyć do ich uczenia. Wybór odpowiednich cech, analiza zebranych informacji oraz przetworzenie ich, wykracza poza zakres uczenia maszynowego tworząc własną dziedzinę zwaną inżynierią i analizą danych. Odpowiedni dobór i obróbka danych wejściowych często daje większe korzyści niż dopracowywanie modeli przewidujących i optymalizacja ich parametrów. 

\subsection{Wybrane cechy}

Spośród dostępnych danych do uczenia modeli wybrane zostały: 
\begin{itemize}
\item podstawowe dane giełdowe oraz ich modyfikacje,
\item wybrane wskaźniki analizy technicznej oraz ich modyfikacje.
\end{itemize}

Analiza fundamentalna ze względu na swoją długoterminową naturę (raporty finansowe spółek publikowane kwartalnie) jest mało istotna przy dziennych predykcjach giełdowych. Dodatkowo istnieje mało darmowych źródeł danych analizy fundamentalnej. Z tych względów zostanie ona pominięta w tej pracy.

\bigskip

Wszystkie dane wejściowe, wraz z opisami, zaprezentowane są w tabeli \ref{tab:data_columns_table}. Wszystkie dane mają charakter dzienny. Najnowsze informacje pochodzą z dnia \textit{t}, zaś przewidywaną ceną jest cena z dnia \textit{t+1}.

\begin{longtable}[c]{| m{0.5cm} m{5cm} m{10cm}|} 

\toprule
  Lp. & Oznaczenie & Opis\\
\midrule
\endhead
\midrule

\caption{Wybrane cechy i ich opis}
\label{tab:data_columns_table}
\endfoot

\bottomrule
\caption{Wybrane cechy i ich opis}
\label{tab:data_columns_table}
\endlastfoot


 1 & $C_t$ & Cena zamknięcia w dniu $t$. \\ 
 2 & $O_t$ & Cena otwarcia w dniu $t$. \\
 3 & $H_t$ & Najwyższa cena w dniu $t$. \\
 4 & $L_t$ & Najniższa w dniu $t$. \\
 5 & $V_t$ & Liczba akcji w obrocie w dniu $t$. \\
 6 & $HL\_PCT$ & Różnica pomiędzy $H_t$ a $L_t$ wyrażona w procentach.\\
 7 & $SMA_5$ & Średnia krocząca z 5 dni. \\
 8 & $SMA_{10}$ & Średnia krocząca z 10 dni. \\\
  9 & $SMA_{20}$ & Średnia krocząca z 20 dni. \\
 10 & $SMA\_DIFF$ & $SMA_{10}-SMA_{5}$ \\
 11 & $SMA\_DIFF2$ & $SMA_{20}-SMA_{5}$ \\
 12 & $TR$ & (ang. True Range) różnica pomiędzy najniższą ceną, a najwyższą ceną danego dnia. \\
 13 & $MACD$ & Wskaźnik wyliczany z różnicy dwóch wykładniczych średnich kroczących.\\
 14 & $MACD\_SIGNAL$ & Wykładnicza średnia krocząca ze wskaźnika MACD \\
 15 & $ROC_{5}$ & (ang. Rate of Change) Wskaźnik liczący procentową różnicę w cenie między dniem $t$ a $t-5$. \\
 16 & $ROC_{10}$ & (ang. Rate of Change) Wskaźnik liczący procentową różnicę w cenie między $t$ a $t-10$. \\
 17 & $ROC\_DIFF$ & $ROC_{10}-ROC_{5}$ \\
  18 & $MOM_{5}$ & Momentum - różnica w cenie między $t$ a $t-5$.  \\
 19 & $MOM_{10}$ & Momentum - różnica w cenie między $t$ a $t-10$. \\
 20 & $MOM\_DIFF$ & $MOM_{10}-MOM_{5}$ \\
  21 & $WILLR_{5}$ & \textit{Williams` \%R} - wskaźnik niedosycenia/przesycenia ceny z ostatnich 5 dni. \\
 22 & $WILLR_{10}$ & \textit{Williams` \%R} - wskaźnik niedosycenia/przesycenia ceny z ostatnich 10 dni.  \\
 23 & $WILLR\_DIFF$ & $WILLR_{10}-WILLR_{5}$ \\
  24 & $APO_{5}$ & Oscylator ceny z 5 dni. \\
 25 & $APO_{10}$ & Oscylator ceny z 10 dni.  \\
 26 & $APO\_DIFF$ & $APO_{10}-APO_{5}$ \\
  27 & $RSI_{5}$ & Wskaźnik siły względnej - oscylator siły trendu z 5 dni. \\
 28 & $RSI_{10}$ & Wskaźnik siły względnej - oscylator siły trendu z 10 dni.\\
 29 & $RSI\_DIFF$ & $RSI_{10}-RSI_{5}$ \\
  30 & $ADX_{5}$ & Wskaźnik siły trendu z 5 dni. \\
 31 & $ADX_{10}$ & Wskaźnik siły trendu z 10 dni. \\
 32 & $ADX\_DIFF$ & $ADX_{10}-ADX_{5}$ \\
 33 & $CCI_{5}$ & (ang. Commodity Channel Index) Oscylator z 5 dni. \\
 32 & $CCI_{10}$ & (ang. Commodity Channel Index) Oscylator z 10 dni. \\
 34 & $CCI\_DIFF$ & $CCI_{10}-CCI_{5}$ \\
 35 & $AD$ & linia \textit{Chaikin A/D}.  \\
 36 & $STOCH\_K$ & Oscylator stochastyczny \textit{Slow \%K}. \\
 37 & $STOCH\_D$ & Oscylator stochastyczny \textit{Slow \%D}.\\
 39 & $STOCH\_K\_DIFF$ & $STOCH\_K_{t}-STOCH\_K_{t-1}$ \\
 40 & $STOCH\_D\_DIFF$ & $STOCH\_D_{t}-STOCH\_D_{t-1}$  \\
 41 & $DISPARITY_{5}$ &  $\frac{C_t}{SMA_5}\times 100$ \\
 42 & $DISPARITY_{10}$ & $\frac{C_t}{SMA_10}\times 100$ \\
 43 & $DISPARITY_{20}$ & $\frac{C_t}{SMA_20}\times 100$ \\
 44 & $BANDS\_DIFF_{10}$ & $BOLL\_UP_{10} - BOLL\_LOW_{10}$ - różnica górnej i dolnej wartości wstąg Bollingera z 10 dni.  \\
 45 & $BANDS\_DIFF_{20}$ & $BOLL\_UP_{20} - BOLL\_LOW_{20}$ - różnica górnej i dolnej wartości wstąg Bollingera z 20 dni.  \\
46 & $PRICE\_BANDS\_UP_{10}$ & $(C_t-BANDS\_UP_{10})\div BANDS\_UP_{10}$ - wskaźnik oparty o wstęgi Bollingera.  \\
 47 & $PRICE\_BANDS\_LOW_{10}$ & $(C_t-BANDS\_LO_{10})\div BANDS\_LOW_{10}$ - wskaźnik oparty o wstęgi Bollingera.\\
 48 & $PRICE\_BANDS\_UP_{20}$ & $(C_t-BANDS\_UP_{20})\div BANDS\_UP_{20}$ - wskaźnik oparty o wstęgi Bollingera.\\
 49 & $PRICE\_BANDS\_LOW_{20}$ & $(C_t-BANDS\_LOW_{20})\div BANDS\_LOW_{20}$ - wskaźnik oparty o wstęgi Bollingera.\\
     
\end{longtable}

\subsection{Przetworzenie wstępne}

Po wybraniu odpowiednich danych należy przystąpić do ich pobrania. Pobrane dane nie są jednak gotowe do wykorzystania w procesie uczenia maszynowego. Zbiory informacji, w szczególności te pobrane z internetu, należy traktować zgodnie z zasadą ograniczonego zaufania. Wobec braku gwarancji jakości, dane powinny zostać zbadane pod względem integralności oraz poprawności. Spośród najczęstszych problemów wymienić można: 
\begin{itemize}
    \item brakujące informacje,
    \item duplikacja danych,
    \item dane nominalne (np. łańcuchy znaków),
    \item błędy pomiarowe.
\end{itemize}
%TODO podpiąć tutaj bibliografię o przetwarzaniu danych w machine learningu
W celu eliminacji błędnych danych należy je usunąć lub zastąpić wybraną wartością np. średnią wartością z danej cechy. Jeśli chodzi o dane nominalne stosowana jest \textbf{binaryzacja}. Polega ona na odpowiednim przekształceniu cechy na wektor cyfr. Po wyeliminowaniu powyższych problemów dane warto przetworzyć takimi metodami jak \textbf{normalizacja} czy \textbf{standaryzacja}. Służą one do przeskalowania zakresu możliwych wartości do przedziału $[0,1]$ lub $[-1,1]$. Taki zabieg polepsza wydajność modeli uczenia maszynowego.

\bigskip

\subsubsection{Niestacjonarność szeregów czasowych}

%TODO bibliografia niestacjonarność szeregów czasowych
Na rysunku \ref{img:non_stationary_adjusted_close} zauważyć można zjawisko niestacjonarności. Jest to cecha związana z autokorelacją zmiennych szeregów czasowych. Oznacza to iż kolejne wyrazy szeregu zależą w jakimś stopniu od poprzednich. Dla cen akcji ta zależność jest ewidentna, cena każdego dnia jest oparta o cenę z dnia poprzedniego. 

\begin{figure}[H]
\centering 
\includegraphics[scale=0.9]{img/GOOGL_adj_close.pdf}
\caption{Wykres cen akcji spółki \textit{Alphabet Inc} (opracowanie własne)}
\label{img:non_stationary_adjusted_close}
\end{figure}

Zjawisko niestacjonarności szeregów czasowych negatywnie wpływa na wykorzystywanie ich do uczenia maszynowego. Wszystkie zmienne, których dotyczy ten problem trzeba odpowiednio dostosować przed użyciem do uczenia modeli. Najbardziej powszechną metodą radzenia sobie z niestacjonarnością jest różnicowanie (ang. \textbf{differencing}). Jest to prosta metoda polegająca na wyliczeniu różnicy pomiędzy kolejnymi elementami w szeregu. W ten sposób zmienna $x_t$ jest zastąpiona przez $x'_t=x_t-x_{t-1}$. Wynik takiego przetworzenia dla ceny zamknięcia spółki \textit{Alphabet Inc} widoczny jest na rysunku \ref{img:stationary_adjusted_close}.

\begin{figure}[H]
\centering 
\includegraphics[scale=0.9]{img/adjusted_close_stationary.pdf}
\caption{Wykres cen akcji spółki \textit{Alphabet Inc} po przetworzeniu (opracowanie własne)}
\label{img:stationary_adjusted_close}
\end{figure}

\subsubsection{Stworzenie etykiet}

W procesie nadzorowanego uczenia maszynowego poza danymi wejściowymi potrzeba również etykiet, tj. zbioru pożądanych odpowiedzi. W przypadku regresyjnej predykcji cen zamknięcia w dniu $t$ etykietą jest cena zamknięcia z dnia $t+1$. Etykietę dla każdego wiersza danych wejściowych można więc uzyskać poprzez dodanie kolumny ceny zamknięcia przesuniętej o jeden dzień wstecz (zilustrowane na rysunku \ref{img:regression_label_creation}). 

\begin{figure}[H]
\centering 
\includegraphics[scale=0.9]{img/label_creation.png}
\caption{Przykładowe dane dla spółki \textit{Alphabet Inc}}
\label{img:regression_label_creation}
\end{figure}

W celu osiągnięcia etykiet do klasyfikacji potrzeba wykonać dodatkowe kroki. Korzystając z nowej kolumny można obliczyć różnicę pomiędzy $C_t$, a $C_{t+1}$ . Wyznaczenie etykiety trendu do klasyfikacji binarnej sprowadza się do wyliczenia funkcji $sgn(C_{t+1}-C_{t})$ (rysunek \ref{img:binary_label_creation}). 

\begin{figure}[H]
\centering 
\includegraphics[scale=0.9]{img/label_creation2.png}
\caption{Przykładowe dane dla spółki \textit{Alphabet Inc}}
\label{img:binary_label_creation}
\end{figure}

 W przypadku klasyfikacji podzielonej na 3 klasy wyznaczenie etykiety sprowadza się do obliczenia procentowej różnicy pomiędzy cenami zamknięcia - $100*(C_{t+1}-C_t)/C_t$. Tak wyliczoną różnicę procentową można wykorzystać do przypisania etykiecie wartości $-1, 0, 1$ w zależności od wybranego progu opłacalności. Przykładowe obliczenia zostały zilustrowane na rysunku \ref{img:classification_label_creation}.

\begin{figure}[H]
\centering 
\includegraphics[scale=0.9]{img/label_creation3.png}
\caption{Przykładowe dane dla spółki \textit{Alphabet Inc}}
\label{img:classification_label_creation}
\end{figure}

\subsubsection{Redukcja danych wejściowych}

Redukcja rozmiaru danych wejściowych jest zagadnieniem pozwalającym na poradzenie sobie ze zbyt dużą liczbą danych wejściowych. Jeżeli dwie zmienne są ze sobą mocno skorelowane, wówczas jedną z nich można odrzucić bez utraty zawartych w niej informacji. Macierz korelacji par zmiennych wejściowych przedstawiona jest na rysunku \ref{img:correlation}. Analizując macierz korelacji zauważyć można że duża część zmiennych jest ze sobą mocno skorelowana (wartości bliskie $1$ oznaczają wysoką korelację, 0 brak korelacji, zaś $-1$ negatywną korelację).

\begin{figure}[H]
\centering 
\includegraphics[scale=0.6]{img/corr_matrix.pdf}
\caption{Macierz korelacji par zmiennych}
\label{img:correlation}
\end{figure}

Dla par zmiennych o najwyższej korelacji można usunąć jedną ze zmiennych, ponieważ powiela ona informacje już zawarte w drugiej zmiennej.  W tabeli \ref{tab:ccorr_table} zostały wylistowane pary zmiennych o najwyższej korelacji. Ze zbioru wejściowego usunięte zostały zmienne z kolumny \textit{Zmienna 2}.


\begin{table}[H]
\centering
\begin{tabular}{ |c|c|c| } 
 \hline
Zmienna 1 & Zmienna 2 &  Stopień korelacji \\
 \hline
APO-5 & APO-10 &  1.000000 \\
 \hline
10-SMA & MOM-10 &  1.000000 \\
 \hline
5-SMA & MOM-5 &  1.000000 \\
 \hline
5-SMA & ROC-5 &  0.997665 \\
 \hline
10-SMA & ROC-10 &  0.996666 \\
 \hline
RSI-5 & RSI-10 &  0.964811 \\  
 \hline
\end{tabular}
\caption{Tabela najbardziej skorelowanych par zmiennych}
\label{tab:ccorr_table1}
\end{table}


Po odrzuceniu najmocniej skorelowanych danych można skorzystać z jednej z metod redukcji wymiaru zadania wejściowego jaką jest \textbf{analiza głównych składowych} (ang. principal component analysis). Jest to statystyczna metoda analizy czynnikowej, która modyfikuje układ współrzędnych w taki sposób aby maksymalizować wariancję kolejncyh zmiennych. Dzięki temu tworzona jest nowa przestrzeń obserwacji, w której najwięcej zmienności przedstawiają początkowe czynniki. Metode ta opiera się o macierz korelacji lub macierz kowariancji stworzonej z danych wejściowych. Rozmiar wejścia redukowany jest poprzez wybranie czynników, które reprezentują największą część wariancji w zbiorze danych. Stosunek liczby wybranych zmiennych do proocenta całkowitej wariancji zbioru danych przedstawiony jest na rysunku \ref{img:pca_variance}. Zawarcie $90\%$ wariancji wymaga użycia 8 składowych,  $95\%$ wariancji wymaga użycia 12 składowych, $99\%$ wariancji wymaga użycia 19 składowych. Wybranie wartości $99\%$ wariancji pozwala ograniczyć rozmiar wejściowego wektora o ponad połowę bez utraty informacji w nim zawartych.

\begin{figure}[H]
\centering 
\includegraphics[scale=0.9]{img/pca_variance.pdf}
\caption{Liczba składowych, a całkowita wariancja zbioru}
\label{img:pca_variance}
\end{figure}

\newpage

\section{Wybrane algorytmy do prognozowania}

Istnieje wiele algorytmów mogących posłużyć do zagadnień klasyfikacji lub regresji. W tym rozdziale omówione zostały klasyfikatory, które później zostały użyte do predykcji na danych giełdowych.

\subsection{SVM \cite{svm}}

Maszyny wektorów podpierających (ang. support-vector machines) są zbiorem klasyfikatorów mających na celu wyznaczenie hiperpłaszczyzn rozdzielających klasy z zachowaniem maksymalnego marginesu rozdzielającego (rysunek \ref{img:wiki_svm}). W podstawowej wersji klasyfikatory SVM potrafią sktuecznie klasyfikować problemy separowalne liniowo.


\begin{figure}[H]
\centering \includegraphics[scale=0.9]{img/svm.png}
\caption{Hiperpłaszczyzna rozdzielająca zbiór z maksymalnym marginesem \cite{wikisvm}}
\label{img:wiki_svm}
\end{figure}

W celu używania maszyn wektorów nośnych do klasyfikacji problemów nieliniowych stosuje się przekształcanie przestrzeni zadania za pomocą funkcji jądrowych. Wprowadzają one dodatkowe wymiary do zadania, w których znalezienie hiperpłaszczyzny rozdzielającej klasy może okazać się prostsze (rysunek \ref{img:wiki_svm2}). Do najpopularniejszych funkcji jądrowych zalicza się funkcje: liniową (zachowującą wymiar zadania w niezmienionym stanie), wielomianową, radialną czy też sigmoidalną.


\begin{figure}[H]
\centering \includegraphics[scale=0.2]{img/svm2.png}
\caption{Ten sam problem zaprezentowany w dwóch oraz trzech wymiarach \cite{wikisvm}}
\label{img:wiki_svm2}
\end{figure}


\subsection{Sieci neuronowe \cite{neural-nets}}

Sieci neuronowe są zbiorem modeli matematycznych służących do realizacji obliczeń, bądź przetwarzania sygnałów. Inspirowane działaniem mózgu, swoją nazwę czerpią z upodobnienia struktury do naturalnych neuronów oraz łączących je synaps. Głównymi zastosowaniami sieci neuronowych są zadania regresji, klasyfikacji oraz generowania danych. 

\bigskip

Podstawowym elementem sieci neuronowej jest neuron, który na wejściu przyjmuje dane wejściowe, przetwarza i zwraca pojedynczy sygnał wyjściowy. Przetwarzanie sygnału przez neuron z polega zazwyczaj na zsumowaniu sygnałów dochodzących do niego, a następnie obliczenie wartości funkcji aktywacji. Uzyskana wartość z funkcji aktywacji jest przekazywana jako wyjście z neuronu (rysunek \ref{neural-net}). Funkcje aktywacji mogą wprowadzić element nieliniowy do modelu dzięki czemu sieci neuronowe mogą posłużyć do klasyfikacji zbiorów, które nie są separowalne liniowo. Dodatkowo połączenia między neuronami posiadają przypisaną wagę mającą bezpośredni wpływ na wartość sygnału przechodzącego między nimi.

\bigskip

Wiodącym schematem uczenia sieci neuronowych jest korzystanie z przykładów, z których każdy ma etykietę czyli oczekiwaną wartość wyjściową. Każdy z przykładów jest przetwarzany przez sieć neuronową, następnie przez zestawienie wartości wyjściowej sieci z etykietą (odpowiednią funkcją straty) można wyliczyć błąd sieci dla danego przykładu. Ostatnim krokiem jest poprawa wag w sieci neuronowej według wybranej metody propagacji wstecznej. Problem optymalizacji sieci neuronowej sprowadzany jest do problemu optymalizacji funkcji poprzez modyfikację wag na połączeniach między neuronami. Metoda ta zaliczana jest do nauczania z nauczycielem (ang. supervised learning). Najczęściej stosowanymi metodami optymalizacji są algorytmy spadku gradientowego. 

\bigskip

Przy wykorzystywaniu sieci neuronowych głównym problemem, z którym zmagają się naukowcy jest odpowiedni dobór parametrów i algorytmów. Spośród elementów wymagających odpowiedniego dobrania wymienić można następujące:
\begin{itemize}
\item liczba warstw sieci,
\item liczba neuronów w każdej z warstw ukrytych,
\item wykorzystane funkcje aktywacji,
\item algorytm optymalizacyjny,
\item funkcja straty.
\end{itemize}


\subsubsection{Sieci typu MLP \cite{mlp}}

Jednym z najprostszych przykładów sieci neuronowych jest perceptron wielowarstwowy (ang. multilayer perceptron). Taka sieć składa się z warstwy wejściowej, z dowolnej ilości warstw ukrytych oraz z warstwy wyjściowej. W tym rodzaju sieci neuronowych, sygnał wyjściowy dowolnego neuronu jest traktowany jako sygnał wejściowy każdego z neuronów z kolejnej warstwy (rysunek \ref{img:neural-net}). 

\bigskip

\begin{figure}[H]
\centering \includegraphics[scale=0.7]{img/nn.png}
\caption{Schemat sieci neuronowej typu MLP \cite{mlpnn}}
\label{img:neural-net}
\end{figure}

Najprostszą implementacja sieci do predykcji danych giełdowych jest sieć przyjmująca na wejściu wektor informacji o akcjach spółki z jednego dnia, zwracająca na wyjściu przewidywaną wartość ceny akcji następnego dnia. Perceptron wielowarstwowy można również zaprojektować tak, aby na wyjściu zwracał wynik klasyfikacji, czyli procentowy wynik przypisania danych wejściowych do każdej z możliwych klas. W tej pracy badane były sieci neuronowe klasyfikujące dane wejściowe według trzech klas: spadek wartości poniżej pewnego progu, utrzymanie wartości w ramach tego progu oraz wzrost wartości powyżej tego progu. 

\subsection{Random forest \cite{randforest}}

Las losowy (ang. \textit{random forest}) jest modelem opartym o drzewa decyzyjne służącym do klasyfikacji lub regresji. Drzewa decyzyjne są graficzną metodą wspomagania procesu decyzyjnego. W przypadku zagadnień uczenia maszynowego drzewa decyzyje najprościej zobrazować na przykładzie problemu klasyfikacji binarnej. Na rysunku \ref{img:wiki_dec_tree} przedstawione jest drzewo decyzyjne dla problemu predykcji losu pasażerów statku Titanic. Drzewo to oparte jest o trzy cechy: płeć, wiek oraz liczbę rodzeństwa oraz współmałżonków (\textit{sibsp}). 

\begin{figure}[H]
\centering \includegraphics[scale=0.6]{img/decision_tree.png}
\caption{Drzewo decyzyjne dla problemu klasyfikacji losu pasażerów statku Titanic \cite{wikidecisiontree}}
\label{img:wiki_dec_tree}
\end{figure}

Dla złożonych zagadnień predykcji takich jak przewidywanie trendu giełdy, drzewa decyzyjne okazują się zbyt prostym modelem. Las losowy jest rozwinięciem koncepcji drzew decyzyjnych w zakresie metod zespołowych. Głównym założeniem jest stworzenie wielu drzew decyzyjnych i opieranie końcowego wyniku na podstawie poszczególnych wyników każdego z drzew. W celu wprowadzenia różnorodności podczas konstrukcji węzłów drzew, losowane są cechy spośród których będą dobrane cechy decyzyjne w danym węźle. Metoda ta zazwyczaj daje dużo lepsze efekty niż pojedyncze drzewa decyzyjne, oraz często pomaga w ograniczaniu zjawiska przeuczania (ang. overfitting).  

\subsection{Light GBM \cite{lgbm}}

\textit{Light GBM} jest algorytmem z rodziny \textit{gradient boosting decision trees}. Algorytmy te oparte są o zespół drzew decyzyjnych. W przeciwieństwie do metody \textit{lasu losowego} konstrukcja kolejnych drzew jest wykonywana w sposób sekwencyjny, oraz zależny od wyników poprzednich drzew. Dzięki takiemu zabiegowi, zespół drzew dąży do ulepszenia swoich wyników jako całości. Algorytm \textit{light GBM} przewyższa inne algorytmy ze swojej klasy takie jak \textit{XGBoost} dzięki innemu podejściu do tworzenia drzew. Podczas gdy większość algorytmów powiększa drzewa decyzyjne wgłąb (\textit{level-wise}  rysunek \ref{img:level-wise}), \textit{light GBM} powiększa drzewa decyzyjne ze względu na liście (\textit{leaf-wise} rysunek \ref{img:leaf-wise}). Ten zabieg wraz z innymi optymalizacjami sprawia, że algorytm ten osiąga porównywalne wyniki do innych algorytmów ze swojej klasy, przy dużym skrócenia czasu uczenia się. 


\begin{figure}[H]%
\centering
\subfigure[Konstrukcja drzewa algorytmu \textit{light GBM}]{%
\label{img:level-wise}
\includegraphics[scale=0.46]{img/lgbm-level-wise.png}}%
\qquad
\subfigure[Konstrukcja drzewa algorytmu \textit{light GBM}]{%
\label{img:leaf-wise}
\includegraphics[scale=0.46]{img/lgbm-leaf-wise.png}}%
\caption{Porównanie konstrukcji drzew algorytmów z rodziny \textit{gradient boosting decision trees}}
\label{img:level-leaf-wise}
\end{figure}


\subsection{Wnioski i uwagi}

Predykcja kursu cen na giełdzie jest zagadnieniem zaawansowanym pod względem trudności i złożoności danych. Z tego powodu w tej pracy zastosowane zostały różnorodne modele klasyfikacyjne zgodne z najnowszymi trendami w dziedzinie uczenia maszynowego. Użycie zarówno tradycyjnych modeli sieci neuronowych jak i nowoczesnych technik takich jak algorytm \textit{Light GBM} pozwoliło na obszerne badanie w zakresie poszukiwania najlepszego klasyfikatora.

\newpage

\section{Eksperymenty numeryczne}

W poniższym rozdziale zostały opisane przeprowadzone eksperymenty numeryczne z wykorzystaniem różnych modeli predykcyjnych. Głównym celem tego rozdziału jest taki dobór modelu wraz z jego hiperparametrami, aby zmaksymalizować wybrane miary jakości. Podstawowym założeniem jest nauczanie modelu dla każdej ze spółek osobno (od zera), gdyż mogą one prezentować różną dynamikę i charakterystykę danych. Testy i optymalizacje były wykonyawne dla pojedynczej spółki \textit{GOOGL}, ze względu na ograniczenia mocy obliczeniowej i czasu. Końcowe porównywanie jakości różnych modeli zostało wykonane na podstawie wyników 10 spośród największych spółek z giełdy \textit{NASDAQ}. Wybrane spółki wraz z ich kapitalizacją rynkową zostały przedstawione w tabeli \ref{tab:biggest_companies}.


\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|}
    \hline
        \textbf{Spółka} & \textbf{Kapitalizacja (mld USD)} \\ \hline
        MSFT & 1014.94 \\ \hline 
        AMZN & 920.5 \\ \hline 
        AAPL & 886.81 \\ \hline 
        GOOGL & 754.16 \\ \hline 
        FB & 517.6 \\ \hline 
        CSCO & 234.37 \\ \hline 
        PEP & 186.06 \\ \hline 
        INTC & 206.79 \\ \hline 
        AMGN & 107.4 \\ \hline 
        QCOM & 83.54 \\ \hline 
    \end{tabular}
    \caption{Spółki wykorzystane do oceny jakości nauczonych modeli}
    \label{tab:biggest_companies}
\end{table}

Wszystkie eksperymenty dla każdego zestawu parametrów zostały przeprowadzone 3 razy, a wartości dokładności i AUC zostały uśrednione. Czas uczenia jest czasem wykonania 3 iteracji testu dla danego zestawu parametrów. W rozdziale zawarto jedynie opis optymalizacji parametrów dających najciekawsze wyniki oraz te parametry, których zmiana przyniosła największą poprawę.

\bigskip

Parametrem rozpatrywanym z osobna przy każdym z modeli jest użycie metody \textbf{PCA} do wstępnego przetworzenia danych. W tabeli \ref{tab:pca_component_number} przedstawiona została liczba zmiennych w zależności od wybranej wariancji przy reudukowaniu rozmiaru wektora wejściowego. Jak widać zmniejszenie wariancji o jedną tysięczną pozwala na ograniczenie rozmiaru wejściowych problemów o $\frac{1}{4}$, a zmniejszenie o jedną setną redukuje rozmiar aż o połowę. Nie można jednak z góry, bez testów, przesądzić jak ograniczanie rozmiaru zadania wpłynie na końcowe wyniki. 


\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|}
    \hline
        \textbf{PCA (wariancja)} & \textbf{Liczba zmiennych} \\ \hline
        0.8000 & 4 \\ \hline 
        0.9000 & 8 \\ \hline 
        0.9500 & 12 \\ \hline 
        0.9700 & 16 \\ \hline 
        0.9800 & 18 \\ \hline 
        0.9900 & 23 \\ \hline
        0.9990 & 31 \\ \hline 
        0.9999 & 34 \\ \hline 
        Brak & 41 \\ \hline 
    \end{tabular}
    \caption{Wybrana wartość wariancji, a liczba zmiennych po wykonaniu PCA}
    \label{tab:pca_component_number}
\end{table}

\bigskip

Kolejnym parametrem rozpatrywanym przy każdym modelu jest \textbf{rozmiar zbioru testowego} w kontekście uczenia metodą kroczącą. Domyślnie modele były uczone w jednej iteracji metody kroczącej z wielkością zbioru testowego równej $0.2$ całego zbioru danych. Dzieląc zbiór testowy na mniejsze części, w każdej iteracji włączając już przetestowane próbki danych do zbioru treningowego, potencjalnie powiększany jest zbiór informacji przekazywanych modelom w trakcie uczenia. Taki zabieg jest powinien pozwolić na poprawę wyników i zbliżenie scenariusza testów do rzeczywistego wykorzystywania modelu predykcyjnego do handlu na giełdzie, gdzie model może być regularnie douczany wraz z upływem czasu. Poza maksymalnym rozmiarem zbioru testowego równego $0.2$ całego zbioru danych, wykorzystane zostały rozmiary $360, 180, 90, 45$ oraz $22$. Po każdym powiększeniu zbioru treningowego o nowe próbki modele były uczone od zera, a ich jakość była oceniana na podstawie kolejnej partii zbioru testowego.

\subsection{SVM}

Początkowo do testów SVM wykorzystane zostały domyślne parametry z biblioteki \textit{sklearn} \cite{bib:sklearnsvm}. Analizę optymalizacji maszyn wektorów nośnych należy zacząć od wyboru odpowiedniej funkcji jądra. Tabele \ref{tab:svm_kernel_binary} oraz \ref{tab:svm_kernel_discrete} przedstawiają wyniki klasyfikacji w zależności od wybranej funkcji jądra. W obu przypadkach najlepsza okazała się funkcja liniowa osiągając $\sim 84\%$ dokładności dla klasyfikacji binarnej oraz $\sim 67\%$  dokładności w klasyfikacji na 3 klasy. Jak widać najgorsze wyniki w obu przypadakch osiąga funkcja wielomianowa (\textit{poly}).  W dalszych eksperymentach wykorzystywana była funkcja liniowa.

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        \textbf{Funkcja jądra} & \textbf{Dokładność} & \textbf{AUC} & \textbf{Czas (s)} \\ \hline
linear  &  \textbf{0.848980} &  \textbf{0.849554} &    2.351031 \\ \hline
poly    &  0.530612 &  0.634002 &    2.357999 \\ \hline
rbf     &  0.805442 &  0.808863 &    \textbf{2.145996} \\ \hline
sigmoid &  0.789116 &  0.792252 &    2.246001 \\ \hline
    \end{tabular}
    \caption{SVM: wyniki klasyfikacji binarnej w zależności od wykorzystanej funkcji jądrowej}
    \label{tab:svm_kernel_binary}
\end{table}

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        \textbf{Funkcja jądra} & \textbf{Dokładność} & \textbf{AUC} & \textbf{Czas (s)} \\ \hline
linear  &  \textbf{0.673469} &  \textbf{0.848302} &    2.806034 \\ \hline
poly    &  0.378231 &  0.594664 &    \textbf{2.571024} \\ \hline
rbf     &  0.609524 &  0.838035 &    2.763033 \\ \hline
sigmoid &  0.589116 &  0.811750 &    2.918002 \\ \hline
    \end{tabular}
    \caption{SVM: wyniki klasyfikacji na 3 klasy w zależności od wykorzystanej funkcji jądrowej}
    \label{tab:svm_kernel_discrete}
\end{table}


Kolejnym testem jest porównanie wyników klasyfikacji w zależności od użycia metody PCA. Pomimo znikomej różnicy w wariancji danych znaczne ograniczanie rozmiaru wektora wejściowego nie okazało się korzystne pod względem uzyskanych wyników. W tabelach \ref{tab:svm_pca_binary} oraz \ref{tab:svm_pca_discrete} zostały przedstawione wyniki klasyfikacji w zależności od zachowanej wariancji przy użyciu metody PCA. Do klasyfikacji binarnej została wybrana wariancja $0.9999$, zaś do klasyfikacji 3 klasy nie została użyta metoda PCA.


\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        \textbf{PCA} & \textbf{Dokładność} &  \textbf{AUC} &  \textbf{Czas (s)} \\ \hline
0.95               &  0.687075 &  0.683055 &    3.364004 \\ \hline
0.98               &  0.741497 &  0.735061 &    2.588999 \\ \hline
0.99               &  0.789116 &  0.792865 &    \textbf{2.532526} \\ \hline
0.999             &  \textbf{0.850340} &  0.846990 &    2.603002 \\ \hline
0.9999             &  0.848980 &  0.\textbf{0.849554} &    2.563003 \\ \hline
Brak                &  0.844898 &  0.842308 &    2.942107 \\ \hline
    \end{tabular}
    \caption{SVM: wyniki klasyfikacji binarnej w zależności od wybranej wartości wariancji w metodzie PCA}
    \label{tab:svm_pca_binary}
\end{table}

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        \textbf{PCA} & \textbf{Dokładność} &  \textbf{AUC} &  \textbf{Czas (s)} \\ \hline
0.95               &  0.510204 &  0.705873 &    3.740000 \\ \hline
0.98               &  0.579592 &  0.788663 &    \textbf{3.095082} \\ \hline
0.99               &  0.653061 &  0.832938 &    3.428001 \\ \hline
0.999              &  0.673469 &  0.848779 &    3.283513 \\ \hline
0.9999             &  0.673469 &  0.848351 &    3.398995 \\ \hline
Brak               &  \textbf{0.681633} &  \textbf{0.851243} &    4.757034 \\ \hline
    \end{tabular}
    \caption{SVM: wyniki klasyfikacji na 3 klasy w zależności od wybranej wartości wariancji w metodzie PCA}
    \label{tab:svm_pca_discrete}
\end{table}


Następnym optymalizowanym parametrem był parametr kary \textit{C}. Wpływa on na wielkość marginesu separacji hiperpłaszczyzny od danych. Im większa wartość \textit{C} tym mniejszy margines. Domyślną wartością \textit{C} jest 1. Niestety manipulacja tym parametrem pozwoliła jedynie na poprawę dokładności rzędu $0.003$ dla obu przypadków klasyfikacji (tabela \ref{tab:svm_c_binary} oraz \ref{tab:svm_c_discrete}). Wraz ze zwiększaniem \textit{C} zauważalny jest znaczny wzrost czasu uczenia modelu. Najlepszą wartością \textit{C} dla klasyfikacji binarnej okazało się 10, zaś dla klasyfikacji na 3 klasy wybrana została wartość 25. 


\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        \textbf{C} & \textbf{Dokładność} & \textbf{AUC} & \textbf{Czas (s)} \\ \hline
0.005 &  0.813605 &  0.811315 &    1.714988 \\ \hline
0.01  &  0.827211 &  0.821739 &    1.886997 \\ \hline
0.1   &  0.846259 &  0.846656 &    \textbf{1.653000} \\ \hline
0.5   &  0.848980 &  0.849554 &    1.900010 \\ \hline
1.0   &  0.848980 &  0.849554 &    2.626542 \\ \hline
5.0   &  0.850340 &  \textbf{0.849889} &    6.406000 \\ \hline
10.0  &  \textbf{0.851701} &  0.849721 &   10.317813 \\ \hline
25.0  &  0.848980 &  0.846656 &   20.054430 \\ \hline
50.0  &  0.85034 &  0.848439 &   44.470990 \\ \hline
100.0  &  0.85034 &  0.845541 &   65.944478 \\ \hline
    \end{tabular}
    \caption{SVM: wyniki klasyfikacji binarnej w zależności wykorzystanego parametru C}
    \label{tab:svm_c_binary}
\end{table}


\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        \textbf{C} & \textbf{Dokładność} & \textbf{AUC} & \textbf{Czas (s)} \\ \hline
0.005 &  0.598639 &  0.834132 &    2.763999 \\ \hline
0.01  &  0.638095 &  0.849006 &    2.746000 \\ \hline
0.1   &  0.676190 &  0.858078 &    \textbf{2.491998} \\ \hline
0.5   &  0.677551 &  0.850738 &    2.952996 \\ \hline
1.0   &  0.681633 &  0.851362 &    3.779023 \\ \hline
5.0   &  0.681633 &  0.852015 &    9.155009 \\ \hline
10.0  &  0.680272 &  0.853454 &   16.950008 \\ \hline
25.0  &  \textbf{0.685714} &  \textbf{0.853973} &   33.401029 \\ \hline
50.0  & 0.682993  &  0.853559 &  71.039315  \\ \hline
100.0  &  0.685714 &  0.853622 &  124.964237 \\ \hline
    \end{tabular}
    \caption{SVM: wyniki klasyfikacji na 3 klasy w zależności wykorzystanego parametru C}
    \label{tab:svm_c_discrete}
\end{table}


Na koniec wykonane zostały testy dokładności w zależności od rozmiaru zbioru testowego w kontekście uczenia SVM metodą kroczącą. Z wyników w tabelach \ref{tab:svm_walk_forward_binary} oraz \ref{tab:svm_walk_forward_discrete} można zauważyć iż ta optymalizacja nie polepszyła znacznie wyników. Poprawa w przypadku użycia zbioru testowego o 360 próbkach wyniosła $\sim 1.5\%$ dla obu rodzajów klasyfikacji.


\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        \textbf{Rozmiar zbioru testowego} & \textbf{Dokładność} & \textbf{AUC} & \textbf{Czas (s)} \\ \hline
max                        &  0.851701 &  \textbf{0.849721} &   \textbf{10.317813} \\ \hline
360                         &  \textbf{0.865079} &  0.843043 &   38.907647 \\ \hline
180                        &  0.860159 &  0.841592 &   68.341332 \\ \hline
90                          &  0.852557 &  0.844671 &  115.171602 \\ \hline
45                          &  0.844164 &  0.843217 &  230.034670 \\ \hline
22                          &  0.841243 &  0.840482 &  430.545312 \\ \hline
    \end{tabular}
    \caption{SVM: wyniki klasyfikacji binarnej w zależności od rozmiaru zbioru testowego}
    \label{tab:svm_walk_forward_binary}
\end{table}



\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        \textbf{Rozmiar zbioru testowego} & \textbf{Dokładność} & \textbf{AUC} & \textbf{Czas (s)} \\ \hline
max                        &  0.685714 &  0.853973 &   \textbf{33.401029} \\ \hline
360.0                         &  \textbf{0.699206} &  0.866392 &   112.669902 \\ \hline
180.0                         &  0.688413 &  0.862114 &   183.599683 \\ \hline
90.0                          &  0.691711 &  0.865704 &   332.625968 \\ \hline
45.0                          &  0.685154 &  0.866440 &   649.421637 \\ \hline
22.0                          &  0.683155 &  \textbf{0.868147} &  1618.037420 \\ \hline
    \end{tabular}
    \caption{SVM: wyniki klasyfikacji na 3 klasy w zależności od rozmiaru zbioru testowego}
    \label{tab:svm_walk_forward_discrete}
\end{table}
    
W końcowych testach dla obu rodzajów klasyfikacji został użyty zbiór testowy o 360 próbkach.

\subsection{Sieci neuronowe}

Sieci neuronowe posiadają wiele parametrów, których zmiana może znacznie wpłynąć jakość klasyfikacji. Pierwszym analizowanym parametrem, jest parametr wariancji przy redukcji rozmiaru problemu metodą PCA. Wyniki testów klasyfikacji binarnej dla różnych progów wariancji, zostały przedstawione w tabeli \ref{tab:nn_pca_binary}.  Najlepszy wynik $\sim 85\%$ został uzyskany przy braku przetworzenia danych metodą PCA, jednak  wykorzystując PCA z wariancją 0.9999 lub 0.999 uzyskany został bardzo podobny wynik.

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        \textbf{PCA} & \textbf{Dokładność} &  \textbf{AUC} &  \textbf{Czas (s)} \\ \hline
0.97               &  0.702948 &  0.748728 &   15.459319 \\ \hline
0.98               &  0.745125 &  0.821377 &   \textbf{12.693174} \\ \hline
0.99               &  0.795918 &  0.877171 &   15.743771 \\ \hline
0.999           &  0.854875 &  \textbf{0.919237} &   14.903868 \\ \hline
0.9999             &  0.852608 &  0.918613 &   13.461666 \\ \hline
Brak                &  \textbf{0.854875} &  0.918459 &   21.490562 \\ \hline

    \end{tabular}
    \caption{MLP: wyniki klasyfikacji binarnej w zależności od wybranej wartości wariancji}
    \label{tab:nn_pca_binary}
\end{table}

Na wykresach \ref{img:nn_pca_binary_vs_accuracy} została przedstawiona dokładność w zależności od czasu uczenia sieci neuronowych (wyrażona w epokach). Można zauważyć iż używając PCA model jest w stanie dużo szybciej osiągnąć wartości dokładności bliskie jego maksimum. Co za tym idzie używając metody PCA sieć neuronowa dużo szybciej zbiega do minimum funcji celu. Sieć bez użycia PCA osiąga minimum funkcji celu w czasie 40 epok, zaś używająć PCA z wariancją 0.999 satysfakcjonujący wynik jest osiągany już po 5 epokach. Wynika to zapewne z ograniczenia rozmiaru danych wejściowych oraz z przekształcenia układu współrzędnych w sposób maksymalizujący wariancję danych. Wraz ze zmniejszaniem liczby danych wejściowych widać stopniowe pogarszanie wyników oraz wzrost różnicy pomiędzy wynikami zbioru treningowego, a zbioru testowego co jest sygnałem, że dochodzi do przeuczenia.


\begin{figure}[H]%
\centering
\subfigure[Brak PCA]{%
\includegraphics[scale=0.4685]{img/nn_pca_none_binary_acc_googl.pdf}}%
\qquad
\subfigure[PCA wariancja 0.999]{%
\includegraphics[scale=0.4685]{img/nn_pca_0999_binary_acc_googl.pdf}}%
\qquad
\subfigure[PCA wariancja 0.99]{%
\includegraphics[scale=0.4685]{img/nn_pca_099_binary_acc_googl.pdf}}%
\qquad
\subfigure[PCA wariancja 0.97]{%
\includegraphics[scale=0.4685]{img/nn_pca_097_binary_acc_googl.pdf}}%

\caption{Wykresy zależności dokładności od redukcji danych metodą PCA dla klasyfikacji binarnej (opracowanie własne)}
\label{img:nn_pca_binary_vs_accuracy}
\end{figure}

Takie same testy zostały przeprowadzone dla klasyfikacji na 3 klasy. Wyniki zostały zaprezentowane w tabeli \ref{tab:nn_pca_discrete}. Najlepsze wyniki zostały uzyskane wówczas gdy dane zostały przetworzone metodą PCA z parametrem wariancji $0.9999$. Dodatkowym atutem takiej konfiguracji jest przyspieszenie czasu nauki modelu oraz poprawa stabilności wyników. 

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        \textbf{PCA} & \textbf{Dokładność} &  \textbf{AUC} &  \textbf{Czas (s)} \\ \hline
0.97               &  0.545125 &  0.723263 &   21.973598 \\ \hline
0.98               &  0.607256 &  0.789558 &   \textbf{21.367600} \\ \hline
0.99               &  0.663946 &  0.829368 &   22.170482 \\ \hline
0.999               &  0.679365 &  \textbf{0.855526} &   24.234406 \\ \hline
0.9999             &  \textbf{0.684086} &  0.854986 &   26.053283 \\ \hline
Brak                &  0.682889 &  0.853353 &   39.720696 \\ \hline
    \end{tabular}
    \caption{MLP: wyniki klasyfikacji na 3 klasy w zależności od wybranej wartości wariancji}
    \label{tab:nn_pca_discrete}
\end{table}

Przy następnych testach dla obu rodzajów klasyfikacji dane były redukowane metodą PCA z parametrem wariancji $0.9999$. 

\bigskip

Następnym parametrem zbadanym podczas uczenia sieci jest liczba warstw ukrytych wraz z liczbą neuronów w każdej z warstw. Dla uproszczenia eksperymentów liczba warstw ukrytych w sieci neuronowej została ograniczona do wartości \{0, 1, 2\}, zaś liczba neuronów w każdej z warstw była taka sama. Wyniki mierzone miarą AUC dla klasyfikacji binarnej zostały przedstawione w tabeli \ref{tab:nn_layers_binary}. Dla tego rodzaju klasyfikacji najlepszym modelem okazał się model sieci neuronowej złożony jedynie z warstwy wejściowej oraz warstwy wyjściowej. Uzyskał on wynik \textbf{0.919} AUC i $\sim 85\%$ dokładności. Model bez warstwy ukrytej w przypadku klasyfikacji binarnej okazuje się najlepszy najprawdopodobniej ze względu na pojedynczy neuron w warstwie wyjściowej. Taka uproszczona architektura pozwala na znalezienie odpowiednich zależności w danych bez dodawania warstw ukrytych. Wyniki wydają się być odwrotnie proporcjonalne do liczby użytych neuronów, lecz nie odbiegają znacznie od najlepszego wyniku.

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|}
        \hline
         & &  \multicolumn{10}{c|}{Liczba neuronów w każdej warstwie}  \\ \hline
        \multirow{4}{*}{Warstwy} & & 0 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10  \\ \cline{2 - 12}
			& 0 & \textbf{0.919} & - & - & - & - & - & - & - & - & - \\ \cline{2 - 12} 
			& 1 & - &  0.919 &  0.918 &  0.916 &  0.907 &  0.917 &  0.915 &  0.915 &  0.915  & 0.917 \\ \cline{2 - 12} 
			& 2 & - & 0.909 &    0.910 &   0.908 &   0.911 &   0.917 &   0.908 &   0.905 &   0.914 & 0.915 \\ \cline{2 - 12} \hline

    \end{tabular}
    \caption{MLP: wartości miary AUC dla różnych konfiguracji warstw ukrytych i liczby neuronów dla klasyfikacji binarnej (wyniki zaokrąglone)}
    \label{tab:nn_layers_binary}
\end{table}

Analogicznie do klasyfikacji binarnej został przeprowadzony test dla klasyfikacji na 3 klasy, wyniki przedstawiono w tabeli \ref{tab:nn_layers_discrete}. Najlepszy wynik \textbf{0.858} AUC ($\sim 68\%$ dokładności) został osiągnięty przy użyciu jednej warstwy ukrytej o 10 neuronach. W odróżnieniu do klasyfikacji binarnej, warstwa wyjściowa posiada 3 neurony, a co za tym idzie, potrzebna jest bardziej skomplikowana architektura sieci do uzyskania optymalnego wyniku. Zauważyć można również iż wykorzystanie wielu warstw ukrytych o małej liczbie neuronów znacznie pogarsza wynik co jest spowodowane zbyt małą liczbą połączeń między kolejnymi warstwami by zachować zależności między danymi.

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|}
        \hline
         & &  \multicolumn{10}{c|}{Liczba neuronów w każdej warstwie}  \\ \hline
        \multirow{4}{*}{Warstwy} & & 0 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10  \\ \cline{2 - 12}
			& 0 & 0.832 & - & - & - & - & - & - & - & - & - \\ \cline{2 - 12} 
			& 1 & - &  0.817 &  0.825 &  0.845 &  0.844 &  0.856 &  0.854 &  0.857 &  0.857 & \textbf{0.858} \\ \cline{2 - 12} 
			& 2 & - & 0.808 &   0.819 &   0.847 &   0.846 &   0.843 &   0.849 &   0.854 &   0.856 &   0.851  \\ \cline{2 - 12} \hline

    \end{tabular}
    \caption{MLP: wartości miary AUC dla różnych konfiguracji warstw ukrytych i liczby neuronów dla klasyfikacji na 3 klasy (wyniki zaokrąglone)}
    \label{tab:nn_layers_discrete}
\end{table}

W kolejnych testach do klasyfikacji binarnej nie zostały użyte warstwy ukrytne, zaś do klasyfikacji na 3 klasy była wykorzystywana jedna warstwa ukryta z 10 neuronami.

\bigskip

Kolejnym analizowanym parametrem był rozmiar zbioru testowego wykorzystywanego w każdej iteracji uczenia modelu metodą kroczącą. Tabela \ref{tab:nn_walk_forward_test_binary} przedstawia wyniki dla różnych rozmiarów zbioru testowego. Najlepszy wynik dla klasyfikacji binarnej został osiągnięty przy 360 próbkach w zbiorze testowym. Dzięki tak prostemu zabiegowi dokładność modelu ulepszyła się o $\sim 3\%$. Niestety wraz ze zmniejszaniem zbioru testowego znacząco zwiększa się czas uczenia. 

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        \textbf{Rozmiar zbioru testowego} & \textbf{Dokładność} &  \textbf{AUC} &  \textbf{Czas (s)} \\ \hline 
max                           &  0.855781 &  \textbf{0.919433} &   \textbf{17.971821} \\  \hline
360                         &  \textbf{0.888757} &  0.918279 &   64.217482 \\  \hline
180                         &  0.878307 &  0.917263 &  148.310481 \\  \hline
90                          &  0.876426 &  0.915586 &  297.019231 \\ \hline
45                          &  0.877280 &  0.910868 &   405.719231 \\ \hline
22                          &  0.880905 &  0.904669 &  1163.856892 \\ \hline
    \end{tabular}
    \caption{MLP: wyniki klasyfikacji binarnej w zależności od rozmiaru zbioru testowego}
    \label{tab:nn_walk_forward_test_binary}
\end{table}

W tabeli \ref{tab:nn_walk_forward_test_discrete} przestawione zostały analogiczne wyniki dla klasyfikacji na 3 klasy. Jak widać dla bardziej złożonego zagadnienia klasyfikacji zmniejszanie zbioru testowego jest bardzo korzystne. Wynik dokładności wzrósł aż o $\sim 10\%$ dla zbioru testowego o 22 próbkach. Dalsze zmniejszanie zbioru jest jednak problematyczne ze względu na rosnący czas obliczeń.

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        \textbf{Rozmiar zbioru testowego} & \textbf{Dokładność} &  \textbf{AUC} &  \textbf{Czas (s)} \\ \hline
max    &  0.682993 &  0.857121 &  \textbf{38.663478} \\ \hline
360     &  0.731041 &  0.866818 &  54.312463 \\ \hline
180   &  0.730847 &  0.867762 &  127.654863 \\ \hline
90   &  0.740388 &  0.869632 &  316.48475 \\ \hline
45     &  0.760286 &  0.873949 &  1146.761132 \\ \hline
22  &  \textbf{0.787767} &  \textbf{0.882507} &  3229.764589 \\ \hline
    \end{tabular}
    \caption{MLP: wyniki klasyfikacji na 3 klasy w zależności od rozmiaru zbioru testowego}
    \label{tab:nn_walk_forward_test_discrete}
\end{table}

Ostatecznie dla klasyfikacji binarnej zostały użyte zbiory testowe z 360 próbkami, zaś dla klasyfikacji trójklasowej zbiory z 22 próbkami.



\subsection{Random forest}

Testy lasów losowych rozpoczęte zostały od analizy przetworzenia danych metodą PCA. Najlepsze wyniki klasyfikacji zostały uzyskane przy wybraniu wariancji o wartości $0.9999$ (tabele \ref{tab:rf_pca_binary} oraz \ref{tab:rf_pca_discrete}). Dla klasyfikacji binarnej osiągnięty został wynik $\sim 78\%$, zaś dla klasyfikacji wieloklasowej  $\sim 58\%$.

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        \textbf{PCA} & \textbf{Dokładność} & \textbf{AUC} & \textbf{Czas (s)} \\ \hline
0.95               &  0.650340 &  0.652564 &    \textbf{1.084675} \\ \hline
0.98               &  0.735147 &  0.734262 &    1.515345 \\ \hline
0.99               &  0.752834 &  0.753326 &    1.626672 \\ \hline
0.999 &  0.772789 &  0.772018 &    1.704345 \\ \hline
0.9999             &  \textbf{0.777778} &  \textbf{0.777053} &    1.710322 \\ \hline
Brak                &  0.753741 &  0.754849 &    2.229286 \\ \hline
    \end{tabular}
    \caption{Random forest: wyniki klasyfikacji binarnej w zależności od wybranej wartości wariancji w metodzie PCA}
    \label{tab:rf_pca_binary}
\end{table}
\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        \textbf{PCA} & \textbf{Dokładność} & \textbf{AUC} & \textbf{Czas (s)} \\ \hline
0.95               &  0.487075 &  0.677503 &    \textbf{1.226344} \\ \hline
0.98               &  0.547846 &  0.742437 &    1.437373 \\ \hline
0.99               &  0.568254 &  0.758338 &    1.406685 \\ \hline
0.999 &  0.570068 &  0.765132 &    1.711658 \\ \hline
0.9999             &  \textbf{0.576417} &  \textbf{0.767606} &    1.747348 \\ \hline
Brak                &  0.567347 &  0.768452 &    2.043028 \\ \hline
    \end{tabular}
    \caption{Random forest: wyniki klasyfikacji na 3 klasy w zależności od wybranej wartości wariancji w metodzie PCA}
    \label{tab:rf_pca_discrete}
\end{table}

Podstawowym parametrem przy używaniu modelu lasu losowego jest dobór odpowiedniej liczby drzew, tworzących las. W poprzednich testach ten parametr miał wartość 150. Im więcej drzew tym bardziej wydłuża się czas obliczeń, jednak zwiększa się liczba elementów biorących udział w predykcji co potencjalnie może polepszać wyniki klasyfikacji. Tabele \ref{tab:rf_estimators_binary} oraz \ref{tab:rf_estimators_discrete} przedstawiają wyniki klasyfikacji w zależności od liczby drzew w lesie. Niestety dobór większej liczby drzew tylko nieznacznie poprawia otrzymywane wyniki, jednocześnie znacznie wydłużając czas obliczeń. Dla obu typów klasyfikacji najlepszy wynik uzyskał las liczący 1500 drzew.

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        \textbf{Liczba drzew} & \textbf{Dokładność} & \textbf{AUC} & \textbf{Czas (s)} \\ \hline
100        &  0.779138 &  0.778948 &    \textbf{1.254666} \\ \hline
200        &  0.781859 &  0.781289 &    2.391548 \\ \hline
300        &  0.786395 &  0.785786 &    3.506159 \\ \hline
500       &  0.779138 &  0.778837 &    5.656016 \\ \hline
1000       &  0.782313 &  0.781438 &   10.835435 \\ \hline
1500      &  \textbf{0.787755} &  \textbf{0.787179} &   16.527833 \\ \hline
2000       &  0.782766 &  0.782144 &   21.734268 \\ \hline
    \end{tabular}
    \caption{Random forest: wyniki klasyfikacji binarnej w zależności od liczby utworzonych drzew}
    \label{tab:rf_estimators_binary}
\end{table}

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        \textbf{Liczba drzew} & \textbf{Dokładność} & \textbf{AUC} & \textbf{Czas (s)} \\ \hline
100        &  0.553851 &  0.763649 &    \textbf{1.228010} \\ \hline
200        &  0.574150 &  0.767209 &    2.428561 \\ \hline
300        &  0.574150 &  0.768572 &    3.478281 \\ \hline
500        &  0.585395 &  0.774938 &    5.866535 \\ \hline
1000       &  0.584127 &  0.775766 &   11.639547 \\ \hline
1500       &  \textbf{0.585988} &  \textbf{0.778329} &   15.834652 \\ \hline
2000      &  0.585441 &  0.776137 &   20.285341 \\ \hline
    \end{tabular}
    \caption{Random forest: wyniki klasyfikacji na 3 klasy w zależności od liczby utworzonych drzew}
    \label{tab:rf_estimators_discrete}
\end{table}

Ostatnim przeanalizowanym parametrem podobnie jak dla poprzednich modeli jest rozmiar zbioru testowego dla uczenia metodą kroczącą. W przeciwieństwie do poprzednich modeli metoda lasu losowego nie wykazuje poprawy podczas iteracyjnej ewaluacji modelu (tabele \ref{tab:rf_walk_forward_binary} oraz \ref{tab:rf_walk_forward_discrete}). Najlepsze wyniki są uzyskane przy jednokrotnym uczeniu oraz ewaluacji modelu, co oznacza że lasy losowe nie są w stanie przyswoić nowych informacji ponad te zawarte w podstawowym zbiorze treningowym. Wobec tego dla tego modelu nie była stosowana ewaluacja metodą kroczącą.

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        \textbf{Rozmiar zbioru testowego} & \textbf{Dokładność} & \textbf{AUC} & \textbf{Czas (s)} \\ \hline
max                         &  \textbf{0.787755} &  \textbf{0.787179} &  \textbf{16.527833} \\ \hline
360                         &  0.753131 &  0.759844 &   65.553659 \\ \hline        
180                         &  0.749894 &  0.756907 &  105.710007 \\ \hline
90                          &  0.755908 &  0.758301 &  180.461685 \\ \hline
45                          &  0.753906 &  0.754997 &  336.741707 \\ \hline
22                          &  0.751783 &  0.755511 &  716.216814 \\ \hline
    \end{tabular}
    \caption{Random forest: wyniki klasyfikacji binarnej w zależności od rozmiaru zbioru testowego}
    \label{tab:rf_walk_forward_binary}
\end{table}

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        \textbf{Rozmiar zbioru testowego} & \textbf{Dokładność} & \textbf{AUC} & \textbf{Czas (s)} \\ \hline
max                         &  \textbf{0.585988} &  0.778329 &  \textbf{15.834652} \\ \hline
360                         &  0.556173 &  0.779862 &   67.133358 \\ \hline
180                         &  0.570370 &  0.786893 &  121.863561 \\ \hline
90                         &  0.569959 &  \textbf{0.788930} &  223.579185 \\ \hline
45                          &  0.574946 &  0.787879 &  443.906251 \\ \hline
22                          &  0.573864 &  0.787886 &  834.891297 \\ \hline
    \end{tabular}
    \caption{Random forest: wyniki klasyfikacji na 3 klasy w zależności od rozmiaru zbioru testowego}
    \label{tab:rf_walk_forward_discrete}
\end{table}

\subsection{Light GBM}

Podobnie jak w przypadku poprzednich modeli dla Light GBM analizowana była zależność jakości klasyfikacji od redukcji rozmiaru danych metodą PCA. Wyniki tej analizy zostały przedstawione w tabelach \ref{tab:lgbm_pca_binary} oraz \ref{tab:lgbm_pca_discrete}. W odróżnieniu od innych klasyfikatorów używanie PCA nawet z zachowaniem największej wartości wariancji powoduje znaczny spadek jakości klasyfikacji. Dzieje się tak zarówno dla klasyfikacji binarnej jak i klasyfikacji wieloklasowej, aczkolwiek dla tej drugiej jest to duż obardziej widoczne. Bez użycia PCA osiągane są  wyniki dokładności $\sim 82\%$ dla klasyfikacji binarnej oraz $\sim 64\%$ dla klasyfikacji na 3 klasy.

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        \textbf{PCA} & \textbf{Dokładność} & \textbf{AUC} & \textbf{Czas (s)} \\ \hline
0.9                &  0.617687 &  0.658673 &    \textbf{0.112996} \\ \hline
0.99               &  0.760544 &  0.845203 &    0.355000 \\ \hline
0.999    &  0.791837 &  0.877228 &    0.765001 \\ \hline
0.9999             &  0.802721 &  0.879168 &    0.903005 \\ \hline
Brak                &  \textbf{0.824490} &  \textbf{0.910806} &    0.632995 \\ \hline
    \end{tabular}
    \caption{Light GBM: wyniki klasyfikacji binarnej w zależności od wybranej wartości wariancji w metodzie PCA}
    \label{tab:lgbm_pca_binary}
\end{table}

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        \textbf{PCA} & \textbf{Dokładność} & \textbf{AUC} & \textbf{Czas (s)} \\ \hline
0.9                &  0.438095 &  0.587427 &    \textbf{0.247017} \\  \hline
0.99               &  0.570068 &  0.757724 &    0.899004 \\ \hline
0.999 &  0.579592 &  0.765829 &    1.133001 \\ \hline
0.9999             &  0.571429 &  0.765824 &    1.166996 \\ \hline
Brak                &  \textbf{0.646259} &  \textbf{0.820201} &    1.241000 \\ \hline
    \end{tabular}
    \caption{Light GBM: wyniki klasyfikacji na 3 klasy w zależności od wybranej wartości wariancji w metodzie PCA}
    \label{tab:lgbm_pca_discrete}
\end{table}

Kolejnym parametrem, który może zostać wykorzystany do optymalizacji modelu Light GBM jest procent cech wykorzystanych do utworzenia każdego z drzew. Na przykład jeżeli ustawimy ten parametr na $0.5$ każde drzewo będzie utworzone biorąc pod uwagę tylko połowę kolumn z wektora wejściowego. Cechy są wybierane losowo w momencie tworzenia kolejnego drzewa z lasu. Domyślnie ten parametr został ustawiony na $0.8$. Wyniki tego eksperymentu przedstawione są w tabelach \ref{tab:lgbm_feature_fraction_binary} oraz \ref{tab:lgbm_feature_fraction_discrete}. W przypadku obu klasyfikacji najbardziej korzystne wyniki daje wykorzystanie całego wektora danych przy tworzeniu każdego z drzew. Zmiana tego parametru pozwoliła na poprawienie miary dokładności o $\sim 1\%$ w obu przypadkach klasyfikacji.

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        \textbf{Procent cech} & \textbf{Dokładność} & \textbf{AUC} & \textbf{Czas (s)} \\ \hline
20              &  0.745578 &  0.832768 &    0.661063 \\ \hline
30              &  0.785034 &  0.884036 &    \textbf{0.391003} \\ \hline
40              &  0.806803 &  0.889521 &    0.710010 \\ \hline
50             &  0.809524 &  0.897808 &    1.246994 \\ \hline
60              &  0.821769 &  0.910041 &    1.367518 \\ \hline
70              &  0.813605 &  0.905641 &    5.311466 \\ \hline
80              &  0.824490 &  0.910806 &    1.581059 \\ \hline
90              &  0.813605 &  0.910754 &    2.108266 \\ \hline
100              &  \textbf{0.831293} &  \textbf{0.911758} &    1.717000 \\ \hline
    \end{tabular}
    \caption{Light GBM: wyniki klasyfikacji binarnej w zależności od procenta cech wykorzystanych do tworzenia pojedynczego drzewa}
    \label{tab:lgbm_feature_fraction_binary}
\end{table}

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        \textbf{Procent cech} & \textbf{Dokładność} & \textbf{AUC} & \textbf{Czas (s)} \\ \hline
20          &  0.541497 &  0.698834 &    \textbf{0.589999} \\ \hline
30              &  0.606803 &  0.775659 &    1.528000 \\ \hline
40              &  0.602721 &  0.780493 &    0.855000 \\ \hline
50              &  0.625850 &  0.796584 &    1.453674 \\ \hline
60              &  0.648980 &  0.821857 &    3.013062 \\ \hline
70              &  0.640816 &  0.819061 &    2.339054 \\ \hline
80              &  0.646259 &  0.820201 &    3.221801 \\ \hline
90              &  0.648980 &  0.821506 &    2.187508 \\ \hline
100              &  \textbf{0.654422} &  \textbf{0.831571} &    1.666998 \\ \hline
    \end{tabular}
    \caption{Light GBM: wyniki klasyfikacji na 3 klasy w zależności od procenta cech wykorzystanych do tworzenia pojedynczego drzewa}
    \label{tab:lgbm_feature_fraction_discrete}
\end{table}

Metoda Light GBM daje możliwość wyboru używanej metody \textit{boostingu}. Domyślnym algorytmem jest \textit{boosting} drzew decyzyjnych (\textit{gbdt}). W tabelach \ref{tab:lgbm_boosting_binary} oraz \ref{tab:lgbm_boosting_discrete} zostały przedstawione wyniki użycia różnych metod \textit{boostingu}. Jak widać dla klasyfikacji binarnej domyślny parametr \textit{gbdt} okazuje się najlepszym. Dla klasyfikacji wieloklasowej lepszy wynik daje metoda \textit{dart} \cite{lightbgm:dart}, poprawiając wynik dokładności o $\sim 1\%$.

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        \textbf{Boosting} & \textbf{Dokładność} & \textbf{AUC} & \textbf{Czas (s)} \\ \hline
dart     &  0.817687 &  0.906808 &    2.796990 \\ \hline
gbdt     &  \textbf{0.834014} &  \textbf{0.911832} &    \textbf{1.173999} \\ \hline
gbrt     &  0.834014 &  0.911832 &    1.244001 \\ \hline
goss     &  0.797279 &  0.902891 &    0.748003 \\ \hline
    \end{tabular}
    \caption{Light GBM: wyniki klasyfikacji binarnej w zależności od wybranego rodzaju boostingu}
    \label{tab:lgbm_boosting_binary}
\end{table}

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        \textbf{Boosting} & \textbf{Dokładność} & \textbf{AUC} & \textbf{Czas (s)} \\ \hline
dart     &  \textbf{0.663946} &  \textbf{0.835296} &    7.743999 \\ \hline
gbdt     &  0.654422 &  0.831571 &    1.947000 \\ \hline
gbrt     &  0.654422 &  0.831571 &    1.154999 \\ \hline
goss     &  0.646259 &  0.810499 &    \textbf{1.321007} \\ \hline
    \end{tabular}
    \caption{Light GBM: wyniki klasyfikacji na 3 klasy w zależności od wybranego rodzaju boostingu}
    \label{tab:lgbm_boosting_discrete}
\end{table}

Ostatnim badanym parametrem jest rozmiar zbioru testowego wykorzystanego podczas uczenia metodą kroczącą. Wyniki badania zostały przedstawione w tabelach \ref{tab:lgbm_walk_forward_binary} oraz \ref{tab:lgbm_walk_forward_discrete}. Dla modelu Light GBM widać znaczną poprawę w klasyfikacji przy używaniu zbioru testowego o 360 próbkach. Dla klasyfikacji binarnej nastąpiła poprawa dokładności o $\sim 3\%$, zaś dla klasyfikacji na 3 klasy wynik poprawił się aż o $\sim 6\%$. Dalsze zmniejszanie zbioru testowego pogarszało wyniki wbrew oczekiwaniom.

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        \textbf{Rozmiar zbioru testowego} & \textbf{Dokładność} & \textbf{AUC} & \textbf{Czas (s)} \\ \hline
max    &  0.834014 &  0.911832 &  \textbf{1.173999} \\ \hline
360                         &  \textbf{0.867857} &  0.915407 &   1.874000 \\ \hline
180                         &  0.855714 &  \textbf{0.918232} &    5.498513 \\ \hline
90                         &  0.837743 &  0.915601 &    6.347999 \\ \hline
45                          &  0.837628 &  0.914706 &   11.757001 \\ \hline
22                          &  0.847594 &  0.921981 &   23.754002 \\ \hline
    \end{tabular}
    \caption{Light GBM: wyniki klasyfikacji binarnej w zależności od rozmiaru zbioru testowego}
    \label{tab:lgbm_walk_forward_binary}
\end{table}


\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        \textbf{Rozmiar zbioru testowego} & \textbf{Dokładność} & \textbf{AUC} & \textbf{Czas (s)} \\ \hline
max   						 &  0.663946 &  0.835296 &  \textbf{7.743999} \\ \hline
360                         &  \textbf{0.727381} &  0.831340 &   26.352005 \\ \hline
180                         &  0.700317 &  \textbf{0.832342} &   45.234971 \\ \hline
90                          &  0.680423 &  0.833708 &   75.542997 \\ \hline
45                          &  0.681793 &  0.837955 &  137.898603 \\ \hline
22                          &  0.665441 &  0.834180 &  398.519057 \\ \hline
    \end{tabular}
    \caption{Light GBM: wyniki klasyfikacji na 3 klasy w zależności od rozmiaru zbioru testowego}
    \label{tab:lgbm_walk_forward_discrete}
\end{table}


\subsection{Podsumowanie i wnioski}

Końcowe wyniki \textbf{klasyfikacji binarnej} dla każdego z klasyfikatorów zostały oparte o testy przeprowadzone na 10 spółkach. Wyniki dokładności dla każdej ze spółek zostały zawarte w tabeli \ref{tab:comparison_final_binary}. Dodatkowo podane zostały uśrednione wyniki dokładności i AUC dla każdego z modeli. 

 \begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|c|}
    \hline
        \textbf{Spółka} & \textbf{SVM} &  \textbf{MLP}  &  \textbf{Random forest}  &  \textbf{Light GBM} \\ \hline
AAPL   &  0.807656 & \textbf{0.823688}  & 0.740741 & 0.811402\\ \hline
AMGN   &  0.799253 &  \textbf{0.826799} &0.772487 &  0.819947 \\ \hline
AMZN   &  0.773109 & 0.811963 & 0.634609 & \textbf{0.820503} \\ \hline
CSCO   &  0.815126 &  \textbf{0.819011} & 0.814815 &  0.811429 \\ \hline
FB     &  0.825215 & \textbf{0.836207} & 0.714422 & 0.801724 \\ \hline
GOOGL  &  0.851701 &  \textbf{0.885767} & 0.787302 & 0.859524 \\ \hline
INTC   &  0.829132 & \textbf{0.837402}  & 0.791783 & 0.829101 \\ \hline
MSFT   &  0.800187 &   \textbf{0.826206} & 0.767818 &  0.798307\\ \hline
PEP    &  0.827586 & \textbf{0.843401}  & 0.765455 & 0.830135 \\ \hline
QCOM   &  0.835668 &  \textbf{0.836926} & 0.808901 & 0.815132 \\ \hline \hline
\textbf{Średnia dokładność} &  0.816463 & \textbf{0.834737} & 0.759833 & 0.81972 \\  \hline  
\textbf{Średnia AUC} &  0.815958 & \textbf{0.904259} & 0.761041 & 0.901649 \\  \hline
    \end{tabular}
    \caption{Końcowe wyniki dokładności dla klasyfikacji binarnej różnych spółek}
    \label{tab:comparison_final_binary}
\end{table}   

Najlepszy średni wynik uzyskał model sieci neuronowej z dokładnością $\sim 83.4\%$ oraz AUC $\sim 0.904$ . Drugi najlepszy wynik osiągnął model Light GBM z  $\sim 82\%$ dokładności i $\sim 0.902$ AUC. Model SVM uzyskał zbliżoną do dwóch poprzednich modeli dokładność $\sim 81.6\%$ jednak ze znacznie gorszym polem pod krzywą ROC $\sim 0.816$. Najgorszym modelem okazał się las losowy uzyskując jedyne $\sim 76\%$ dokładności oraz $\sim 0.76$ AUC.

\bigskip

Model sieci neuronowej okazał się najlepszy dla niemal wszystkich spółek.  Jedynym wyjątkiem okazała się spółka Amazon.com Inc. (\textit{AMZN}) gdzie lepszy wynik został osiągnięty przez model Light GBM. Na rysunku \ref{img:amzn_googl_adjusted_comparison} zostało przedstawione porównanie zmian ceny zamknięcia spółki \textit{AMZN} ze spółką \textit{GOOGL}, dla której został uzyskany najlepszy wynik $\sim 88.5\%$ dokładności. To porównanie pozwala dostrzec dynamiczny wzrost ceny spółki \textit{AMZN} począwszy od 2015 roku. Zauważyć można również spadek ceny \textit{AMZN} o prawie 35\% pod koniec 2018 roku, podczas gdy ten sam okres dla spółki \textit{GOOGL} przyniosł spadek rzędu 20\%. Oba te czynniki wskazują na wysoką wariancję ceny spółki \textit{AMZN} co jest sprzężone z większą losowością ruchów cen akcji, a to utrudnia przewidywanie ceny. Można przypuszczać, iż model Light GBM uzyskał lepszy wynik dla klasyfikacji binarnej ze względu na większą odporność na dużą wariancję danych. 


\begin{figure}[H]
\centering \includegraphics[scale=1]{img/AMZN_GOOGL_close_comparison.pdf}
\caption{Porównanie wykresów ceny zamknięcia spółek \textit{GOOGL} i \textit{AMZN} (opracowanie własne)}
\label{img:amzn_googl_adjusted_comparison}
\end{figure}



\bigskip

Dla \textbf{klasyfikacji na 3 klasy} zostały wykonane analogiczne testy dla 10 spółek. Wyniki zostały przedstawione w tabeli \ref{tab:comparison_final_discrete}. Tutaj bez wyjątku, najlepsze wyniki dla każdej spółki uzyskała sieć neuronowa ze średnim wynikiem dokładności $\sim 78.2\%$ oraz $\sim 0.875$ AUC. Pozostałe klasyfikatory otrzymały wyniki: 
\begin{itemize}
\item SVM: $\sim 67.2\%$ dokładności oraz $\sim 0.844$ AUC,
\item random forest: $\sim 59.8\%$ dokładności oraz $\sim 0.784$ AUC,
\item Light GBM: $\sim 66.4\%$ dokładności oraz $\sim 0.83$ AUC.
\end{itemize}  

 \begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|c|}
    \hline
        \textbf{Spółka} & \textbf{SVM} &  \textbf{MLP}  &  \textbf{Random forest}  &  \textbf{Light GBM} \\ \hline
AAPL   &  0.667600 & \textbf{0.779353}  & 0.607221 & 0.650688 \\ \hline
AMGN   &  0.687208 &  \textbf{0.793533} & 0.610644 &  0.649841 \\ \hline
AMZN   &  0.616246 & \textbf{0.758636} & 0.510115  & 0.660079 \\ \hline
CSCO   &  0.676004 &  \textbf{0.776217} & 0.619359 &  0.632989 \\ \hline
FB     &  0.624642 & \textbf{0.740004} & 0.543457 & 0.678161 \\ \hline
GOOGL  &  0.685714 &  \textbf{0.789327} & 0.589116 & 0.729233 \\ \hline
INTC   &  0.719888 & \textbf{0.812174}  & 0.641768 & 0.668836 \\ \hline
MSFT   &  0.680672 &   \textbf{0.785449} & 0.604108 &  0.636958 \\ \hline
PEP    &  0.683131 & \textbf{0.807127}  & 0.610127 & 0.670854 \\ \hline
QCOM   &  0.683473 &  \textbf{0.777542} & 0.641457 & 0.661878 \\ \hline \hline
\textbf{Średnia dokładność} &  0.672458 & \textbf{0.781936} & 0.597737 & 0.663952 \\  \hline  
\textbf{Średnia AUC} &  0.843943 & \textbf{0.874600} & 0.783574 & 0.830858 \\  \hline
    \end{tabular}
    \caption{Końcowe wyniki dokładności dla klasyfikacji na 3 klasy różnych spółek}
    \label{tab:comparison_final_discrete}
\end{table}   

Najlepszy wynik udało się osiągnąć dla spółki \textit{INTC} $\sim 81.2\%$, zaś najgorszy dla spółki \textit{FB}  $\sim 74\%$. Słaby wynik dla spółki \textit{FB} może być spowodowany kilkoma czynnikami. Po pierwsze spółka zapoczątkowała swoją obecność na giełdzie stosunkowo niedawno, w 2012 roku, a jej historia ukazuje dynamiczne zmiany ceny (rysunek \ref{img:fb_adj_close}). Po drugie na rysunku \ref{img:fb_hist} przedstawiony został histogram liczby próbek w każdej z klas, na którym widać mocną dysproporcję między klasami. Klasa utrzymania ceny jest najmniej liczna wobec czego najciężej będzie ją przewidzieć. Powyższe czynniki mogą mieć negatywny wpływ na przewidywanie ruchów giełdowych.


\begin{figure}[H]%
\centering
\subfigure[Wykres ceny zamknięcia]{%
\includegraphics[scale=0.46]{img/FB_adj_close.pdf}
\label{img:fb_adj_close}}%
\qquad
\subfigure[Histogram liczby próbek w każdej klasie zbioru danych]{%
\includegraphics[scale=0.46]{img/FB_discrete_hist.pdf}
\label{img:fb_hist}}%

\caption{Wykresy przedstawiające dane dotyczące spółki \textit{FB} (opracowanie własne)}
\label{img:fb_data_description}
\end{figure}


\bigskip

Dodatkowo przeprowadzona została analiza klasyfikacji konkretnych klas. Na wykresie \ref{img:nn_roc_auc_discrete} zostały przedstawione krzywe ROC dla 3 klas, wraz z ich mikro-średnią, dla sieci neuronowej o jednej warstwie ukrytej z 10 neuronami. Analizując wykres łatwo zauważyć dysproporcję pomiędzy AUC poszczególnych klas. Model ma największą trudność z przewidywaniem klasy utrzymania ceny, która ma aż o $0.14$ AUC mniej niż pozostałe klasy. Taka rozbieżność może być problematyczna na etapie używania nauczonego modelu do predykcji. Im większa rozbieżność między AUC poszczególnych klas tym gorzej. Może się bowiem okazać iż dwa modele o porównywalnej mierze AUC będą uzyskiwały rozbieżne wyniki w grze na giełdzie. Mogłoby to wynikać z faktu iż model w ogóle nie zwraca w swoich przewidywaniach jednej z klas, zaś pozostałe estymuje bardzo dobrze. Na przykład model nie wskazujący nigdy klasy spadku, nie dawałby sygnału do sprzedaży akcji, a to całkowicie wyklucza jego praktyczne użycie. 

\begin{figure}[H]
\centering \includegraphics[scale=0.8]{img/nn_layers_10_discrete_roc-googl.pdf}
\caption{Wykres ROC sieci neuronowej o jednej warstwie neuronowej z 10 neuronami dla klasyfikacji na 3 klasy spółki \textit{GOOGL} (opracowanie własne)}
\label{img:nn_roc_auc_discrete}
\end{figure}



\section{Wspomaganie decyzji giełdowych}

Mając do wykorzystania klasyfikatory o wybranych parametrach można przystąpić do weryfikacji ich skuteczności na giełdzie. Ocena jakości odbyła się poprzez symulację uproszczonego modelu giełdy. Głównym założeniem było dokonywanie transakcji jedynie na początku sesji giełdowej tj. po cenie otwarcia. Taki scenariusz odzwierciedla wykonanie predykcji klasyfikayorem na podstawie danych z sesji giełdowej z dnia \textit{t} oraz podjęcie decyzji w najbliższym możliwym czasie tj. przy rozpoczęciu sesji w dniu \textit{t+1}. Jako zbiór treningowy dla każdej spółki wykorzystane zostały wszystkie dane od początku jej istnienia aż do 31 grudnia 2018. Symulacja giełdowa została przeprowadzona na danych od 1 stycznia 2019, aż do 6 lipca 2019. W tym okresie przeprowadzono 127 sesji giełdowych. Symulacja uwzględniała prowizję od każdej transakcji na poziomie 0.2\% jej wartości. Każda spółka była testowana osobno. Budżet dla każdej spółki wynosił \textit{100~000} dolarów.

\bigskip

Algorytm dokonujący transakcji opiera się na analizie kolejnych sesji giełdowych ze zbioru testowego. Jeżeli klasifikator przewiduje wzrost ceny, algorytm kupuje maksymalną możliwą liczbę akcji (musi to być liczba naturalna więc budżet nie zawsze jest całkowicie wykorzystany). Jeżeli algorytm jest w posiadaniu papierów wartościowych, a klasyfikator daje sygnał utrzymania ceny lub wzrostu, algorytm pozostaje bezczynny. Jeżeli algorytm jest w posiadaniu papierów wartościowych, a klasyfikator daje sygnał spadku ceny, algorytm wyprzedaje wszystkie posiadane akcje. Ostatnim krokiem algorytmu jest monetyzacja wszelkich zakupionych akcji w ostatniej sesji ze zbioru testowego w celu oszacowania zysków.

\bigskip

Do porównania uzyskanych wyników zastosowana była technika \textit{buy and hold}, która polega na kupieniu akcji odpowiednich spółek i pozostanie biernym na wahania rynku do czasu spieniężenia akcji.  Ta metoda jest preferowaną formą inwestowania analityków fundamentalnych, którzy często twierdzą iż niemożliwym jest wypracowanie ponadprzeciętnych zysków w oparciu o analizę techniczną i predykcję trendów. Innym wskaźnikiem stosowanym do oceniania wyników aktywnego grania na giełdzie jest indeks giełdowy, który jest odwzorowaniem średniej zmiany wartości dla konkretnej grupy spółek. Inwestowanie w fundusze inwestycyjne oparte o indeksy giełdowe często jest uznawane za wygodną alternatywę do handlu na konkretnych akcjach, gdyż odzwierciedla szeroki rynek i nie wymaga dogłębnej analizy spółek.  Odpowiednim indeksem giełdowym do wybranych w tej pracy spółek jest \textit{S\&P 500} zawierającym 500 przedsiębiorstw o największej kapitalizacji notowanych na giełdach \textit{NYSE} oraz \textit{NASDAQ}. W okresie od 1 stycznia 2019 do 6 lipca 2019 indeks \textit{S\&P 500} zanotował wzrost o \textbf{18.45}\%.

\bigskip

Wyniki dla metody \textit{buy and hold} oraz klasyfikatorów binarnych zostały opisane w tabeli \ref{tab:comparison_simulation_binary}. Jak widać wyniki są pewnym odzwierciedleniem porównania modeli pod względem dokładności klasyfikacji (tabela \ref{tab:comparison_final_binary}). Najlepszy średni wynik na poziomie \textbf{148}\% uzsykał model sieci neuronowej, troche gorsze wyniki uzyskał model SVM oraz Light GBM około 141\%, zaś najgorszy wynik wypracował las losowy 136\%. Niezależnie od wybranego modelu średnio udało się uzyskać dużo lepsze wyniki od strategii \textit{buy and hold} (124\%) czy też indeksu giełdowego (118\%). Strategia \textit{buy and hold} dla niektórych modeli i spółek okazała się lepsza, jednak nie była to zazwyczaj duża różnica. Największą korzyść z wykorzystywania klasyfikatorów do handlu na giełdzie widać przy spółkach, które uzyskały najgorsze wyniki przy strategii \textit{buy and hold}. Dla spółki \textit{AMGN} odniesiona została strata na poziomie 3\% kapitału, jednak wykorzystanie dowolnego modelu pozwala na ograniczenie ryzyka i wypracowanie zadowalającego zysku. W żadnym przypadku użycia klasyfikatorów nie została odnotowana strata kapitału, co jest bardzo istotnym czynnikiem przy szacowaniu ryzyka wynikającego z automatyzacji handlu.

 \begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|}
    \hline
        \textbf{Spółka}  & \textbf{Buy and hold} & \textbf{SVM} &  \textbf{MLP}  &  \textbf{Random forest}  &  \textbf{Light GBM} \\ \hline
AAPL & 140.61 & 148.31  &  \textbf{153.67} & 136.91 & 143.21\\ \hline
AMGN & 97.23 &  125.81 & \textbf{133.44}  & 119.42 &  127.09 \\ \hline
AMZN & 126.58 &  139.00 & \textbf{147.15} & 115.36 & 135.98 \\ \hline
CSCO & 131.31 & 149.18  & 144.76  & \textbf{154.39} &  143.15 \\ \hline
FB   & 143.52 & 164.96  & \textbf{177.34} & 149.97 & 159.19 \\ \hline
GOOGL & 105.97 &  133.85 &  140.69 & 120.45 & \textbf{141.03} \\ \hline
INTC & 103.98 & 124.35  & 130.99  & \textbf{138.33} & 131.97 \\ \hline
MSFT &  136.12 & \textbf{147.06}  &  144.46  & 141.61 & 133.76 \\ \hline
PEP  & 121.60 &  118.67 &  \textbf{123.37} & 117.12 & 118.67 \\ \hline
QCOM & 137.18 &  166.75 &  \textbf{184.64} & 169.69 & 177.81  \\ \hline \hline
\textbf{Średni zysk} & 124.41 & 141.79 & \textbf{148.05} &  136.32 & 141.19 \\  \hline  
    \end{tabular}
    \caption{Uzyskany zysk wyrażony w procentach początkowego budżetu (100 oznacza budżet wejściowy), wyniki symulacji dla klasyfikacji binarnej.}
    \label{tab:comparison_simulation_binary}
\end{table}   

Analogiczne wyniki dla metody \textit{buy and hold} oraz klasyfikatorów wieloklasowych zostały opisane w tabeli \ref{tab:comparison_simulation_discrete}. Dla tego rodzaju klasyfikacji wyniki symulacji giełdy różnią się od wyników dokładności (tabela \ref{tab:comparison_final_discrete}). Model SVM okazał się lepszy w handlu od sieci neuronowej pomimo różnicy w szacowaniu dokładności aż o 11\%.  W przypadku SVM, lasu losowego oraz metody Light GBM średni wynik, w stosunku do symulacji dla klasyfikacji binarnej, poprawił się o kilka procent. Gorszy wynik wykazał jedynie model sieci neuronowej jednak dał on mimo wszystko bardzo satysfakcjonujący zysk.

 \begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|}
    \hline
        \textbf{Spółka}  & \textbf{Buy and hold} & \textbf{SVM} &  \textbf{MLP}  &  \textbf{Random forest}  &  \textbf{Light GBM} \\ \hline
AAPL & 140.61 & 148.26  & \textbf{151.58}  & 139.66 & 140.42 \\ \hline
AMGN & 97.23 & 124.28  &  \textbf{137.08} & 121.94 &  131.88 \\ \hline
AMZN & 126.58 &  143.37 & 131.96 & 122.90 & \textbf{148.86} \\ \hline
CSCO & 131.31 & 152.57  & \textbf{163.61}  & 159.67 & 148.83  \\ \hline
FB   & 143.52 &  169.41 & 153.14 & 144.98 & \textbf{185.99} \\ \hline
GOOGL & 105.97 &  \textbf{136.04} & 130.46  & 121.23 & 134.14 \\ \hline
INTC & 103.98 & 136.13  & \textbf{137.33}  & 126.85 & 131.09 \\ \hline
MSFT &  136.12 & \textbf{151.86}  &  140.73  & 147.55 & 136.44 \\ \hline
PEP  & 121.60 &  123.50 & 121.51  & 118.71 & \textbf{124.08} \\ \hline
QCOM & 137.18 &  \textbf{199.61} & 189.39  & 179.87 & 189.19 \\ \hline \hline
\textbf{Średni zysk} & 124.41 & \textbf{148.5} & 145.68 & 138.34 & 147.09 \\  \hline  
    \end{tabular}
    \caption{Uzyskany zysk wyrażony w procentach początkowego budżetu (100 oznacza budżet wejściowy), wyniki symulacji dla klasyfikacji na 3 klasy.}
    \label{tab:comparison_simulation_discrete}
\end{table}   

W symulacjach handlu na giełdzie z pomocą klasyfikatorów widać zależność końcowych wyników od wyników dokładności jednak ta zależność nie jest bezpośrednia. Dla lasów losowych wyniki dokładności oraz wyniki gry na giełdzie były dużo gorsze od pozostałych modeli. Jednak gdy wyniki dokładności nie są zauważalnie gorsze ciężko jednoznacznie określić jak dany model poradzi sobie na giełdzie. 

\bigskip

Analizę symulacji można pogłębić o wgląd w decyzje algorytmu. Rysunek \ref{img:amgn_wallet_buy_sell} przedstawia decyzje dokonywane przez algorytm używający klasyfikatora wieloklasowego w zestawieniu z rzeczywistą ceną zamknięcia z każdego dnia. Na czerwono oznaczone są okresy gdy klasyfikator przewidywał spadek lub utrzymanie ceny, a w portfelu znajdowała się gotówka. Na zielono oznaczone zostały okresy gdy klasyfikator przewidywał wzrost lub utrzymanie ceny, a w portfelu znajdowały się akcje spółki \textit{AMGN}. Łatwo dostrzec, że klasyfikator ma największą skuteczność w momentach gwałtownych spadków lub wzrostów ceny. W przypadku delikatnych zmian, algorytm zazwyczaj nie zmienia strategii co jest oczekiwanym zachowaniem wynikającym z klasyfikacji zmian ceny do klasy \textit{utrzymanie}. Takie zachowanie algorytmu pozwala na uzyskiwanie ponadprzeciętnych zysków. 

\begin{figure}[H]
\centering \includegraphics[scale=1.1]{img/AMGN-buy_and_sell_plot.pdf}
\caption{Wykres ceny akcji spółki \textit{AMGN} w zestawieniu z portfelem zarządzany przez algorytm używający wieloklasowego klasyfikatora MLP (opracowanie własne)}
\label{img:amgn_wallet_buy_sell}
\end{figure}

Wartość portfela w czasie została przedstawiona na rysunku \ref{img:amgn_wallet_value}. Zestawienie wartości portfela zarządzanego przez algorytm z użyciem klasyfikatora z wartością portfela strategii \textit{buy and hold} pokazuje wyższość poprawnej predykcji nad biernym udziałem w giełdzie. Gdy giełda odnotowuje spadki wartość portfela klasyfikatora utrzymuje się, zaś gdy ceny akcji rosną algorytm poprawnie inwestuje zarabiając pieniądze. Jakość klasyfikacji nie jest na poziomie 100\% wobec czego algorytm wykonuje błędne decyzje (maj 2019 na rysunku \ref{img:amgn_wallet_value}), jednak w porównaniu do poprawnych ruchów są one marginalne.

\begin{figure}[H]
\centering \includegraphics[scale=0.9]{img/AMGN-balance-plot.pdf}
\caption{Wykres wartości portfela algorytmu handlującego akcjami spółki \textit{AMGN} używającego wieloklasowego klasyfikatora MLP (opracowanie własne)}
\label{img:amgn_wallet_value}
\end{figure}

Faktem, który warto odnotować jest niewątpliwa wyższość klasyfikacji na 3 klasy nad klasyfikacją binarną w grze na giełdzie. Średni zysk dla handlu na podstawie klasyfikacji wieloklasowej był większy o ponad \textbf{3}\% od zysku algorytmu używającego klasyfikacji binarnej. Taka różnica wydaje się być niewielka, lecz na dłuższą metę, dzięki ponownemu inwestowaniu zyskaego kapitału, będzie ona rosła wykładniczo. W ekonomii to zjawisko nosi miano procenta składanego. Analizując przewagę predykcji wieloklasowej warto zwrócić uwagę na krzywe ROC poszczególnych klas na rysunku  \ref{img:nn_roc_auc_discrete}. Przedstawione wartości \textit{AUC} dla każdej z klas dowodzą iż ten model lepiej przewiduje spadek (\textit{AUC} 0.92) i wzrost (\textit{AUC} 0.89) ceny ponad uzgodniony próg niż klasyfikator binarny (\textit{AUC} 0.88 tabela \ref{tab:comparison_final_binary}). Ponadto klasyfikator przewidujący klasę utrzymania pozwala na bardziej powściągliwe decyzje o kupnie bądź monetyzacji akcji, a jak wiadomo każda transakcja obarczona jest kosztem prowizji domu maklerskiego. Predykcja klasy utrzymania uzyskuje znacznie gorsze wyniki (\textit{AUC} 0.75 rysunek \ref{img:nn_roc_auc_discrete}), jednak najwidoczniej nie ma to dużego znaczenia na wykorzystywanie klasyfikatorów w grze na giełdzie. Tabela \ref{tab:simulation_avg_value_vs_transactions} zestawia średnie uzyskane zyski na giełdzie poszczególnych klasyfikatorów wraz z liczbą decyzji o zamianie instrumentu finansowego w portfelu inwestycyjnym. Porównanie zysków i liczby transakcji dla konkretnych modeli nie pozwala na wysnucie jednoznacznych wniosków. Perspektywa średniej liczby transakcji dla modeli klasyfikacji binarnej i klasyfikacji wieloklasowej ukazuje ujemną korelację między zyskiem, a liczbą transakcji.

 \begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|}
    \hline
        \textbf{Model}  & \textbf{Średni zysk} & \textbf{Średnia liczba transakcji}\\ \hline
            SVM binarny & 141.79 & 61.4 \\ \hline
            MLP binarny & 148.05 & 60.2 \\ \hline
            Random forest binarny & 136.32 & 57.2 \\ \hline
            Light GBM binarny & 141.19 & 63.2 \\ \hline 
            \textbf{Średnia modeli binarnych} & \textbf{141.84} & \textbf{60.5} \\ \hline \hline
            
            SVM wieloklasowy & 148.5 & 39.6 \\ \hline
            MLP wieloklasowy & 145.68 & 45.6 \\ \hline
            Random forest wieloklasowy & 138.34 & 48.0 \\ \hline
            Light GBM wieloklasowy & 147.09 & 51.5 \\ \hline
            \textbf{Średnia modeli wieloklasowych} & \textbf{144.9} & \textbf{46.17} \\ \hline
    \end{tabular}
    \caption{Porównanie średniego zysku z aktywnością danego modelu na giełdzie}
    \label{tab:simulation_avg_value_vs_transactions}
\end{table} 

 Modele klasyfikujące na 3 klasy wykonały średnio o 14 transakcji mniej niż klasyfikatory binarne (miesięcznie jest to średnio aż o 2.3 transakcji mniej). Takie zachowanie pozwoliło ograniczyć koszty prowizji domu maklerskiego, a dzięki temu zwiększyć zysk.

\section{Podsumowanie}

W pracy przedstawione zostały różnorodne dane mogące posłużyć do analiz cen giełdowych, oraz różne podejścia do problemu przewidywania zmian cen akcji na giełdzie. Wykonane eksperymenty klasyfikacji demonstrują możliwości predykcji zmian cen na giełdzie jedynie z wykorzystaniem podstawowych danych giełdowych oraz wskaźników analizy technicznej. Oba przedstawione problemy klasyfikacji uzyskały nad wyraz satysfakcjonujące wyniki przy użyciu różnorodnych metod uczenia maszynowego. Najlepsze wyniki uzyskał model sieci neuronowej oraz model maszyny wektorów nośnych.

\bigskip

Symulacje z użyciem algorytmu opartego o nauczone klasyfikatory dały doskonałe wyniki w grze na giełdzie. W większości przypadków uzyskiwany zysk znacznie przekroczył wzrost indeksu \textit{S\&P 500} oraz strategię \textit{buy and hold}. Takie rezultaty analiz daje podstawę do rozważenia użycia wbranych modeli w handlu na prawdziwym rynku papierów wartościowych. Jednakowoż wyniki symulacji użycia klasyfikatorów w handlu, pomimo bardzo obiecujących wyników, oparte zostały o uproszczony model giełdy. Przy prawdziwych transakcjach trzeba brać pod uwagę \textit{spread} ceny czyli różnicę między ceną kupna, a ceną sprzedaży danej akcji. Handlując dużą liczbą akcji, istotną rolę odgrywa podaż i popyt. Fakt iż algorytm w danym momencie sugeruje sprzedaż jakiejś liczby akcji po danej cenie, nie oznacza że znajdzie się na nie kupiec. Co za tym idzie cena sprzedaży może zostać obniżona przez konkurencyjną ofertę. Należy mieć na uwadze do jakiego stopnia opłaca się obniżać cenę przy zamiarze sprzedaży akcji oraz analogicznie wyznaczyć maksymalną cenę za jaką jesteśmy w stanie kupić akcje.  Dodatkowo w Polsce przy zyskach z gry na giełdzie trzeba pamiętać o podatku od dochodów kapitałowych (potocznie nazywany podatkiem Belki). Ze względu na symplifikację w kodzie źródłowym, wszystkie operacje zostały oparte o typy zmiennoprzecinkowe co oznacza utratę precyzji przy wykorzystywaniu ułamków, z tego powodu wszelkie wyniki w tej pracy należy traktować jako zaokrąglenia. Ta aproksymacja nie ma żadnych implikacji jeśli chodzi o meritum prezentowane w tej pracy, jednak z perspektywy automatycznych systemów do gry na giełdzie takie uproszczenie jest nieakceptowalne. Powyższe argumenty mają na celu podkreślenie iż wykorzystanie modeli z tej pracy na prawdziwej giełdzie, należy traktować zgodnie z regułą ograniczonego zaufania, analizując decyzje podejmowane przez algorytm.

\bigskip

Kierunki dalszych potencjalnych badań uwzględniają:
\begin{itemize}
	\item rozszerzenie algorytmu o klasyczne narzędzia wykorzystywane przy inwestowanie na giełdzie takie jak \textit{stop loss},
	\item rozszerzenie algorytmu o analizę i ograniczenie ryzyka,
	\item rozszerzenie algorytmu o dobór spółek gwarantujących jak największe zyski,
	\item stworzenie automatycznego systemu do handlu na giełdzie połączonego z API domu maklerskiego,
	\item dalszy rozwój i ulepszanie klasyfikatorów.
\end{itemize}


\section{Bibliografia}


\begin{thebibliography}{9}
  
 \bibitem{nyse}
Strona główna NYSE
\\\url{https://www.nyse.com}
 
 \bibitem{nasdaq}
Strona główna NASDAQ
\\\url{https://www.nasdaq.com/}

 \bibitem{jpx}
Strona główna JPX
\\\url{https://www.jpx.co.jp/english/}

\bibitem{fundamentalanalysis}
  John C. Ritchie,
  \textit{Analiza fundamentalna}.
  Wig-Press,
  1997.
  
  \bibitem{berkeshire}
Strona główna Berkeshire Hathaway
\\\url{http://www.berkshirehathaway.com/}

\bibitem{technicalanalysis}
  John J. Murphy,
  \textit{Analiza techniczna rynków finansowych}.
  Maklerska.pl,
  2017.

 \bibitem{alphavantage}
Strona główna Alpha Vantage
\\\url{https://www.alphavantage.co/}

\bibitem{randwalk}
  Burton G. Malkiel,
  \textit{Random Walk Down Wall Street: The Time-Tested Strategy for Successful Investing}.
  W. W. Norton Company,
  2007.

\bibitem{efficientmarket}
  Eugene Fama,
  \textit{"Efficient Capital Markets: A Review of Theory and Empirical Work}
  Journal of Finance. 25:2, pp. 383-417, 1970.

\bibitem{pythonmachinelearning}
  John Hearty
  \textit{Advanced Machine Learning with Python}.
  Packt Publishing,
  2016.

\bibitem{roc}
	Tom Fawcett, 
  \textit{An introduction to ROC analysis.}
  Pattern Recognition Letters 27,
  2005.

\bibitem{roccurves}
	ROC, \url{https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5} 
	Data dostępu: 15.02.2019

\bibitem{hmeasure}
	David J. Hand, 
  \textit{Measuring classifier performance: a coherent alternative to the area under the ROC curve}
  Machine Learning, 77:103–123, 2009.

\bibitem{roccritique}
	David J. Hand, 
  \textit{Evaluating diagnostic tests: the area under the ROC curve and the balance of errors.}
 Statistics in Medicine, 29:1502–1510, 2010

\bibitem{brier}
	Glenn W. Brier, 
  \textit{Verification of Forecasts Expressed in Terms of Probability}
  Monthly Weather Review, 78:1–3, 1950

\bibitem{train_test_split}
 Podział danych testowych \url{https://medium.com/@rinu.gour123/train-and-test-set-in-python-machine-learning-how-to-split-58029a0d657b}
 Data dostępu: 30.05.2019
 
 
\bibitem{train_test_split_time_series}
 Podział danych testowych metodą kroczącą \url{https://robjhyndman.com/hyndsight/tscv/}
 Data dostępu: 30.05.2019
 
\bibitem{svm}
	Bell, Jason, \textit{Machine Learning : Hands-On for Developers and Technical Professionals}  Indianapolis, IN, USA: John Wiley \& Sons, 2015. 139-160. Web.
	
\bibitem{wikisvm}
	SVM, \url{https://en.wikipedia.org/wiki/Support-vector_machine} 
	Data dostępu: 03.03.2019

\bibitem{neural-nets}
	Bell, Jason, \textit{Machine Learning : Hands-On for Developers and Technical Professionals}  Indianapolis, IN, USA: John Wiley \& Sons, 2015. 91-116. Web.


\bibitem{mlp}
	Angel Kuri-Morales, 
  \textit{Closed determination of the number of neurons in the hidden layer of a multi-layered perceptron network}
  Soft Computing, 21:597–609, 2017

\bibitem{mlpnn}
	Artificial neural network, \url{http://www.saedsayad.com/artificial_neural_network_bkp.htm} 
	Data dostępu: 04.03.2019

\bibitem{randforest}
	Breiman, L, 
  \textit{Random forests}
	MACHINE LEARNING  Volume: 45   Issue: 1   Pages: 5-32   Published: OCT 2001


\bibitem{wikidecisiontree}
	Decision tree learning, \url{https://www.wikiwand.com/en/Decision_tree_learning} 
	Data dostępu: 06.04.2019


\bibitem{lgbm}
Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang,Wei Chen, Weidong Ma, Qiwei Ye, Tie-Yan Liu
  \textit{LightGBM: A Highly Efficient Gradient Boosting Decision Tree}
	MACHINE LEARNING  Volume: 45   Issue: 1   Pages: 5-32   Published: OCT 2001

\bibitem{wikidecisiontree}
	Decision tree learning, \url{https://www.wikiwand.com/en/Decision_tree_learning} 
	Data dostępu: 06.04.2019

\bibitem{bib:sklearnsvm}
	Sklearn SVM, \url{https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC}
	Data dostępu: 23.06.2019

\bibitem{lightgbm:dart}
	K. V. Rashmi, Ran Gilad-Bachrach
	\textit{DART: Dropouts meet Multiple Additive Regression Trees}
	CoRR Volume: abs/1505.01866 \url{http://arxiv.org/abs/1505.01866} Published: AUG 2018

\end{thebibliography}

\listoffigures
 
\listoftables

\section{Dodatek: opis aplikacji}

\subsection{Technologie}

\subsection{Pobranie danych}

\subsection{Wykonanie testów klasyfikacj}

\subsection{Wykonanie testów klasyfikacj}

\end{document}