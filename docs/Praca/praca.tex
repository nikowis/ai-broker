\documentclass[a4paper, twoside, 11pt, openright]{article}
\usepackage[utf8]{inputenc}
\usepackage{polski}
\usepackage{float}
\usepackage[T1]{fontenc}

\usepackage{url}
\usepackage{longtable}
\usepackage{a4wide}
\raggedbottom
\usepackage{tabularx, booktabs}

\usepackage[left=3.0cm, right=2.0cm, top=2.5cm, bottom=2.5cm]{geometry}


% PERSONAL data about the thesis
\newcommand{\myTitle}{Metodyka porównania algorytmów prognozy do wspomagania decyzji giełdowych}
\newcommand{\myName}{Nikodem Wiśniewski}
\newcommand{\myNumber}{260907}
\newcommand{\myThesisType}{Praca dyplomowa magisterska}
\newcommand{\myCourse}{Informatyka}
\newcommand{\myProf}{dr hab. inż. Jerzy Balicki, profesor PW}
\newcommand{\myFaculty}{Wydział Matematyki i Nauk Informacyjnych}
\newcommand{\myUni}{Politechnika Warszawska}
\newcommand{\myLocation}{Warszawa}
\newcommand{\myYear}{2019}
\newcommand{\myKeywords}{}
\newcommand{\myKeywordsPL}{}



% DOCUMENT settings


\usepackage{graphicx}
\usepackage{multirow}
\usepackage{indentfirst}
\usepackage{wrapfig}
\usepackage[font=footnotesize, % equivalent to 9 pt font
			labelfont=bf, 
			justification=justified, 
			singlelinecheck=false]{caption} 
%\usepackage[justification=centering]{subcaption} % two images side by side captions
\usepackage{tabularx, booktabs} % pretty LaTeX tables
\usepackage{siunitx} % units SI e.g. \SI{10}{\kilogram\per\meter\square}
\usepackage{mathtools} % amsmath, symbols such as brackets, arrows, equation numbering only for referrenced eqs.
%\usepackage[parfill]{parskip} % spacing between paragraphs instead of indent
%\parfillskip 0pt plus 0.75\textwidth % get rid of widows at the end of paragraphs
\frenchspacing % for "Polish" spaces after the sentence
\usepackage{polski} % Polish rules of hyphenation
\usepackage{dashrule} % for dotted lines in declarations page
\usepackage{emptypage} % removes headers on empty pages
\usepackage{fancyhdr} % header and footer settings
\usepackage{subfigure}
\usepackage{cleveref}


\pagestyle{fancy}
\fancyhf{}
\newcommand{\fncyfront}{%
	\fancyhead[RO]{}
	\fancyfoot[RO]{}
	\fancyhead[LE]{}
	\fancyfoot[LE]{}
	\fancyhead[RE,LO]{}
	\fancyfoot[C]{}
	\renewcommand{\headrulewidth}{0pt}}
\newcommand{\fncymain}{%
	\fancyhead[RO]{{\footnotesize \rightmark}}
	\fancyfoot[RO]{\thepage}
	\fancyhead[LE]{{\footnotesize \leftmark}}
	\fancyfoot[LE]{\thepage}
	\fancyfoot[C]{}
	\renewcommand{\headrulewidth}{0.3pt}}
	
\renewcommand*{\tablename}{Tabela} 
	
\newcolumntype{P}[1]{>{\centering\arraybackslash}p{#1}}
\newcolumntype{M}[1]{>{\centering\arraybackslash}m{#1}}



% FONT settings
\usepackage[T1]{fontenc}

%\renewcommand{\familydefault}{\sfdefault} % change font to sans serif
\usepackage{amsfonts} % mathematical fonts
\usepackage{inconsolata} % monospaced font in urls and \texttt
%\usepackage{url}
%\urlstyle{same}

% DEBUG
\usepackage{lipsum}
\usepackage{etoolbox} % removes page number in table of contents
\patchcmd{\chapter}{plain}{empty}{}{}


\begin{document}
\fncyfront
%*******************************************************
% Titlepage
%*******************************************************
\begin{titlepage}
\begingroup
\begin{center}		
			\includegraphics[width=1.0\textwidth]{img/pw_header}
			
			\vspace{1.0cm}
			\fontsize{24}{30}\selectfont\myThesisType
			\fontsize{12}{14}\selectfont
			
			\vspace{0.5cm}
			na kierunku \myCourse \\
			\vspace{1cm}
			{\fontsize{14}{18}\selectfont \myTitle} \\ 
			
			\vspace{1.5cm}
			\fontsize{21}{25}\selectfont \myName \\
			\fontsize{12}{14}\selectfont
			Numer albumu \myNumber \\

			\vspace{6.5cm}
			promotor \\
			\myProf \\
			\vspace{0.5cm}
			\vfill 
			Warszawa, \myYear
        \vfill                      
\end{center}
\endgroup
\end{titlepage}

\cleardoublepage

\begingroup
\fontsize{12pt}{14.4pt}\selectfont


\begin{abstract}
	Głównym celem pracy było opracowanie oraz porównanie modeli predykcyjnych pomagających w podejmowaniu decyzji maklerowi giełdowemu.

\bigskip

	\noindent \textbf{Słowa kluczowe:} giełda, predykcja, klasyfikacja, sieci neuronowe
\end{abstract}

\cleardoublepage


\hfill
\begin{table}[b]
\centering
\begin{tabular}[t]{ccc}
............................................. & \hspace*{100pt} & .............................................\\
podpis promotora & \hspace*{100pt} & podpis autora
\end{tabular}
\end{table}

\fncymain



\cleardoublepage

\tableofcontents

\cleardoublepage

\section{Modele prognozy na giełdzie oraz kryteria ich oceny}

Celem tej pracy jest opracowanie, ocena i porównanie różnych modeli predykcji cen akcji na giełdzie papierów wartościowych.

\subsection{Charakterystyka giełdy}

Giełda z definicji jest miejscem wymiany towarów przez sprzedawców i kupców. Giełdy można podzielić na giełdy towarowe, pieniężne lub usługowe. Wymiany na tradycyjnych giełdach przebiegają przede wszystkim podczas sesji, które są organizowane w określonych dniach i godzinach. Najpopularniejszym rodzajem giełd są giełdy pieniężne, a w szczególności giełdy papierów wartościowych. Największymi giełdami papierów wartościowych są \textit{NYSE (New York Stock Exchange)}\cite{nyse}, \textit{NASDAQ}\cite{nasdaq} oraz \textit{JPX (Japan Exchange Group)}\cite{jpx}. Na każdej z tych giełd w dniach, w których prowadzone są sesje, dochodzi do transakcji opiewających na łączną kwotę rzędu miliardów dolarów amerykańskich.

\bigskip

 Jednym z wymienianych na giełdzie towarów są akcje różnorodnych spółek. Każda spółka, która jest obecna na giełdzie ma przypisany do siebie symbol giełdowy (\textit{ticker}). Symbol giełdowy jest skrótowym kodem do identyfikowania spółek na określonej giełdzie (przykładowe symbole: \textit{GOOGL}, \textit{MSFT}, \textit{AMZN}). Podczas każdej sesji dokonywane są transakcje milionów akcji, których cena regulowana jest przez wolny rynek. Wynikiem tego jest duża zmienność cen i nieprzewidywalność akcji. Jest ona spowodowana między innymi: spekulacjami inwestorów, upublicznianiem informacji o konkretnej spółce (np. raportów finansowych) lub wydarzeniami na arenie politycznej (np. ustawy wpływające na działalność spólek z konkretnego sektora).

\subsection{Dane giełdowe}

Istnieje wiele rodzajów danych, które są w większym lub mniejszym stopniu powiązane z giełdą papierów wartościowych. Zbiór informacji, które można wykorzystywać w przewidywaniu cen akcji jest bardzo szeroki, począwszy od cech bezpośrednio opisujących akcje na giełdzie, przez dane opisujące finansową sytuację spółek emitujących akcje, wskaźniki będące statystycznym odzwierciedleniem zmian cen na giełdzie, aż po dane alternatywne takie jak sentyment powiązany z wiadomościami na temat spółek oraz giełdy.

\subsubsection{Dane podstawowe}

Podstawowymi (dziennymi) danymi wynikającymi bezpośrednio z funkcjonowania giełdy są:

\begin{itemize}
\item{Data}
\item{Cena zamknięcia} - cena akcji pod koniec dnia
\item{Cena otwarcia} - cena akcji na początku dnia
\item{Liczba akcji w obrocie danego dnia}
\item{Najniższa cena akcji danego dnia}
\item{Najwyższa cena akcji danego dnia}
\end{itemize}

 Przy korzystaniu z wartości cen akcji należy również uwzględnić podział akcji(tak zwany \textit{split}). Gdy jakaś spółka decyduje się na podział swoich akcji oznacza to, że każda z akcji dzieli się na dwie akcje o cenie wynoszącej połowę pierwotnej ceny. Taki zabieg pozwala na zmniejszenie ceny pojedynczej akcji dzięki czemu może stać się ona dostępna dla większej liczby inwestorów. 
 
\bigskip

Powyższe dane nie wnoszą jednak zbyt wiele informacji ponieważ są odzwierciedleniem powstałego obrotu akcji na giełdzie, a nie jego przyczyną. W związku z dużą losowością ruchów giełdowych, są niewystarczające aby skutecznie przewidzieć zmiany cen akcji. Zawodowi maklerzy do podejmowania swoich decyzji wspomagają się dodatkowo dwoma technikami: \textbf{analizą fundamentalną} oraz \textbf{analizą techniczną}.

\subsubsection{Analiza fundamentalna \cite{fundamentalanalysis}}

Analiza fundamentalna spółek jest analizą kondycji ekonomicznej spółek w zestawieniu z wartością ich akcji. Ten rodzaj analizy ma odpowiedzieć na pytanie czy cena akcji konkretnej spółki odpowiada jej sytuacji na rynku. Przy takim badaniu spółki brane jest pod uwagę wiele różnych czynników, takich jak:
\begin{itemize}
\item{analiza finansowa spółki}
\item{analiza sektorowa}
\item{analiza makroekonomiczna}
\item{analiza ogólnej sytuacji spółki}
\end{itemize}

Ten rodzaj badania spółek jest niezwykle czasochłonny i często wymaga eksperckiej wiedzy w dziedzinie finansów. Dodatkowo analiza fundamentalna wymaga posiadania danych, publicznych aczkolwiek czasami ciężko dostępnych, o spółkach i sektorach, w których się znajdują. Analizę fundamentalną stosuje się w szczególności przy inwestycjach długoterminowych (np. kilka miesięcy).

Najsłynniejszym analitykiem technicznym świata jest \textit{Warren Buffet} prezes amerykańskiego holdingu \textit{Berkshire Hathaway \cite{berkeshire}}. 

\subsubsection{Analiza techniczna \cite{technicalanalysis}}

Analiza techniczna jest zbiorem technik mających na celu wspomaganie inwestora w podejmowaniu decyzji na podstawie historycznych danych giełdowych. Analiza ta bada zachowania rynku oraz poszukuje trendów np. poprzez analizę kształtów wykresów giełdowych. Szczególnie istotne są liczne wskaźniki techniczne oraz narzędzia analizy statystycznej.
Najpopularniejsze wskaźniki techniczne obejmują:
\begin{itemize}
\item{\textbf{SMA}} - średnia krocząca. Jest to średnia cen z kilku ostatnich dni (np. 3, 7, 14, 30),
\item{\textbf{EMA}} - wykładnicza średnia krocząca. Jest to wykładnicza średnia cen z kilku ostatnich dni (np. 3, 7, 14, 30),
\item{\textbf{MACD}} -  miara zbieżności i rozbieżności średnich ruchomych,
\item{\textbf{RSI}} -  wskaźnik siły względnej określający siłę trendu,
\item{\textbf{oscylator stochastyczny}} -  wskaźnik momentum i siły trendu.
\end{itemize}

\subsubsection{Źródło danych i wybrane spółki}

W pracy zostało wykorzystane darmowe źródło danych giełdowych \textit{Alpha Vantage} \cite{alphavantage}. Jest to API pozwalające na pobranie historycznych danych giełdowych dla konkretnej spółki poprzez podanie odpowiedniego symbolu giełdowego. Dostępne są zarówno podstawowe dane giełdowe jak i wskaźniki analizy technicznej. 

\bigskip

Na giełdach papierów wartościowych są obecne tysiące spółek. Ze względu na ograniczone zasoby obliczeniowe oraz dostępność danych badania zostały przeprowadzone na spółkach z giełdy \textit{NASDAQ} o największej kapitalizacji.

\subsection{Predykcja}

Na rysunku \ref{alphabet_history} widoczne są zmiany cen akcji spółki \textit{Alphabet Inc.} w latach 2004-2018. Analizując ten wykres z łatwością można wskazać daty, w których opłacalnym było zainwestowanie w akcje, aby następnie je sprzedać w póżniejszym terminie by osiągnąć zysk. Niestety stwierdzenie czy wartość akcji w przyszłości spadnie, czy wzrośnie, nie jest tak trywialne jak odczytywanie danych historycznych. Przewidywanie przyszłych cen akcji jest głównym zajęciem zarówno inwestorów indywidualnych jak i instytucjonalnych. Skuteczne odgadywanie przyszłych wzrostów lub spadków cen pozwoliłoby na osiąganie ponadprzeciętnych zysków i unikanie strat. O trudności tego zadania mogą świadczyć takie teorie jak \textit{hipoteza błądzenia losowego} czy też \textit{hipoteza rynku efektywnego}. Zgodnie z \textit{hipotezą błądzenia losowego} \cite{randwalk}, krótkoterminowo, ceny akcji zmieniają się według nieprzewidywalnych schematów. Zmiany minutowe cen akcji są więc dużo trudniejsze do przewidzenia niż zmiany dobowe. \textit{Hipoteza rynku efektywnego} \cite{efficientmarket} opiera się na założeniu iż ceny obecne na giełdzie całkowicie odwzorowują wszystkie dostępne informacje na rynku. Oznacza to, że próby wyprzedzenia innych inwestorów na podstawie szybkiej reakcji na pojawiające się informacje nie będą skuteczne. Obie te hipotezy mają zarówno swoich zwolenników jak i krytyków.

\begin{figure}[H]
\centering \includegraphics[scale=0.9]{img/linear_regression/l_r_stock_data}
\caption{Wykres cen akcji spółki \textit{Alphabet Inc} (opracowanie własne)}
\label{alphabet_history}
\end{figure}

Rysunek \ref{alphabet_history} ilustruje fakt, że ceny zamknięcia akcji tworzą szereg czasowy. Dotyczy to także pozostałych charakterystyk akcji, takich jak cena otwarcia, liczba akcji w obrocie danego dnia, najniższa cena akcji czy najwyższa cena akcji danego dnia. Fakt ten ma istotny wpływ na sposób używania i przetwarzania danych giełdowych.

\subsubsection{Zakres prognozy}

Przed przystąpieniem do konstruowania modeli predykcyjnych należy zdefiniować co tak naprawdę warto przewidywać, każda akcja ma bowiem kilka atrybutów. Najbardziej pożytecznym parametrem akcji, którego wykorzystanie daje inwestorowi największe szanse na zysk jest \textbf{cena zamknięcia}. Znajomość ceny zamknięcia z kolejnego dnia daje inwestorowi cały czas trwania sesji giełdowej na podjęcie skutecznych decyzji inwestycyjnych. Jest to najczęściej wybierany parametr akcji przy przewidywaniu ceny. Przykładem parametru, który nie jest istotny jest liczba akcji w obrocie z kolejnych dni, ta liczba sama w sobie nie niesie informacji o spadku lub wzroście cen.

\bigskip

Po wybraniu celu prognozy należy również określić jej przedział czasowy. Ceny na giełdzie można przewidywać dla dowolnego przedziału czasu. Może to być zarówno okres jednej minuty jak i kilku miesięcy. Przy gwarancji doskonałych prognoz, im większa częstotliwość dokładnego przewidywania ceny tym lepiej. Wynika to z tego iż inwestor może szybciej reagować na zachodzące zmiany i w większym stopniu wykorzystywać pozyskaną wiedzę zwiększając zyski. Z drugiej strony opierając się na \textit{hipotezie błądzenia losowego} można zauważyć, że zmiany w małych przedziałach czasowych są dużo bardziej zaburzone przez losowe wahania ceny. To z kolei sprawia iż krótkoterminowe ruchy cen mogą okazać się nie do przewidzenia. W celu utrzymania kompromisu pomiędzy użytecznością modelu, a jego odpornością na losowość giełdy, za okres predykcji został wybrany \textbf{jeden dzień}.
 
\subsubsection{Prognozowanie - regresja czy klasyfikacja?}

Do tematu prognozowania cen akcji można podejść na dwa sposoby:
\begin{itemize}
\item{\textbf{dokładny}, przewidywanie konkretnych wartości cen akcji,}
\item{\textbf{binarny}, predykcja wzrostu lub spadku ceny - tak zwana predykcja trendu.}
\end{itemize}

Potencjalnie korzystniejszym podejściem jest przewidywanie dokładnych cen akcji, gdyż jest to dokładniejsze aproksymowanie ceny. Jednakże z perspektywy inwestora istotniejszym od dokładnych wartości ceny są trendy. To właśnie różnice w cenach akcji pozwalają zarobić na ich obrocie. Wobec tego zamiast przewidywania dokładnej ceny zamknięcia warto przewidywać wzrosty oraz spadki cen. W przeciwieństwie do danych ciągłych, wyjściowe dane dyskretne  dają jasny sygnał o działaniach jakie należy podjąć aby zarobić. Z tego powodu jako podstawowe wyjście z modeli predykcyjnych wybrany został \textbf{trend binarny}.

\bigskip

Ze względu na to jak przebiega obrót akcjami, binarne przewidywanie z dnia na dzień może jednak okazać się niedostosowane do rzeczywistości. Akcje kupuje i sprzedaje się za pomocą domu maklerskiego, który pobiera prowizje za każdą transakcję. Obecnie najniższe prowizje na polskim rynku są na poziomie $0,19\%$ za transakcję. Pojedyncza operacja dająca zarobić na przewidzianej cenie wymaga kupienia, a następnie sprzedania akcji, wobec czego łączna prowizja wyniesie przy zaokrągleniu $0,4\%$. Wszystkie wahania cen poniżej tej wartości są teoretycznie bez znaczenia dla inwestora, ponieważ nie da się na nich zarobić. W związku z powyższym wnioskowaniem należy zastosować model dyskretny, będący rozwinięciem modelu binarnego o dodatkową klasę - klasę utrzymania ceny w pewnych ramach. Wyszczególnione są wówczas trzy klasy:
\begin{itemize}
\item spadek ceny poniżej $0,4\%$
\item wzrost ceny powyżej $0,4\%$
\item utrzymanie zmiany ceny w przedziale $(-0,4; 0,4)\%$
\end{itemize}

Dla potwierdzenia zasadności takiego modelu, należy upewnić się że dzienne wahania cen na giełdzie są wystarczające. Na rysunku \ref{l_r_pct_change_last_30} można zaobserwować, iż zmiany w kursie często przekraczają $0,4\%$ w związku z czym transakcje przynoszące zysk można wykonywać regularnie. Ten wniosek potwierdza zasadność takiej konstrukcji modeli. W związku z większym stopniem złożoności takiej klasyfikacji, może okazać się iż dane wejściowe nie pozwalają na odseparowanie tych trzech klas. 

%TODO dodać paski -0.4%   +0.4% do wykresu
\begin{figure}[H]
\centering \includegraphics[scale=0.9]{img/linear_regression/l_r_pct_change_last_30}
\caption{Dzeinna zmiana ceny akcji spółki \textit{GOOGL} z 30 dni (opracowanie własne)}
\label{l_r_pct_change_last_30}
\end{figure}


%\subsubsection{Selekcja cech}

%Według niektórych badań wolumen obrotów akcji nie jest skorelowany w żaden sposób z jej ceną. Modele mogą więc wykazywać lepsze wyniki przy mniejszej lub większej liczbie wejściowych parametrów. Niektóre parametry mogą okazać się zbędne lub wręcz mogą osłabiać przewidywanie wartości.

%\subsubsection{Dobór spółek}

%Modele oceniane na podstawie danych poszczególnych spółek mogą dawać w skrajnych przypadkach zafałszowane wyniki. Wiele spółek wykazuje wysoką korelację cen akcji między sobą. W celu uniknięcia pułapki przetrenowania, do uczenia i testowania użyte zostały dane spółek o niskiej korelacji i różnych trendach wzrostu/spadku.

\subsection{Kryteria oceny modeli predykcji}

Porównywanie jakości i wydajności jest nierozłącznym elementem tworzenia i testowania metod uczenia maszynowego. Istnieje wiele sposobów na realizację tego nietrywialnego zadania, które jak się okazuje, często wymaga porównywania modeli na kilku płaszczyznach. Najpopularniejszymi miarami porównawczymi są:
\begin{itemize}
\item procent prawidłowych klasyfikacji
\item pole AUC pod krzywą ROC
\item częściowy indeks Gini
\item metryka F1
\item współczynnik Briera
\item statystyka Kołomogrowa-Smirnova
\end{itemize}

\subsubsection{Macierz błędu}

W przypadku klasyfikacji dwuklasowej na klasy A i B każdą predykcję można przypisać do jednej z 4 grup:
\begin{itemize}
\item True Positive (TP) - gdy przewidziano klasę A dla etykiety A
\item False Negative (FN) - gdy przewidziano klasę B dla etykiety A
\item False Positive (FP) - gdy przewidziano klasę A dla etykiety B
\item True Negative (TN) - gdy przewidziano klasę B dla etykiety B
\end{itemize}

%TODO dodać schemat macierzy błedu

Graficzną reprezentację podziału klasyfikacji na powyższe kategorie nazywamy \textit{macierzą błędu}. Zastosowanie miar opartych o tablicę błędów dla problemów z większą liczbą klas wymaga dodatkowych kroków. W celu policzenia wartości TP, FN, FP i TN należy wyróżnić konkretną klasę, a pozostałe klasy należy zagregować w sztuczną klasę przeciwną. W ten sposób należy wyliczyć konkretną miarę tyle razy ile jest klas. Ostatecznym krokiem w celu uzyskania jednolitej oceny modelu jest na przykład wyliczenie średniej ważonej z wyników dla każdej z klas.


\subsubsection{Procent prawidłowych klasyfikacji}

Jednym z najprostszych sposobów do oceny dokładności klasyfikatorów jest określenie procentu prawidłowych przypisań przykładu do klasy. Metoda ta potrafi dawać złudzenie zadowalających wyników, w których występują duże różnice w licznościach poszczególnych klas. Rozważmy dla takiego zadania naiwny model przypisujący do każdego postawionego przykładu klasę, której liczność jest największa. Wówczas wyniki procentowe prawidłowej klasyfikacji będą wprost proporcjonalne do różnicy w liczności klasy największej w stosunku do innych klas. W większości przypadków pomimo dobrego wyniku taki model będzie uznany za bezużyteczny. Wobec tego tę miarę jakości należy stosować wraz z innymi miarami, które nie są podatne na tego typu zaburzenia.

\subsubsection{Pole AUC pod krzywą ROC \cite{roc}}

Krzywa ROC (ang. receiver operating characteristic) jest narzędziem, która opisuje dokładność klasyfikatora za pomocą oceny jego czułości i precyzji. Precyzją modelu nazywa się stosunek $\frac{TP}{TP+FP}$, zaś czułość jest oznaczona przez $\frac{TP}{TP+FN}$.

\bigskip

Zdefiniujmy wartości \textit{True Positive Rate (TPR)} oraz \textit{False\ Positive\ Rate (FPR)}:

$$ TPR = \frac{TP}{TP+FN}\ \ \ \ \ \ \ \ FPR = \frac{FP}{FP+TN} $$

Klasyfikatory w większości przypadków nie zwracają dokładnego wyniku przypisania przykładu do klasy. Zazwyczaj wynikiem klasyfikacji jest liczba rzeczywista z przedziału $[0, 1]$, którą można identyfikować jako prawdopodobieństwo. Można przyjąć że jeżeli klasyfikator zwróci $0$ oznacza to przypisanie do klasy A, zaś $1$ oznacza przypisanie do klasy B. Dla wartości z zakresu $(0, 1)$ przypisuje się pewną wartość progową rozgraniczającą obie klasy. Dla tego progu mniejsze od niego wartości przypisujemy do klasy A, zaś resztę do klasy B. Intuicyjnie jest to zazwyczaj połowa przedziału czyli $0.5$.

Krzywa ROC jest graficzną reprezentacją skuteczności modelu klasyfikacyjnego. Jest ona skonstruowana poprzez wykreślenie stosunku $TPR$ do $FPR$ dla różnych progów rozgraniczających klasy. Na rysunku \ref{roc} widać przykładowe krzywe ROC dla klasyfikatorów różnej jakości.


%source: https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5
\begin{figure}[H]%
\centering
\subfigure[Krzywa ROC dla modelu, który nie jest w stanie rozdzielić klas]{%
\includegraphics[scale=0.55]{img/roc_1.png}}%
\qquad
\subfigure[Krzywa ROC przykładowego klasyfikatora]{%
\includegraphics[scale=0.55]{img/roc_2.png}}%
\qquad
\subfigure[Krzywa ROC dla modelu idealnego]{%
\includegraphics[scale=0.55]{img/roc_3.png}}%
\caption{Przykładowe krzywe ROC \cite{roccurves} }% (źródło: https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5).}
\label{roc}
\end{figure}


Porównanie różnych klasyfikatorów za pomocą krzywej ROC odbywa się poprzez porównanie pola pod krzywymi. Im większe pole pod krzywą ROC dla danego klasyfikatora tym lepsza jest jego jakość. Pole pod krzywą dla modelu idealnego wynosi $1$, zaś dla modelu losowego $0.5$. Warto zauważyć że dla wartości pola poniżej 0.5  korzystnym zabiegiem jest zamiana przedziałów dla klas.


\subsubsection{Częściowy indeks Gini} %TODO bibliografia

%TODO dodać wykres z indeksem GINI

Częściowy indeks Gini jest innym sposobem na analizę jakości modelu predykcyjnego za pomocą krzywej ROC. Otrzymuje się go poprzez wyliczenie pola powierzchni pomiędzy krzywą ROC dla modelu predykcyjnego, a krzywą ROC dla modelu losowego, w stosunku do pola powierzchni między krzywą ROC modelu idealnego, a krzywą ROC modelu losowego. Dla modelu losowego wynosi 0, zaś dla modelu idealnego wartość indeksu wynosi 1. W ten sposób otrzymana wartość indeksu Gini może być interpretowana jako procent idealności modelu.

\subsubsection{F1} %TODO bibliografia

Metryka F1 jest średnią harmoniczną metryk czułości i precyzji (wyrażona wzorem $F1=2*\frac{precyzja*czulosc}{precyzja+czulosc}$). Metryka ta jest dobrym narzędziem pozwalającym określić za pomocą jednej wartości jakość modelu, biorąc pod uwagę precyzję jak i czułość modelu. Osiąga ona w najlepszym przypadku wartość 1, zaś w najgorszym wartość 0. 

\subsubsection{Współczynnik Briera \cite{brier}}

Współczynnik Briera (ang. Brier score) jest metodą oceny modeli klasyfikujących opisana wzorem:

$$	BS=\frac{1}{N} \sum_{t=1}^{N} \sum_{i=1}^{R}(f_{ti}-o_{ti})^2 $$

\begin{itemize}
\item $N$ to liczba predykcji,
\item $R$  to liczba możliwych klas
\item $f_{ti}$ to prawdopodobieństwo, które wyznaczył klasyfikator, przypisania przykładu $t$ do klasy $i$,
\item $o_{ti}$ to rzeczywiste przypisanie przykładu do danej klasy (0 gdy przykład nie jest tej klasy, oraz 1 gdy przykład należy do tej klasy).
\end{itemize}

W związku z powyższą definicją, miara ta może zostać wykorzystana w przypadku modeli, które na swoim wyjściu zwracają prawdopodobieństwo przypisania przykładu do każdej z klas. Wobec tego nie każdy model można ocenić tą metryką. Istotnym spostrzeżeniem jest fakt iż w przeciwieństwie do innych metryk, współczynnik Briera modelu idealnego wynosi $0$, zaś im gorszy model tym większy współczynnik.


%TODO źródło do poniższego
\subsubsection{Statystyka Kołmogorowa-Smirnova}

Statystyka Kołmogorowa-Smirnova (ang. Kolmogrow-Smirnov Test) pozwala ocenić jakość klasyfikatora binarnego na podstawie stopnia separacji rozkładu dwóch klas. Ocena dokonywana jest przez zmierzenie maksymalnej odległości między wkyresami dystrybuant rozkładu jednej i drugiej klasy. Niech $F(x)$ to dystrybuanta rozkład klasy 1, zaś $G(x)$ to dystrybuanta rozkładu klasy 2. Wówczas statystyka Kołmogorowa-Smirnova opisana jest wzorem:

$$D_{n,m}=\sup_x|F(x)-G(x)|$$

Metryka ta daje wartość 100 dla modelu idealnego, zaś 0 dla modelu losowego.

\subsubsection{Dobór metryki}

Porównanie modeli klasyfikujących jest zadaniem trywialnym tylko dla specyficznych problemów. W tych przypadkach można wykorzystać procent prawidłowych klasyfikacji jako jedyną miarę jakości modeli. W bardziej złożonych przypadkach, gdy dochodzi do dysproporcji w licznościach klas, ta podstawowa miara zostaje w pewien sposób zafałszowana. Innym aspektem, który może być brany pod uwagę przy ocenie klasyfikatorów jest różnica w wadze błędu z grupy \textit{FP}, względem błędu z grupy \textit{FN}. Te problemy należy rozwiązywać poprzez używanie różnorodnych miar do porównywania modeli. Używanie wielu metryk może być przydatne w szczególności gdy dwa modele mają podobne wartości dla jednej z miar.

\bigskip

W zagadnieniu predykcji giełdowych sprowadzonym do klasyfikacji, można posłużyć się \textit{procentem prawidłowych klasyfikacji} jako podstawową miarą porównawczą. Wynika to z faktu, iż dla większości spółek różnica w licznościach klas mieści się w granicach kilku do kilkunastu procent całego zbioru danych. Taka dysproporcja jest jednak na tyle znacząca, że dla porównywania modeli o bliskich wynikach trzeba stosować dodatkową miarę porównawczą. Ze względu na niewrażliwość na dysproporcje w licznościach klas oraz swoją popularność, jako drugą metrykę wykorzystano \textit{pole AUC pod krzywą ROC}.


\subsection{Uczenie modeli - specyfika szeregów czasowych}

Każdy proces uczenia modeli sztucznej inteligencji zwieńczony jest analizą jakości. Zazwyczaj taką analizę przeprowadza się poprzez wydzielenie pewnej części zbioru danych i oznaczenia jej jako zbioru testowego. Reszta zbioru danych zwana jest zbiorem treningowym (rysunek \ref{train_test_split}). Taki podział wszystkich próbek pozwala na używanie części treningowej do nauki modelu, zaś części testowej do jego oceny. Ocena modelu na podstawie próbek, któych model nie widział podczas procesu uczenia daje wiarygodne wyniki.

\begin{figure}[H]
\centering 
\includegraphics[scale=0.5]{img/train_test_split.png}
\caption{Podział danych na zbiór treningowy i testowy \cite{train_test_split}}
\label{train_test_split}
\end{figure}

Ten model podziału jest najbardziej powszechny pośród zagadnień klasyfikacyjnych ze względu na swoją prostotę i odporność na zjawisko przeuczenia (ang. overfitting). Dane giełdowe jako szeregi czasowe posiadają dodatkową cechę - umiejscowienie próbek na osi czasu. Wykorzystanie faktu, iż kolejne próbki danych pojawiają się stopniowo wraz z upływem czasu, pozwala na udoskonalenie metody doboru danych do uczenia się. Uczenie i ocena metodą kroczącą (ang. walk forward) polega na stopniowym powiększaniu zbioru danych treningowych o kolejne próbki ze zbioru testowego podczas procesu oceny jakości. 

\textit{Przykład:} podczas oceny jakości model przewiduje cenę za pomocą próbki z dnia $t$ mając do uprzedniej nauki wszystkie próbki od $t_0$ do $t-1$. Po tej predykcji próbka z dnia $t$ zostaje wcielona do zbioru uczącego. Model może, ale nie musi, zostać ponownie poddany procesowi uczenia przed przystąpieniem do oceny jakości dla predykcji kolejnej próbki $t+1$. Proces ten zobrazowany jest na rysunku \ref{train_test_split_time_series}. Na niebiesko oznaczono próbki zbioru treningowego, na czerwono zaś próbkę zbioru testowego podlegającą ocenie.

\begin{figure}[H]
\centering 
\includegraphics[scale=0.75]{img/train_test_split_time_series.png}
\caption{Podział danych na zbiór treningowy i testowy metodą kroczącą \cite{train_test_split_time_series}}
\label{train_test_split_time_series}
\end{figure}

Wykorzystanie metody kroczącej do podziału zbioru danych pozwala zmaksymalizować ilość informacji przekazanych do modelu podczas procesu uczenia, a tym samym poprawia końcowe wyniki klasyfikacji. 


\subsection{Wnioski i uwagi}

Do zagadnienia predykcji cen na giełdzie można podchodzić na kilka sposobów. Najbardziej intuicyjnym rozwiązaniem z perspektywy początkującego inwestora, jest model, który na wyjściu wyznacza jaką akcję powinien wykonać inwestor w stosunku do akcji konkretnej spółki. Doświadczony makler do wyznaczania cen zapewne wybrałby model regresyjny, który poza określeniem trendu daje możliwość oceny jak duże są wahania ceny. Dzięki temu mógłby dobrać spółki, dla których wzrost cen będzie największy. Przy ocenie jakości regresji błąd jest zazwyczaj określany za pomocą odległości przewidywanej wartości ceny od rzeczywistej wartości ceny. Informacja że dany model aproksymuje wartość ceny z błędem $\pm 5 \$$ jest ciężka do zinterpretowania wprost. Na podstawie takiej oceny makler nie jest w stanie bezpośrednio stwierdzić czy taki model nadaje się do użycia na giełdzie. Dla zagadnienia klasyfikacji błąd jest określony jako $\%$ prawidłowych klasyfikacji, więc daje dużo lepsze wyobrażenie na temat jakości i możliwości wykorzystania modelu do obrotu akcjami.

\bigskip



\newpage

\section{Analiza i przetworzenie danych}

Przed przystąpieniem do wyboru modeli należy zastanowić się nad danymi jakie będą służyć do ich uczenia. Wybór odpowiednich cech, analiza zebranych informacji oraz przetworzenie ich, wykracza poza zakres uczenia maszynowego tworząc własną dziedzinę zwaną inżynierią i analizą danych. Odpowiedni dobór i obróbka danych wejściowych często daje większe korzyści niż dopracowywanie modeli przewidujących i optymalizacja ich parametrów. 

\subsection{Wybrane cechy}

Spośród dostępnych danych do uczenia modeli wybrane zostały: 
\begin{itemize}
\item podstawowe dane giełdowe oraz ich modyfikacje,
\item wybrane wskaźniki analizy technicznej oraz ich modyfikacje.
\end{itemize}

Analiza fundamentalna ze względu na swoją długoterminową naturę (raporty finansowe spółek publikowane kwartalnie) jest mało istotna przy dziennych predykcjach giełdowych. Dodatkowo istnieje mało darmowych źródeł danych analizy fundamentalnej. Z tych względów zostanie ona pominięta w tej pracy.

\bigskip

Wszystkie dane wejściowe, wraz z opisami, zaprezentowane są w tabeli \ref{data_columns_table}. Wszystkie dane mają charakter dzienny. Najnowsze informacje pochodzą z dnia \textit{t}, zaś przewidywaną ceną jest cena z dnia \textit{t+1}.

\begin{longtable}[c]{| m{0.5cm} m{5cm} m{10cm}|} 

\toprule
  Lp. & Oznaczenie & Opis\\
\midrule
\endhead
\midrule

\caption{Wybrane cechy i ich opis}
\label{data_columns_table}
\endfoot

\bottomrule
\caption{Wybrane cechy i ich opis}
\label{data_columns_table}
\endlastfoot


 1 & $C_t$ & Cena zamknięcia w dniu $t$. \\ 
 2 & $O_t$ & Cena otwarcia w dniu $t$. \\
 3 & $H_t$ & Najwyższa cena w dniu $t$. \\
 4 & $L_t$ & Najniższa w dniu $t$. \\
 5 & $V_t$ & Liczba akcji w obrocie w dniu $t$. \\
 6 & $HL\_PCT$ & Różnica pomiędzy $H_t$ a $L_t$ wyrażona w procentach.\\
 7 & $SMA_5$ & Średnia krocząca z 5 dni. \\
 8 & $SMA_{10}$ & Średnia krocząca z 10 dni. \\\
  9 & $SMA_{20}$ & Średnia krocząca z 20 dni. \\
 10 & $SMA\_DIFF$ & $SMA_{10}-SMA_{5}$ \\
 11 & $SMA\_DIFF2$ & $SMA_{20}-SMA_{5}$ \\
 12 & $TR$ & (ang. True Range) różnica pomiędzy najniższą ceną, a najwyższą ceną danego dnia. \\
 13 & $MACD$ & Wskaźnik wyliczany z różnicy dwóch wykładniczych średnich kroczących.\\
 14 & $MACD\_SIGNAL$ & Wykładnicza średnia krocząca ze wskaźnika MACD \\
 15 & $ROC_{5}$ & (ang. Rate of Change) Wskaźnik liczący procentową różnicę w cenie między dniem $t$ a $t-5$. \\
 16 & $ROC_{10}$ & (ang. Rate of Change) Wskaźnik liczący procentową różnicę w cenie między $t$ a $t-10$. \\
 17 & $ROC\_DIFF$ & $ROC_{10}-ROC_{5}$ \\
  18 & $MOM_{5}$ & Momentum - różnica w cenie między $t$ a $t-5$.  \\
 19 & $MOM_{10}$ & Momentum - różnica w cenie między $t$ a $t-10$. \\
 20 & $MOM\_DIFF$ & $MOM_{10}-MOM_{5}$ \\
  21 & $WILLR_{5}$ & \textit{Williams` \%R} - wskaźnik niedosycenia/przesycenia ceny z ostatnich 5 dni. \\
 22 & $WILLR_{10}$ & \textit{Williams` \%R} - wskaźnik niedosycenia/przesycenia ceny z ostatnich 10 dni.  \\
 23 & $WILLR\_DIFF$ & $WILLR_{10}-WILLR_{5}$ \\
  24 & $APO_{5}$ & Oscylator ceny z 5 dni. \\
 25 & $APO_{10}$ & Oscylator ceny z 10 dni.  \\
 26 & $APO\_DIFF$ & $APO_{10}-APO_{5}$ \\
  27 & $RSI_{5}$ & Wskaźnik siły względnej - oscylator siły trendu z 5 dni. \\
 28 & $RSI_{10}$ & Wskaźnik siły względnej - oscylator siły trendu z 10 dni.\\
 29 & $RSI\_DIFF$ & $RSI_{10}-RSI_{5}$ \\
  30 & $ADX_{5}$ & Wskaźnik siły trendu z 5 dni. \\
 31 & $ADX_{10}$ & Wskaźnik siły trendu z 10 dni. \\
 32 & $ADX\_DIFF$ & $ADX_{10}-ADX_{5}$ \\
 33 & $CCI_{5}$ & (ang. Commodity Channel Index) Oscylator z 5 dni. \\
 32 & $CCI_{10}$ & (ang. Commodity Channel Index) Oscylator z 10 dni. \\
 34 & $CCI\_DIFF$ & $CCI_{10}-CCI_{5}$ \\
 35 & $AD$ & linia \textit{Chaikin A/D}.  \\
 36 & $STOCH\_K$ & Oscylator stochastyczny \textit{Slow \%K}. \\
 37 & $STOCH\_D$ & Oscylator stochastyczny \textit{Slow \%D}.\\
 39 & $STOCH\_K\_DIFF$ & $STOCH\_K_{t}-STOCH\_K_{t-1}$ \\
 40 & $STOCH\_D\_DIFF$ & $STOCH\_D_{t}-STOCH\_D_{t-1}$  \\
 41 & $DISPARITY_{5}$ &  $\frac{C_t}{SMA_5}\times 100$ \\
 42 & $DISPARITY_{10}$ & $\frac{C_t}{SMA_10}\times 100$ \\
 43 & $DISPARITY_{20}$ & $\frac{C_t}{SMA_20}\times 100$ \\
 44 & $BANDS\_DIFF_{10}$ & $BOLL\_UP_{10} - BOLL\_LOW_{10}$ - różnica górnej i dolnej wartości wstąg Bollingera z 10 dni.  \\
 45 & $BANDS\_DIFF_{20}$ & $BOLL\_UP_{20} - BOLL\_LOW_{20}$ - różnica górnej i dolnej wartości wstąg Bollingera z 20 dni.  \\
46 & $PRICE\_BANDS\_UP_{10}$ & $(C_t-BANDS\_UP_{10})\div BANDS\_UP_{10}$ - wskaźnik oparty o wstęgi Bollingera.  \\
 47 & $PRICE\_BANDS\_LOW_{10}$ & $(C_t-BANDS\_LO_{10})\div BANDS\_LOW_{10}$ - wskaźnik oparty o wstęgi Bollingera.\\
 48 & $PRICE\_BANDS\_UP_{20}$ & $(C_t-BANDS\_UP_{20})\div BANDS\_UP_{20}$ - wskaźnik oparty o wstęgi Bollingera.\\
 49 & $PRICE\_BANDS\_LOW_{20}$ & $(C_t-BANDS\_LOW_{20})\div BANDS\_LOW_{20}$ - wskaźnik oparty o wstęgi Bollingera.\\
     
\end{longtable}

\subsection{Przetworzenie wstępne}

Po wybraniu odpowiednich danych należy przystąpić do ich pobrania. Pobrane dane nie są jednak gotowe do wykorzystania w procesie uczenia maszynowego. Zbiory informacji, w szczególności te pobrane z internetu, należy traktować zgodnie z zasadą ograniczonego zaufania. Wobec braku gwarancji jakości, dane powinny zostać zbadane pod względem integralności oraz poprawności. Spośród najczęstszych problemów wymienić można: 
\begin{itemize}
    \item brakujące informacje,
    \item duplikacja danych,
    \item dane nominalne (np. łańcuchy znaków),
    \item błędy pomiarowe.
\end{itemize}
%TODO podpiąć tutaj bibliografię o przetwarzaniu danych w machine learningu
W celu eliminacji błędnych danych należy je usunąć lub zastąpić wybraną wartością np. średnią wartością z danej cechy. Jeśli chodzi o dane nominalne stosowana jest \textbf{binaryzacja}. Polega ona na odpowiednim przekształceniu cechy na wektor cyfr. Po wyeliminowaniu powyższych problemów dane warto przetworzyć takimi metodami jak \textbf{normalizacja} czy \textbf{standaryzacja}. Służą one do przeskalowania zakresu możliwych wartości do przedziału $[0,1]$ lub $[-1,1]$. Taki zabieg polepsza wydajność modeli uczenia maszynowego.

\bigskip

\subsubsection{Niestacjonarność szeregów czasowych}

%TODO bibliografia niestacjonarność szeregów czasowych
Na rysunku \ref{non_stationary_adjusted_close} zauważyć można zjawisko niestacjonarności. Jest to cecha związana z autokorelacją zmiennych szeregów czasowych. Oznacza to iż kolejne wyrazy szeregu zależą w jakimś stopniu od poprzednich. Dla cen akcji ta zależność jest ewidentna, cena każdego dnia jest oparta o cenę z dnia poprzedniego. 

\begin{figure}[H]
\centering 
\includegraphics[scale=0.9]{img/adjusted_close.pdf}
\caption{Wykres cen akcji spółki \textit{Alphabet Inc} (opracowanie własne)}
\label{non_stationary_adjusted_close}
\end{figure}

Zjawisko niestacjonarności szeregów czasowych negatywnie wpływa na wykorzystywanie ich do uczenia maszynowego. Wszystkie zmienne, których dotyczy ten problem trzeba odpowiednio dostosować przed użyciem do uczenia modeli. Najbardziej powszechną metodą radzenia sobie z niestacjonarnością jest różnicowanie (ang. \textbf{differencing}). Jest to prosta metoda polegająca na wyliczeniu różnicy pomiędzy kolejnymi elementami w szeregu. W ten sposób zmienna $x_t$ jest zastąpiona przez $x'_t=x_t-x_{t-1}$. Wynik takiego przetworzenia dla ceny zamknięcia spółki \textit{Alphabet Inc} widoczny jest na rysunku \ref{stationary_adjusted_close}.

\begin{figure}[H]
\centering 
\includegraphics[scale=0.9]{img/adjusted_close_stationary.pdf}
\caption{Wykres cen akcji spółki \textit{Alphabet Inc} po przetworzeniu (opracowanie własne)}
\label{stationary_adjusted_close}
\end{figure}

\subsubsection{Stworzenie etykiet}

W procesie nadzorowanego uczenia maszynowego poza danymi wejściowymi potrzeba również etykiet, tj. zbioru pożądanych odpowiedzi. W przypadku regresyjnej predykcji cen zamknięcia w dniu $t$ etykietą jest cena zamknięcia z dnia $t+1$. Etykietę dla każdego wiersza danych wejściowych można więc uzyskać poprzez dodanie kolumny ceny zamknięcia przesuniętej o jeden dzień wstecz (zilustrowane na rysunku \ref{regression_label_creation}). 

\begin{figure}[H]
\centering 
\includegraphics[scale=0.9]{img/label_creation.png}
\caption{Przykładowe dane dla spółki \textit{Alphabet Inc}}
\label{regression_label_creation}
\end{figure}

W celu osiągnięcia etykiet do klasyfikacji potrzeba wykonać dodatkowe kroki. Korzystając z nowej kolumny można obliczyć różnicę pomiędzy $C_t$, a $C_{t+1}$ . Wyznaczenie etykiety trendu do klasyfikacji binarnej sprowadza się do wyliczenia funkcji $sgn(C_{t+1}-C_{t})$ (rysunek \ref{binary_label_creation}). 

\begin{figure}[H]
\centering 
\includegraphics[scale=0.9]{img/label_creation2.png}
\caption{Przykładowe dane dla spółki \textit{Alphabet Inc}}
\label{binary_label_creation}
\end{figure}

 W przypadku klasyfikacji podzielonej na 3 klasy wyznaczenie etykiety sprowadza się do obliczenia procentowej różnicy pomiędzy cenami zamknięcia - $100*(C_{t+1}-C_t)/C_t$. Tak wyliczoną różnicę procentową można wykorzystać do przypisania etykiecie wartości $-1, 0, 1$ w zależności od wybranego progu opłacalności. Przykładowe obliczenia zostały zilustrowane na rysunku \ref{classification_label_creation}.

\begin{figure}[H]
\centering 
\includegraphics[scale=0.9]{img/label_creation3.png}
\caption{Przykładowe dane dla spółki \textit{Alphabet Inc}}
\label{classification_label_creation}
\end{figure}

% TODO \subsubsection{EDA}

\subsubsection{Redukcja danych wejściowych}

Redukcja rozmiaru danych wejściowych jest zagadnieniem pozwalającym na poradzenie sobie ze zbyt dużą liczbą danych wejściowych. Jeżeli dwie zmienne są ze sobą mocno skorelowane, wówczas jedną z nich można odrzucić bez utraty zawartych w niej informacji. Macierz korelacji par zmiennych wejściowych przedstawiona jest na rysunku \ref{correlation}. Analizując macierz korelacji zauważyć można że duża część zmiennych jest ze sobą mocno skorelowana (wartości bliskie $1$ oznaczają wysoką korelację, 0 brak korelacji, zaś $-1$ negatywną korelację).

\begin{figure}[H]
\centering 
\includegraphics[scale=0.6]{img/corr_matrix.pdf}
\caption{Macierz korelacji par zmiennych}
\label{correlation}
\end{figure}

Dla par zmiennych o najwyższej korelacji można usunąć jedną ze zmiennych, ponieważ powiela ona informacje już zawarte w drugiej zmiennej.  W tabeli \ref{ccorr_table} zostały wylistowane pary zmiennych o najwyższej korelacji. Ze zbioru wejściowego usunięte zostały zmienne z kolumny \textit{Zmienna 2}.


\begin{table}[H]
\centering
\begin{tabular}{ |c|c|c| } 
 \hline
Zmienna 1 & Zmienna 2 &  Stopień korelacji \\
 \hline
APO-5 & APO-10 &  1.000000 \\
 \hline
10-SMA & MOM-10 &  1.000000 \\
 \hline
5-SMA & MOM-5 &  1.000000 \\
 \hline
5-SMA & ROC-5 &  0.997665 \\
 \hline
10-SMA & ROC-10 &  0.996666 \\
 \hline
RSI-5 & RSI-10 &  0.964811 \\  
 \hline
\end{tabular}
\caption{Tabela najbardziej skorelowanych par zmiennych}
\label{ccorr_table1}
\end{table}


Po odrzuceniu najmocniej skorelowanych danych można skorzystać z jednej z metod redukcji wymiaru zadania wejściowego jaką jest \textbf{analiza głównych składowych} (ang. principal component analysis). Jest to statystyczna metoda analizy czynnikowej, która modyfikuje układ współrzędnych w taki sposób aby maksymalizować wariancję kolejncyh zmiennych. Dzięki temu tworzona jest nowa przestrzeń obserwacji, w której najwięcej zmienności przedstawiają początkowe czynniki. Metode ta opiera się o macierz korelacji lub macierz kowariancji stworzonej z danych wejściowych. Rozmiar wejścia redukowany jest poprzez wybranie czynników, które reprezentują największą część wariancji w zbiorze danych. Stosunek liczby wybranych zmiennych do proocenta całkowitej wariancji zbioru danych przedstawiony jest na rysunku \ref{pca_variance}. Zawarcie $90\%$ wariancji wymaga użycia 8 składowych,  $95\%$ wariancji wymaga użycia 12 składowych, $99\%$ wariancji wymaga użycia 19 składowych. Wybranie wartości $99\%$ wariancji pozwala ograniczyć rozmiar wejściowego wektora o ponad połowę bez utraty informacji w nim zawartych.

\begin{figure}[H]
\centering 
\includegraphics[scale=0.9]{img/pca_variance.pdf}
\caption{Liczba składowych, a całkowita wariancja zbioru}
\label{pca_variance}
\end{figure}

\newpage

\section{Wybrane algorytmy do prognozowania}

%Todo wstęp tutaj

\subsection{SVM \cite{svm}}

Maszyny wektorów podpierających (ang. support-vector machines) są zbiorem klasyfikatorów mających na celu wyznaczenie hiperpłaszczyzn rozdzielających klasy z zachowaniem maksymalnego marginesu rozdzielającego (rysunek \ref{wiki_svm}). W podstawowej wersji klasyfikatory SVM potrafią sktuecznie klasyfikować problemy separowalne liniowo.


\begin{figure}[H]
\centering \includegraphics[scale=0.9]{img/svm.png}
\caption{Hiperpłaszczyzna rozdzielająca zbiór z maksymalnym marginesem \cite{wikisvm}}
\label{wiki_svm}
\end{figure}

W celu używania maszyn wektorów nośnych do klasyfikacji problemów nieliniowych stosuje się przekształcanie przestrzeni zadania za pomocą funkcji jądrowych. Wprowadzają one dodatkowe wymiary do zadania, w których znalezienie hiperpłaszczyzny rozdzielającej klasy może okazać się prostsze (rysunek \ref{wiki_svm2}). Do najpopularniejszych funkcji jądrowych zalicza się funkcje: liniową (zachowującą wymiar zadania w niezmienionym stanie), wielomianową, radialną czy też sigmoidalną.


\begin{figure}[H]
\centering \includegraphics[scale=0.2]{img/svm2.png}
\caption{Ten sam problem zaprezentowany w dwóch oraz trzech wymiarach \cite{wikisvm}}
\label{wiki_svm2}
\end{figure}


\subsection{Sieci neuronowe \cite{neural-nets}}

Sieci neuronowe są zbiorem modeli matematycznych służących do realizacji obliczeń, bądź przetwarzania sygnałów. Inspirowane działaniem mózgu, swoją nazwę czerpią z upodobnienia struktury do naturalnych neuronów oraz łączących je synaps. Głównymi zastosowaniami sieci neuronowych są zadania regresji, klasyfikacji oraz generowania danych. 

\bigskip

Podstawowym elementem sieci neuronowej jest neuron, który na wejściu przyjmuje dane wejściowe, przetwarza i zwraca pojedynczy sygnał wyjściowy. Przetwarzanie sygnału przez neuron z polega zazwyczaj na zsumowaniu sygnałów dochodzących do niego, a następnie obliczenie wartości funkcji aktywacji. Uzyskana wartość z funkcji aktywacji jest przekazywana jako wyjście z neuronu (rysunek \ref{neural-net}). Funkcje aktywacji mogą wprowadzić element nieliniowy do modelu dzięki czemu sieci neuronowe mogą posłużyć do klasyfikacji zbiorów, które nie są separowalne liniowo. Dodatkowo połączenia między neuronami posiadają przypisaną wagę mającą bezpośredni wpływ na wartość sygnału przechodzącego między nimi.

\bigskip

Wiodącym schematem uczenia sieci neuronowych jest korzystanie z przykładów, z których każdy ma etykietę czyli oczekiwaną wartość wyjściową. Każdy z przykładów jest przetwarzany przez sieć neuronową, następnie przez zestawienie wartości wyjściowej sieci z etykietą (odpowiednią funkcją straty) można wyliczyć błąd sieci dla danego przykładu. Ostatnim krokiem jest poprawa wag w sieci neuronowej według wybranej metody propagacji wstecznej. Problem optymalizacji sieci neuronowej sprowadzany jest do problemu optymalizacji funkcji poprzez modyfikację wag na połączeniach między neuronami. Metoda ta zaliczana jest do nauczania z nauczycielem (ang. supervised learning). Najczęściej stosowanymi metodami optymalizacji są algorytmy spadku gradientowego. 

\bigskip

Przy wykorzystywaniu sieci neuronowych głównym problemem, z którym zmagają się naukowcy jest odpowiedni dobór parametrów i algorytmów. Spośród elementów wymagających odpowiedniego dobrania wymienić można następujące:
\begin{itemize}
\item liczba warstw sieci,
\item liczba neuronów w każdej z warstw ukrytych,
\item wykorzystane funkcje aktywacji,
\item algorytm optymalizacyjny,
\item funkcja straty.
\end{itemize}


\subsubsection{Sieci typu MLP \cite{mlp}}

Jednym z najprostszych przykładów sieci neuronowych jest perceptron wielowarstwowy (ang. multilayer perceptron). Taka sieć składa się z warstwy wejściowej, z dowolnej ilości warstw ukrytych oraz z warstwy wyjściowej. W tym rodzaju sieci neuronowych, sygnał wyjściowy dowolnego neuronu jest traktowany jako sygnał wejściowy każdego z neuronów z kolejnej warstwy (rysunek \ref{neural-net}). 

\bigskip

\begin{figure}[H]
\centering \includegraphics[scale=0.7]{img/nn.png}
\caption{Schemat sieci neuronowej typu MLP \cite{mlpnn}}
\label{neural-net}
\end{figure}

Najprostszą implementacja sieci do predykcji danych giełdowych jest sieć przyjmująca na wejściu wektor informacji o akcjach spółki z jednego dnia, zwracająca na wyjściu przewidywaną wartość ceny akcji następnego dnia. Perceptron wielowarstwowy można również zaprojektować tak, aby na wyjściu zwracał wynik klasyfikacji, czyli procentowy wynik przypisania danych wejściowych do każdej z możliwych klas. W tej pracy badane były sieci neuronowe klasyfikujące dane wejściowe według trzech klas: spadek wartości poniżej pewnego progu, utrzymanie wartości w ramach tego progu oraz wzrost wartości powyżej tego progu. 


% \subsubsection{Sieci rekurencyjne}

% W przeciwieństwie do sieci MLP, sieci rekurencyjne posiadają sprzężenia zwrotne sygnału wychodzącego z neuronów. Dzięki wtórnemu sygnałowi sieci te posiadają pewną pamięć przepływających sygnałów. Wpływem sygnału wtórnego na końcowy wynik można sterować za pomocą wag na połączeniach między odpowiednimi neuronami.

% \subsubsection{Sieć typu LSTM \cite{lstm}}

% Sieci LSTM (ang. Long Short Term Memory) są specjalnym rodzajem sieci rekurencyjnych, będących w stanie zapamiętywać długoterminowe zależności. Jak widać na rysunku \ref{lstm-net} sieć typu LSTM jest postaci łańcucha komórek. Każda komórka jest odpowiedzialna za zestawienie i przetworzenie sygnału wejściowego $x_t$ z sygnałem wychodzącym z poprzedniego modułu.

% \begin{figure}[H]
% \centering \includegraphics[scale=0.22]{img/lstm.png}
% \caption{Schemat sieci neuronowej typu LSTM \cite{lstm-scheme}}
% \label{lstm-net}
% \end{figure}

% Głównym elementem każdej komórki jest sygnał $c_{t-1}$ zmieniający się w $c_{t}$, który jest jej stanem. Pierwszym krokiem przy zmianie stanu komórki jest $F_t$ z funkcją sigmoidalną,tak zwana forget gate layer.  Odpowiada ona za zdecydowanie, jaka część sygnału zostanie odrzucona. Kolejnym elementem jest $i_t$, \textit{input gate layer}, która decyduje o tym jakie dane wejściowe zostaną użyte do zmiany stanu komórki. Ostatecznie warstwa $O_t$, \textit{output layer}, decyduje o tym jaka część sygnału powinna przejść do następnej komórki.

% \bigskip

% W ostatnich latach sieci tego rodzaju znajdują szerokie zastosowanie w takich dziedzinach jak rozpoznawanie mowy, tłumaczenia czy też opisywanie obrazów. Sieci LSTM mogą również być użyteczne w pracy z szeregami czasowymi, gdzie możliwe są zależności danych w czasie, tak jak na przykład na 
% giełdzie. 

%\subsection{Metody zespołowe}

%Metody zespołowe (ang. ensemble methods) polegają na tworzeniu wielu klasyfikatorów o małej złożoności, które w odosobnieniu nie dają zadowalających wyników (często są niewiele lepsze od klasyfikatora losowego), a następnie łączenie ich w komitety. Wyniki komitetów mogą być interpretowane na wiele sposobów np. poprzez głosowanie gdzie każdy członek komitetu oddaje swój głos na konkretny wynik klasyfikacji. Okazuje się że w praktyce stosowanie tej metody często daje bardzo konkurencyjne wyniki w stosunku do stosowania pojedynczych złożonych modeli klasyfikacyjnych bądź regresyjnych.

\subsection{Random forest \cite{randforest}}

Las losowy (ang. \textit{random forest}) jest modelem opartym o drzewa decyzyjne służącym do klasyfikacji lub regresji. Drzewa decyzyjne są graficzną metodą wspomagania procesu decyzyjnego. W przypadku zagadnień uczenia maszynowego drzewa decyzyje najprościej zobrazować na przykładzie problemu klasyfikacji binarnej. Na rysnku \ref{wiki_dec_tree} przedstawione jest drzewo decyzyjne dla problemu predykcji losu pasażerów statku Titanic. Drzewo to oparte jest o trzy cechy: płeć, wiek oraz liczbę rodzeństwa oraz współmałżonków (\textit{sibsp}). 

\begin{figure}[H]
\centering \includegraphics[scale=0.6]{img/decision_tree.png}
\caption{Drzewo decyzyjne dla problemu klasyfikacji losu pasażerów statku Titanic \cite{wikidecisiontree}}
\label{wiki_dec_tree}
\end{figure}

Dla złożonych zagadnień predykcji takich jak przewidywanie trendu giełdy, drzewa decyzyjne okazują się zbyt prostym modelem. Las losowy jest rozwinięciem koncepcji drzew decyzyjnych w zakresie metod zespołowych. Głównym założeniem jest stworzenie wielu drzew decyzyjnych i opieranie końcowego wyniku na podstawie poszczególnych wyników każdego z drzew. W celu wprowadzenia różnorodności podczas konstrukcji węzłów drzew, losowane są cechy spośród których będą dobrane cechy decyzyjne w danym węźle. Metoda ta zazwyczaj daje dużo lepsze efekty niż pojedyncze drzewa decyzyjne, oraz często pomaga w ograniczaniu zjawiska przeuczania (ang. overfitting).  

\subsection{Light GBM \cite{lgbm}}

\textit{Light GBM} jest algorytmem z rodziny \textit{gradient boosting decision trees}. Algorytmy te oparte są o zespół drzew decyzyjnych. W przeciwieństwie do metody \textit{lasu losowego} konstrukcja kolejnych drzew jest wykonywana w sposób sekwencyjny, oraz zależny od wyników poprzednich drzew. Dzięki takiemu zabiegowi, zespół drzew dąży do ulepszenia swoich wyników jako całości. Algorytm \textit{light GBM} przewyższa inne algorytmy ze swojej klasy takie jak \textit{XGBoost} dzięki innemu podejściu do tworzenia drzew. Podczas gdy większość algorytmów powiększa drzewa decyzyjne wgłąb (\textit{level-wise}  rysunek \ref{level-wise}), \textit{light GBM} powiększa drzewa decyzyjne ze względu na liście (\textit{leaf-wise} rysunek \ref{leaf-wise}). Ten zabieg wraz z innymi optymalizacjami sprawia, że algorytm ten osiąga porównywalne wyniki do innych algorytmów ze swojej klasy, przy dużym skrócenia czasu uczenia się. 


\begin{figure}[H]%
\centering
\subfigure[Konstrukcja drzewa algorytmu \textit{light GBM}]{%
\label{level-wise}
\includegraphics[scale=0.46]{img/lgbm-level-wise.png}}%
\qquad
\subfigure[Konstrukcja drzewa algorytmu \textit{light GBM}]{%
\label{leaf-wise}
\includegraphics[scale=0.46]{img/lgbm-leaf-wise.png}}%
\caption{Porównanie konstrukcji drzew algorytmów z rodziny \textit{gradient boosting decision trees}}
\label{level-leaf-wise}
\end{figure}






%TODO \subsection{Wykorzystanie wykrywania sentymentu do poprawienia predykcji}

\subsection{Wnioski i uwagi}

Predykcja kursu cen na giełdzie jest zagadnieniem zaawansowanym pod względem trudności i złożoności danych. Z tego powodu w tej pracy zastosowane zostały różnorodne modele klasyfikacyjne zgodne z najnowszymi trendami w dziedzinie uczenia maszynowego. Użycie zarówno tradycyjnych modeli sieci neuronowych jak i nowoczesnych technik takich jak algorytm \textit{Light GBM} pozwoliło na obszerne badanie w zakresie poszukiwania najlepszego klasyfikatora.

\newpage

\section{Eksperymenty numeryczne}

W poniższym rozdziale zostały opisane przeprowadzone eksperymenty numeryczne z wykorzystaniem różnych modeli predykcyjnych. Głównym celem tego rozdziału jest taki dobór modelu wraz z jego hiperparametrami, aby zmaksymalizować wybrane miary jakości. Podstawowym założeniem jest nauczanie modelu dla każdej ze spółek osobno, gdyż mogą one prezentować różną dynamikę i charakterystykę danych. Testy i optymalizacje były wykonyawne dla pojedynczej spółki ze względu na ograniczenia mocy obliczeniowej i czasu. Końcowe porównywanie jakości różnych modeli zostało wykonane na podstawie wyników 10 spośród największych spółek z giełdy \textit{NASDAQ}. Wybrane spółki oraz ich kapitalizacją rynkową zostały przedstawione w tabeli \ref{tab:biggest_companies}.


\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|}
    \hline
        \textbf{Spółka} & \textbf{Kapitalizacja (mld USD)} \\ \hline
        MSFT & 1014.94 \\ \hline 
        AMZN & 920.5 \\ \hline 
        AAPL & 886.81 \\ \hline 
        GOOGL & 754.16 \\ \hline 
        FB & 517.6 \\ \hline 
        CSCO & 234.37 \\ \hline 
        PEP & 186.06 \\ \hline 
        INTC & 206.79 \\ \hline 
        AMGN & 107.4 \\ \hline 
        QCOM & 83.54 \\ \hline 
    \end{tabular}
    \caption{Spółki wykorzystane do oceny jakości nauczonych modeli}
    \label{tab:biggest_companies}
\end{table}

Wszystkie eksperymenty dla każdego zestawu parametrów zostały przeprowadzone 3 razy, a wartości dokładności i AUC zostały uśrednione. Czas uczenia jest czasem wykonania 3 iteracji testu dla danego zestawu parametrów.

\subsection{SVM}

Analiza maszyn wektorów nośnych należy zacząć od wyboru odpowiedniej funkcji jądra. Początkowo wykorzystane zostały domyślne parametry SVM z biblioteki \textit{sklearn} \cite{bib:sklearnsvm}. Tabele \ref{tab:svm_kernel_binary} oraz \ref{tab:svm_kernel_discrete} przedstawiają wyniki klasyfikacji w zależności od wybranej funkcji jądra. W obu przypadkach najlepsza okazała się funkcja liniowa osiągając 84\% dokładności dla klasyfikacji binarnej oraz 67\% dokładności w klasyfikacji na 3 klasy.
 Jak widać w obu przypadakch najgorsze wyniki osiąga funkcja wielomianowa (\textit{poly}). 
W dalszych eksperymentach wykorzystywana była funkcja liniowa.
\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        \textbf{Kernel} & \textbf{Dokładność} & \textbf{AUC} & \textbf{Czas (s)} \\ \hline
linear  &  \textbf{0.848980} &  \textbf{0.849554} &    2.351031 \\ \hline
poly    &  0.530612 &  0.634002 &    2.357999 \\ \hline
rbf     &  0.805442 &  0.808863 &    \textbf{2.145996} \\ \hline
sigmoid &  0.789116 &  0.792252 &    2.246001 \\ \hline
    \end{tabular}
    \caption{SVM: wyniki klasyfikacji binarnej w zależności od wykorzystanej funkcji jądra}
    \label{tab:svm_kernel_binary}
\end{table}

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        \textbf{Kernel} & \textbf{Dokładność} & \textbf{AUC} & \textbf{Czas (s)} \\ \hline
linear  &  \textbf{0.673469} &  \textbf{0.848302} &    2.806034 \\ \hline
poly    &  0.378231 &  0.594664 &    \textbf{2.571024} \\ \hline
rbf     &  0.609524 &  0.838035 &    2.763033 \\ \hline
sigmoid &  0.589116 &  0.811750 &    2.918002 \\ \hline
    \end{tabular}
    \caption{SVM: wyniki klasyfikacji na 3 klasy w zależności od wykorzystanej funkcji jądra}
    \label{tab:svm_kernel_discrete}
\end{table}

Następnym optymalizowanym parametrem był parametr kary \textit{C}. Domyślną wartością \textit{C} jest 1. Niestety manipulacja tym parametrem pozwoliła jedynie na poprawę dokładności rzędu $0.03$ dla obu przypadków klasyfikacji (tabela \ref{tab:svm_c_binary} oraz \ref{tab:svm_c_discrete}. Najlepszą wartością \textit{C} okazało się 10. 


\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        \textbf{C} & \textbf{Dokładność} & \textbf{AUC} & \textbf{Czas (s)} \\ \hline
0.005 &  0.813605 &  0.811315 &    1.528037 \\ \hline
0.01  &  0.827211 &  0.820457 &    1.358999 \\ \hline
0.1   &  0.846259 &  0.843590 &    \textbf{1.202999} \\ \hline
0.5   &  0.848980 &  0.847938 &    1.599977 \\ \hline
1.0   &  0.848980 &  0.849554 &    2.088028 \\ \hline
5.0   &  0.850340 &  \textbf{0.851338} &    5.381001 \\ \hline
10.0  &  \textbf{0.851701} &  0.848439 &    9.490025 \\ \hline
25.0  &  0.848980 &  0.846488 &   18.815997 \\ \hline
    \end{tabular}
    \caption{SVM: wyniki klasyfikacji binarnej w zależności wykorzystanego parametru C}
    \label{tab:svm_c_binary}
\end{table}


\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        \textbf{C} & \textbf{Dokładność} & \textbf{AUC} & \textbf{Czas (s)} \\ \hline
0.005 &  0.600000 &  0.833851 &    1.851034 \\ \hline
0.01  &  0.638095 &  0.848663 &    1.773027 \\ \hline
0.1   &  0.670748 &  0.857033 &    \textbf{1.660041} \\ \hline
0.5   &  0.672109 &  0.849077 &    2.105039 \\ \hline
1.0   &  0.673469 &  0.848400 &    2.824997 \\ \hline
5.0   &  0.674830 &  0.846707 &    7.747027 \\ \hline
10.0  &  \textbf{0.676190} &  0.847141 &   13.023001 \\ \hline
25.0  &  0.673469 &  \textbf{0.847253} &   30.673997 \\ \hline
    \end{tabular}
    \caption{SVM: wyniki klasyfikacji na 3 klasy w zależności wykorzystanego parametru C}
    \label{tab:svm_c_discrete}
\end{table}


Na koniec wykonane zostały testy dokładności w zależności od rozmiaru zbioru testowego w kontekście uczenia SVM metodą kroczącą. Z wyników w tabelach \ref{tab:svm_walk_forward_binary} oraz \ref{tab:svm_walk_forward_discrete} można zauważyć iż ta optymalizacja nie polepszyła znacznie wyników tak jak miało to miejsce w przypadku sieci neuronowych. Poprawa wyniosła 1\% dla klasyfikacji binarnej oraz 2\% dla klasyfikacji na 3 klasy. Optymalny rozmiar zbioru testowego wyniósł 360 próbek.


\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        \textbf{Rozmiar zbioru testowego} & \textbf{Dokładność} & \textbf{AUC} & \textbf{Czas (s)} \\ \hline
max                        &  0.851701 &  0.848439 &   \textbf{9.490025} \\ \hline
360                        &  \textbf{0.865079} &  0.834325 &   33.307443 \\ \hline
180                      &  0.860159 &  0.841421 &   62.537217 \\ \hline
90                         &  0.852557 &  \textbf{0.843217} &  103.744769 \\ \hline
45                       &  0.844164 &  0.843217 &  250.237508 \\ \hline
22                       &  0.841243 &  0.841935 &  529.248996 \\ \hline
    \end{tabular}
    \caption{SVM: wyniki klasyfikacji binarnej w zależności od rozmiaru zbioru testowego}
    \label{tab:svm_walk_forward_binary}
\end{table}


\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        \textbf{Rozmiar zbioru testowego} & \textbf{Dokładność} & \textbf{AUC} & \textbf{Czas (s)} \\ \hline
max                        &  0.676190 &  0.847141 &   \textbf{13.023001} \\ \hline
360                        &  \textbf{0.697354} &  0.855685 &   68.528990 \\ \hline
180                        &  0.686190 &  0.861628 &  107.270033 \\ \hline
90                         &  0.691711 &  \textbf{0.865852} &  193.407998 \\ \hline
45                         &  0.687768 &  0.865695 &  364.011001 \\ \hline
22                          &  0.691176 &  0.867509 &  724.383028 \\ \hline
    \end{tabular}
    \caption{SVM: wyniki klasyfikacji na 3 klasy w zależności od rozmiaru zbioru testowego}
    \label{tab:svm_walk_forward_discrete}
\end{table}
    
    

\subsection{Sieci neuronowe}

Sieci neuronowe posiadają wiele parametrów, których zmiana może poprawić lub pogorszyć jakość klasyfikacji. Ze względu na liczność hiperparametrów, testy i optymalizacje zostały wykonane w sposób sekwencyjny. Najciekawsze wyniki zostały przedstawione poniżej.

\bigskip

Pierwszym analizowanym parametrem, jest parametr wariancji przy redukcji rozmiaru problemu metodą PCA. Kolejne progi (wraz z liczbą zmiennych po transformacji), dla których zostały przeprowadzone testy zostały przedstawione w tabeli \ref{tab:pca_component_number}. Jak widać zmniejszenie wariancji o jedną tysięczną pozwala na ograniczenie rozmiaru wejściowych problemów o $\frac{1}{4}$, a zmniejszenie o jedną setną redukuje rozmiar aż o połowę. Nie można jednak z góry, bez testów, przesądzić jak ograniczanie rozmiaru zadania wpłynie na końcowe wyniki. 

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|}
    \hline
        \textbf{PCA (wariancja)} & \textbf{Liczba zmiennych} \\ \hline
        0.8000 & 4 \\ \hline 
        0.9000 & 8 \\ \hline 
        0.9500 & 12 \\ \hline 
        0.9700 & 16 \\ \hline 
        0.9800 & 18 \\ \hline 
        0.9900 & 23 \\ \hline
        0.9990 & 31 \\ \hline 
        0.9999 & 34 \\ \hline 
        Brak & 41 \\ \hline 
    \end{tabular}
    \caption{Wybrana wartość wariancji, a liczba zmiennych po wykonaniu PCA}
    \label{tab:pca_component_number}
\end{table}

Wyniki testów klasyfikacji binarnej dla różnych progów wariancji, zostały przedstawione w tabeli \ref{tab:nn_pca_binary}. Pomimo znikomej różnicy w wariancji danych ograniczanie rozmiaru wektora wejściowego nie okazało się korzystne pod względem uzyskanych wyników. Najlepszy wynik $\sim
85\%$ został uzyskany przy braku przetworzenia danych metodą PCA, jednak  wykorzystując PCA z wariancją 0.9999 lub 0.999 uzyskany został bardzo podobny wynik.

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        \textbf{PCA} & \textbf{Dokładność} &  \textbf{AUC} &  \textbf{Czas (s)} \\ \hline
0.9700               &  0.702948 &  0.748728 &   15.459319 \\ \hline
0.9800               &  0.745125 &  0.821377 &   \textbf{12.693174} \\ \hline
0.9900               &  0.795918 &  0.877171 &   15.743771 \\ \hline
0.9990           &  0.854875 &  \textbf{0.919237} &   14.903868 \\ \hline
0.9999             &  0.852608 &  0.918613 &   13.461666 \\ \hline
Brak                &  \textbf{0.854875} &  0.918459 &   21.490562 \\ \hline

    \end{tabular}
    \caption{MLP: wyniki klasyfikacji binarnej w zależności od wybranej wartości wariancji}
    \label{tab:nn_pca_binary}
\end{table}

Na wykresach \ref{img:nn_pca_binary_vs_accuracy} została przedstawiona dokładność w zależności od czasu uczenia sieci neuronowych (wyrażona w epokach). Można zauważyć iż używając PCA model jest w stanie dużo szybciej osiągnąć wartości dokładności bliskie jego maksimum. Co za tym idzie używając metody PCA sieć neuronowa dużo szybciej zbiega do minimum funcji celu. Sieć bez użycia PCA osiąga minimum funkcji celu w czasie 40 epok, zaś używająć PCA z wariancją 0.999 satysfakcjonujący wynik jest osiągany już po 5 epokach. Wynika to zapewne z ograniczenia rozmiaru danych wejściowych oraz z przekształcenia układu współrzędnych maksymalizującego wariancję. Wraz ze zmniejszaniem liczby danych wejściowych widać stopniowe pogarszanie wyników oraz wzrost różnicy pomiędzy wynikami zbioru treningowego, a zbioru testowego co jest sygnałem, że dochodzi do przeuczenia.


\begin{figure}[H]%
\centering
\subfigure[Brak PCA]{%
\includegraphics[scale=0.4685]{img/results/nn/nn_pca_none_binary_acc_googl.pdf}}%
\qquad
\subfigure[PCA wariancja 0.999]{%
\includegraphics[scale=0.4685]{img/results/nn/nn_pca_0999_binary_acc_googl.pdf}}%
\qquad
\subfigure[PCA wariancja 0.99]{%
\includegraphics[scale=0.4685]{img/results/nn/nn_pca_099_binary_acc_googl.pdf}}%
\qquad
\subfigure[PCA wariancja 0.97]{%
\includegraphics[scale=0.4685]{img/results/nn/nn_pca_097_binary_acc_googl.pdf}}%

\caption{Wykresy zależności dokładności od redukcji danych metodą PCA dla klasyfikacji binarnej (opracowanie własne)}
\label{img:nn_pca_binary_vs_accuracy}
\end{figure}

Takie same testy zostały przeprowadzone dla klasyfikacji na 3 klasy. Wyniki zostały zaprezentowane w tabeli \ref{tab:nn_pca_discrete}. Tutaj najlepszy wynik dokładności $\sim{78\%}$ został uzyskany przy użyciu PCA z największą wybraną wariancją. Wyniki są analogiczne do wyników klasyfikacji binarnej, 

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        \textbf{PCA} & \textbf{Dokładność} &  \textbf{AUC} &  \textbf{Czas (s)} \\ \hline
0.9700               &  0.716402 &  0.719409 &   32.111927 \\ \hline
0.9800               &  0.745578 &  0.774588 &   29.711963 \\ \hline
0.9900               &  0.762661 &  0.809976 &   26.185506 \\ \hline
0.9990              &  0.777778 &  0.847995 &   \textbf{21.621159} \\ \hline
0.9999             &  \textbf{0.782766} &  \textbf{0.850174} &   26.393088 \\ \hline
Brak                &  0.779138 &  0.848541 &   29.234138 \\ \hline
    \end{tabular}
    \caption{MLP: wyniki klasyfikacji na 3 klasy w zależności od wybranej wartości wariancji}
    \label{tab:nn_pca_discrete}
\end{table}

Najlepsze wyniki zostały uzyskane wówczas gdy dane zostały przetworzone metodą PCA z parametrem wariancji $0.9999$. Dodatkowym atutem takiej konfiguracji jest przyspieszenie czasu nauki modelu oraz poprawa stabilności wyników.  Przy następnych testach dla obu rodzajów klasyfikacji dane były redukowane metodą PCA z parametrem wariancji $0.9999$.

\bigskip

Następnym parametrem zbadanym podczas uczenia sieci jest liczba warstw ukrytych wraz z liczbą neuronów w każdej z warstw. Dla uproszczenia eksperymentów liczba warstw ukrytych w sieci neuronowej została ograniczona do wartości \{0, 1, 2\}, zaś liczba neuronów w każdej z warstw była taka sama. Wyniki mierzone miarą AUC dla klasyfikacji binarnej zostały przedstawione w tabeli \ref{tab:nn_layers_binary}. Dla tego rodzaju klasyfikacji najlepszym modelem okazał się model sieci neuronowej złożony jedynie z warstwy wejściowej oraz warstwy wyjściowej. Uzyskał on wynik \textbf{0.919} AUC i 85\% dokładności. Model bez warstwy ukrytej w przypadku klasyfikacji binarnej okazuje się najlepszy najprawdopodobniej ze względu na pojedynczy neuron w warstwie wyjściowej. Taka uproszczona architektura pozwala na znalezienie odpowiednich zależności w danych bez dodawania warstw ukrytych. Wyniki wydają się być odwrotnie proporcjonalne do liczby użytych neuronów, lecz nie odbiegają znacznie od najlepszego wyniku.

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|}
        \hline
         & &  \multicolumn{10}{c|}{Liczba neuronów w każdej warstwie}  \\ \hline
        \multirow{4}{*}{Warstwy} & & 0 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10  \\ \cline{2 - 12}
			& 0 & \textbf{0.919} & - & - & - & - & - & - & - & - & - \\ \cline{2 - 12} 
			& 1 & - &  0.919 &  0.918 &  0.916 &  0.907 &  0.917 &  0.915 &  0.915 &  0.915  & 0.917 \\ \cline{2 - 12} 
			& 2 & - & 0.909 &    0.910 &   0.908 &   0.911 &   0.917 &   0.908 &   0.905 &   0.914 & 0.915 \\ \cline{2 - 12} \hline

    \end{tabular}
    \caption{MLP: wartości miary AUC dla różnych konfiguracji warstw ukrytych i liczby neuronów dla klasyfikacji binarnej (wyniki zaokrąglone)}
    \label{tab:nn_layers_binary}
\end{table}

Analogicznie do klasyfikacji binarnej został przeprowadzony test dla klasyfikacji na 3 klasy, wyniki przedstawiono w tabeli \ref{tab:nn_layers_discrete}. Najlepszy wynik \textbf{0.858} AUC (68\% dokładności) został osiągnięty przy użyciu jednej warstwy ukrytej o 10 neuronach. W odróżnieniu do klasyfikacji binarnej, warstwa wyjściowa posiada 3 neurony, a co za tym idzie potrzeba bardziej skomplikowanej architektury sieci do uzyskania optymalnego wyniku. Zauważyć można również iż wykorzystanie wielu warstw ukrytych o małej liczbie neuronów znacznie pogarsza wynik co jest spowodowane zbyt małą liczbą połączeń między kolejnymi warstwami by zachować zależności między danymi.

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|}
        \hline
         & &  \multicolumn{10}{c|}{Liczba neuronów w każdej warstwie}  \\ \hline
        \multirow{4}{*}{Warstwy} & & 0 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10  \\ \cline{2 - 12}
			& 0 & 0.832 & - & - & - & - & - & - & - & - & - \\ \cline{2 - 12} 
			& 1 & - &  0.817 &  0.825 &  0.845 &  0.844 &  0.856 &  0.854 &  0.857 &  0.857 & \textbf{0.858} \\ \cline{2 - 12} 
			& 2 & - & 0.808 &   0.819 &   0.847 &   0.846 &   0.843 &   0.849 &   0.854 &   0.856 &   0.851  \\ \cline{2 - 12} \hline

    \end{tabular}
    \caption{MLP: wartości miary AUC dla różnych konfiguracji warstw ukrytych i liczby neuronów dla klasyfikacji na 3 klasy (wyniki zaokrąglone)}
    \label{tab:nn_layers_discrete}
\end{table}

W kolejnych testach do klasyfikacji binarnej nie zostały użyte warstwy ukrytne, zaś do klasyfikacji na 3 klasy była wykorzystywana jedna warstwa ukryta z 10 neuronami.

\bigskip

Na wykresie \ref{img:nn_layers_discrete} przedstawione zostały krzywe ROC dla 3 klas, wraz z ich mikro-średnią, dla sieci neuronowej o jednej warstwie ukrytej z 10 neuronami. Analizując wykres łatwo zauważyć, iż model ma największą trudność z przewidywaniem klasy utrzymania ceny. Taka rozbieżność może być problematyczna na etapie używania nauczonego modelu do predykcji. Im większa rozbieżność między AUC poszczególnych klas tym gorzej. Może się bowiem okazać iż dwa modele o porównywalnej mierze AUC będą uzyskiwały rozbieżne wyniki w grze na giełdzie. Mogłoby to wynikać z faktu iż model w ogóle nie zwraca w swoich przewidywaniach jednej z klas, zaś pozostałe estymuje bardzo dobrze. Na przykład model mógłby nigdy nie dawać sygnału do sprzedaży, a to całkowicie wyklucza jego praktyczne użycie. 


\begin{figure}[H]
\centering \includegraphics[scale=0.8]{img/results/nn/nn_layers_10_discrete_roc-googl.pdf}
\caption{Wykres ROC sieci neuronowej o jednej warstwie neuronowej z 10 neuronami dla klasyfikacji na 3 klasy (opracowanie własne)}
\label{img:nn_layers_discrete}
\end{figure}

\bigskip

Kolejnym analizowanym parametrem był rozmiar zbioru testowego wykorzystywanego w każdej iteracji uczenia modelu metodą kroczącą. Domyślnie model był uczony w jednej iteracji metody kroczącej z wielkością zbioru testowego równej $0.2$ całego zbioru danych. Dzieląc zbiór testowy na mniejsze części, w każdej iteracji włączając już przetestowane próbki danych do zbioru treningowego, potencjalnie powiększany jest zbiór informacji przekazywanych modelom w trakcie uczenia. Tabela \ref{tab:nn_walk_forward_test_binary} przedstawia wyniki dla różnych rozmiarów zbioru testowego. Najlepszy wynik dla klasyfikacji binarnej został osiągnięty przy 360 próbkach w zbiorze testowym. Dzięki tak prostemu zabiegowi dokładność modelu ulepszyła się aż o 3\%. Niestety wraz ze zmniejszaniem zbioru testowego drastycznie zwiększa się czas uczenia. 

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        \textbf{Rozmiar zbioru testowego} & \textbf{Dokładność} &  \textbf{AUC} &  \textbf{Czas (s)} \\ \hline 
max                           &  0.855781 &  \textbf{0.919433} &   \textbf{17} \\  \hline
360                         &  \textbf{0.888757} &  0.918279 &   64 \\  \hline
180                         &  0.878307 &  0.917263 &  148 \\  \hline
90                          &  0.876426 &  0.915586 &  297 \\ \hline
45                          &  0.877280 &  0.910868 &   405 \\ \hline
22                          &  0.880905 &  0.904669 &  1163 \\ \hline
    \end{tabular}
    \caption{MLP: wyniki klasyfikacji binarnej w zależności od rozmiaru zbioru testowego}
    \label{tab:nn_walk_forward_test_binary}
\end{table}

W tabeli \ref{tab:nn_walk_forward_test_discrete} przestawione zostały analogiczne wyniki dla klasyfikacji na 3 klasy. Jak widać dla bardziej złożonego zagadnienia klasyfikacji zmniejszanie zbioru testowego jest bardzo korzystne. Wynik dokładności wzrósł aż o 10\% dla zbioru testowego o 22 próbkach. Dalsze zmniejszanie zbioru jest jednak problematyczne ze względu na rosnącą długość obliczeń.

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        \textbf{Rozmiar zbioru testowego} & \textbf{Dokładność} &  \textbf{AUC} &  \textbf{Czas (s)} \\ \hline
max    &  0.682993 &  0.857121 &  \textbf{38} \\ \hline
360     &  0.731041 &  0.866818 &  54 \\ \hline
180   &  0.730847 &  0.867762 &  127 \\ \hline
90   &  0.740388 &  0.869632 &  316 \\ \hline
45     &  0.760286 &  0.873949 &  1146 \\ \hline
22  &  \textbf{0.787767} &  \textbf{0.882507} &  3229 \\ \hline
    \end{tabular}
    \caption{MLP: wyniki klasyfikacji na 3 klasy w zależności od rozmiaru zbioru testowego}
    \label{tab:nn_walk_forward_test_discrete}
\end{table}

Ostatecznie dla klasyfikacji binarnej zostały użyte zbiory testowe z 360 próbkami, zaś dla klasyfikacji trójklasowej zbiory z 22 próbkami.



\subsection{Random forest}

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        \textbf{PCA} & \textbf{Dokładność} & \textbf{AUC} & \textbf{Czas (s)} \\ \hline
0.95               &  0.650340 &  0.652564 &    \textbf{1.084675} \\ \hline
0.98               &  0.735147 &  0.734262 &    1.515345 \\ \hline
0.99               &  0.752834 &  0.753326 &    1.626672 \\ \hline
0.999 &  0.772789 &  0.772018 &    1.704345 \\ \hline
0.9999             &  \textbf{0.777778} &  \textbf{0.777053} &    1.710322 \\ \hline
Brak                &  0.753741 &  0.754849 &    2.229286 \\ \hline
    \end{tabular}
    \caption{Random forest: wyniki klasyfikacji binarnej w zależności od wybranej wartości wariancji}
    \label{tab:rf_pca_binary}
\end{table}
\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        \textbf{PCA} & \textbf{Dokładność} & \textbf{AUC} & \textbf{Czas (s)} \\ \hline
0.95               &  0.487075 &  0.677503 &    \textbf{1.226344} \\ \hline
0.98               &  0.547846 &  0.742437 &    1.437373 \\ \hline
0.99               &  0.568254 &  0.758338 &    1.406685 \\ \hline
0.999 &  0.570068 &  0.765132 &    1.711658 \\ \hline
0.9999             &  \textbf{0.576417} &  \textbf{0.767606} &    1.747348 \\ \hline
Brak                &  0.567347 &  0.768452 &    2.043028 \\ \hline
    \end{tabular}
    \caption{Random forest: wyniki klasyfikacji na 3 klasy w zależności od wybranej wartości wariancji}
    \label{tab:rf_pca_discrete}
\end{table}


\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        \textbf{Liczba drzew} & \textbf{Dokładność} & \textbf{AUC} & \textbf{Czas (s)} \\ \hline
100        &  0.779138 &  0.778948 &    \textbf{1.254666} \\ \hline
200        &  0.781859 &  0.781289 &    2.391548 \\ \hline
300        &  0.786395 &  0.785786 &    3.506159 \\ \hline
500       &  0.779138 &  0.778837 &    5.656016 \\ \hline
1000       &  0.782313 &  0.781438 &   10.835435 \\ \hline
1500      &  \textbf{0.787755} &  \textbf{0.787179} &   16.527833 \\ \hline
2000       &  0.782766 &  0.782144 &   21.734268 \\ \hline
    \end{tabular}
    \caption{Random forest: wyniki klasyfikacji binarnej w zależności od liczby utworzonych drzew}
    \label{tab:rf_estimators_binary}
\end{table}
\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        \textbf{Liczba drzew} & \textbf{Dokładność} & \textbf{AUC} & \textbf{Czas (s)} \\ \hline
100        &  0.574150 &  0.763649 &    \textbf{1.228010} \\ \hline
200        &  0.574150 &  0.767209 &    2.428561 \\ \hline
300        &  0.574150 &  0.768572 &    3.478281 \\ \hline
500        &  0.585395 &  0.774938 &    5.866535 \\ \hline
1000       &  0.584127 &  0.775766 &   11.639547 \\ \hline
1500       &  \textbf{0.585988} &  \textbf{0.778329} &   15.834652 \\ \hline
2000      &  0.585441 &  0.776137 &   20.285341 \\ \hline
    \end{tabular}
    \caption{Random forest: wyniki klasyfikacji na 3 klasy w zależności od liczby utworzonych drzew}
    \label{tab:rf_estimators_discrete}
\end{table}


\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        \textbf{Rozmiar zbioru testowego} & \textbf{Dokładność} & \textbf{AUC} & \textbf{Czas (s)} \\ \hline
max                         &  \textbf{0.787755} &  \textbf{0.787179} &  \textbf{16.527833} \\ \hline
360                         &  0.753131 &  0.759844 &   65.553659 \\ \hline        
180                         &  0.749894 &  0.756907 &  105.710007 \\ \hline
90                          &  0.755908 &  0.758301 &  180.461685 \\ \hline
45                          &  0.753906 &  0.754997 &  336.741707 \\ \hline
22                          &  0.751783 &  0.755511 &  716.216814 \\ \hline
    \end{tabular}
    \caption{Random forest: wyniki klasyfikacji binarnej w zależności od rozmiaru zbioru testowego}
    \label{tab:rf_walk_forward_binary}
\end{table}

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        \textbf{Rozmiar zbioru testowego} & \textbf{Dokładność} & \textbf{AUC} & \textbf{Czas (s)} \\ \hline
max                         &  \textbf{0.585988} &  0.778329 &  \textbf{15.834652} \\ \hline
360                         &  0.556173 &  0.779862 &   67.133358 \\ \hline
180                         &  0.570370 &  0.786893 &  121.863561 \\ \hline
90                         &  0.569959 &  \textbf{0.788930} &  223.579185 \\ \hline
45                          &  0.574946 &  0.787879 &  443.906251 \\ \hline
22                          &  0.573864 &  0.787886 &  834.891297 \\ \hline
    \end{tabular}
    \caption{Random forest: wyniki klasyfikacji na 3 klasy w zależności od rozmiaru zbioru testowego}
    \label{tab:rf_walk_forward_discrete}
\end{table}

\subsection{Light GBM}

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        \textbf{PCA} & \textbf{Dokładność} & \textbf{AUC} & \textbf{Czas (s)} \\ \hline
0.9                &  0.617687 &  0.658673 &    \textbf{0.112996} \\ \hline
0.99               &  0.760544 &  0.845203 &    0.355000 \\ \hline
0.999    &  0.791837 &  0.877228 &    0.765001 \\ \hline
0.9999             &  0.802721 &  0.879168 &    0.903005 \\ \hline
Brak                &  \textbf{0.824490} &  \textbf{0.910806} &    0.632995 \\ \hline
    \end{tabular}
    \caption{Light GBM: wyniki klasyfikacji binarnej w zależności od wybranej wartości wariancji}
    \label{tab:lgbm_pca_binary}
\end{table}

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        \textbf{PCA} & \textbf{Dokładność} & \textbf{AUC} & \textbf{Czas (s)} \\ \hline
0.9                &  0.438095 &  0.587427 &    \textbf{0.247017} \\  \hline
0.99               &  0.570068 &  0.757724 &    0.899004 \\ \hline
0.999 &  0.579592 &  0.765829 &    1.133001 \\ \hline
0.9999             &  0.571429 &  0.765824 &    1.166996 \\ \hline
Brak                &  \textbf{0.646259} &  \textbf{0.820201} &    1.241000 \\ \hline
    \end{tabular}
    \caption{Light GBM: wyniki klasyfikacji na 3 klasy w zależności od wybranej wartości wariancji}
    \label{tab:lgbm_pca_discrete}
\end{table}

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        \textbf{Procent cech} & \textbf{Dokładność} & \textbf{AUC} & \textbf{Czas (s)} \\ \hline
20              &  0.745578 &  0.832768 &    0.661063 \\ \hline
30              &  0.785034 &  0.884036 &    \textbf{0.391003} \\ \hline
40              &  0.806803 &  0.889521 &    0.710010 \\ \hline
50             &  0.809524 &  0.897808 &    1.246994 \\ \hline
60              &  0.821769 &  0.910041 &    1.367518 \\ \hline
70              &  0.813605 &  0.905641 &    5.311466 \\ \hline
80              &  0.824490 &  0.910806 &    1.581059 \\ \hline
90              &  0.813605 &  0.910754 &    2.108266 \\ \hline
100              &  \textbf{0.831293} &  \textbf{0.911758} &    1.717000 \\ \hline
    \end{tabular}
    \caption{Light GBM: wyniki klasyfikacji binarnej w zależności od procenta cech wykorzystanych do tworzenia pojedynczego drzewa}
    \label{tab:lgbm_feature_fraction_binary}
\end{table}

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        \textbf{Procent cech} & \textbf{Dokładność} & \textbf{AUC} & \textbf{Czas (s)} \\ \hline
20          &  0.541497 &  0.698834 &    \textbf{0.589999} \\ \hline
30              &  0.606803 &  0.775659 &    1.528000 \\ \hline
40              &  0.602721 &  0.780493 &    0.855000 \\ \hline
50              &  0.625850 &  0.796584 &    1.453674 \\ \hline
60              &  0.648980 &  0.821857 &    3.013062 \\ \hline
70              &  0.640816 &  0.819061 &    2.339054 \\ \hline
80              &  0.646259 &  0.820201 &    3.221801 \\ \hline
90              &  0.648980 &  0.821506 &    2.187508 \\ \hline
100              &  \textbf{0.654422} &  \textbf{0.831571} &    1.666998 \\ \hline
    \end{tabular}
    \caption{Light GBM: wyniki klasyfikacji na 3 klasy w zależności od procenta cech wykorzystanych do tworzenia pojedynczego drzewa}
    \label{tab:lgbm_feature_fraction_discrete}
\end{table}


\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        \textbf{Boosting} & \textbf{Dokładność} & \textbf{AUC} & \textbf{Czas (s)} \\ \hline
dart     &  0.817687 &  0.906808 &    2.796990 \\ \hline
gbdt     &  \textbf{0.834014} &  \textbf{0.911832} &    \textbf{1.173999} \\ \hline
gbrt     &  0.834014 &  0.911832 &    1.244001 \\ \hline
goss     &  0.797279 &  0.902891 &    0.748003 \\ \hline
    \end{tabular}
    \caption{Light GBM: wyniki klasyfikacji na 3 klasy w zależności od wybranego rodzaju boostingu}
    \label{tab:lgbm_boosting_binary}
\end{table}

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        \textbf{Boosting} & \textbf{Dokładność} & \textbf{AUC} & \textbf{Czas (s)} \\ \hline
dart     &  \textbf{0.663946} &  \textbf{0.835296} &    7.743999 \\ \hline
gbdt     &  0.654422 &  0.831571 &    1.947000 \\ \hline
gbrt     &  0.654422 &  0.831571 &    1.154999 \\ \hline
goss     &  0.646259 &  0.810499 &    \textbf{1.321007} \\ \hline
    \end{tabular}
    \caption{Light GBM: wyniki klasyfikacji na 3 klasy w zależności od wybranego rodzaju boostingu}
    \label{tab:lgbm_boosting_discrete}
\end{table}

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        \textbf{Rozmiar zbioru testowego} & \textbf{Dokładność} & \textbf{AUC} & \textbf{Czas (s)} \\ \hline
max    &  0.834014 &  0.911832 &  \textbf{1.173999} \\ \hline
360                         &  \textbf{0.867857} &  0.915407 &   1.874000 \\ \hline
180                         &  0.855714 &  \textbf{0.918232} &    5.498513 \\ \hline
90                         &  0.837743 &  0.915601 &    6.347999 \\ \hline
45                          &  0.837628 &  0.914706 &   11.757001 \\ \hline
22                          &  0.847594 &  0.921981 &   23.754002 \\ \hline
    \end{tabular}
    \caption{Light GBM: wyniki klasyfikacji binarnej w zależności od rozmiaru zbioru testowego}
    \label{tab:lgbm_walk_forward_binary}
\end{table}


\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
        \textbf{Rozmiar zbioru testowego} & \textbf{Dokładność} & \textbf{AUC} & \textbf{Czas (s)} \\ \hline
max   						 &  0.663946 &  0.835296 &  \textbf{7.743999} \\ \hline
360                         &  \textbf{0.727381} &  0.831340 &   26.352005 \\ \hline
180                         &  0.700317 &  \textbf{0.832342} &   45.234971 \\ \hline
90                          &  0.680423 &  0.833708 &   75.542997 \\ \hline
45                          &  0.681793 &  0.837955 &  137.898603 \\ \hline
22                          &  0.665441 &  0.834180 &  398.519057 \\ \hline
    \end{tabular}
    \caption{Light GBM: wyniki klasyfikacji na 3 klasy w zależności od rozmiaru zbioru testowego}
    \label{tab:lgbm_walk_forward_discrete}
\end{table}


\subsection{Podsumowanie}



 \begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|c|}
    \hline
        \textbf{Spółka} & \textbf{SVM} &  \textbf{MLP}  &  \textbf{Random forest}  &  \textbf{Light GBM} \\ \hline
AAPL   &  0.807656 & 0.823688  & 0.740741 & 0.811402\\ \hline
AMGN   &  0.799253 &  0.826799 &0.772487 &  0.819947 \\ \hline
AMZN   &  0.773109 & 0.811963 & 0.634609 & 0.820503 \\ \hline
CSCO   &  0.815126 &  0.819011 & 0.814815 &  0.811429 \\ \hline
FB     &  0.825215 & 0.836207 & 0.714422 & 0.801724 \\ \hline
GOOGL  &  0.851701 &  0.885767 & 0.787302 & 0.859524 \\ \hline
INTC   &  0.829132 & 0.837402  & 0.791783 & 0.829101 \\ \hline
MSFT   &  0.800187 &   0.826206 & 0.767818 &  0.798307\\ \hline
PEP    &  0.827586 & 0.843401  & 0.765455 & 0.830135 \\ \hline
QCOM   &  0.835668 &  0.836926 & 0.808901 & 0.815132 \\ \hline \hline
\textbf{Średnia dokładność} &  0.816463 & \textbf{0.834737} & 0.759833 & 0.81972 \\  \hline  
\textbf{Średnia ROC} &  0.816157 & \textbf{0.904259} & 0.761041 & 0.901649 \\  \hline
    \end{tabular}
    \caption{Końcowe wyniki dokładności dla klasyfikacji binarnej różnych spółek}
    \label{tab:comparison_final_binary}
\end{table}   



 \begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|c|}
    \hline
        \textbf{Spółka} & \textbf{SVM} &  \textbf{MLP}  &  \textbf{Random forest}  &  \textbf{Light GBM} \\ \hline
AAPL   &  0.671335 & 0.779353  & 0.607221 & 0.650688 \\ \hline
AMGN   &  0.676937 &  0.793533 & 0.610644 &  0.649841 \\ \hline
AMZN   &  0.625584 & 0.758636 & 0.510115  & 0.660079 \\ \hline
CSCO   &  0.661064 &  0.776217 & 0.619359 &  0.632989 \\ \hline
FB     &  0.604585 & 0.740004 & 0.543457 & 0.678161 \\ \hline
GOOGL  &  0.676190 &  0.789327 & 0.589116 & 0.729233 \\ \hline
INTC   &  0.718954 & 0.812174  & 0.641768 & 0.668836 \\ \hline
MSFT   &  0.672269 &   0.785449 & 0.604108 &  0.636958 \\ \hline
PEP    &  0.678472 & 0.807127  & 0.610127 & 0.670854 \\ \hline
QCOM   &  0.687208 &  0.777542 & 0.641457 & 0.661878 \\ \hline \hline
\textbf{Średnia dokładność} &  0.667260 & \textbf{0.781936} & 0.597737 & 0.663952 \\  \hline  
\textbf{Średnia ROC} &  0.839264 & \textbf{0.874600} & 0.783574 & 0.830858 \\  \hline
    \end{tabular}
    \caption{Końcowe wyniki dokładności dla klasyfikacji na 3 klasy różnych spółek}
    \label{tab:comparison_final_discrete}
\end{table}   

\section{Wspomaganie decyzji giełdowych}

\section{Projekt aplikacji}

\section{Podsumowanie}


\newpage

\section{Bibliografia}
\begin{thebibliography}{9}
  
 \bibitem{nyse}
Strona główna NYSE
\\\url{https://www.nyse.com}
 
 \bibitem{nasdaq}
Strona główna NASDAQ
\\\url{https://www.nasdaq.com/}

 \bibitem{jpx}
Strona główna JPX
\\\url{https://www.jpx.co.jp/english/}

\bibitem{fundamentalanalysis}
  John C. Ritchie,
  \textit{Analiza fundamentalna}.
  Wig-Press,
  1997.
  
  \bibitem{berkeshire}
Strona główna Berkeshire Hathaway
\\\url{http://www.berkshirehathaway.com/}

\bibitem{technicalanalysis}
  John J. Murphy,
  \textit{Analiza techniczna rynków finansowych}.
  Maklerska.pl,
  2017.

 \bibitem{alphavantage}
Strona główna Alpha Vantage
\\\url{https://www.alphavantage.co/}

\bibitem{randwalk}
  Burton G. Malkiel,
  \textit{Random Walk Down Wall Street: The Time-Tested Strategy for Successful Investing}.
  W. W. Norton Company,
  2007.

\bibitem{efficientmarket}
  Eugene Fama,
  \textit{"Efficient Capital Markets: A Review of Theory and Empirical Work}
  Journal of Finance. 25:2, pp. 383-417, 1970.

\bibitem{pythonmachinelearning}
  John Hearty
  \textit{Advanced Machine Learning with Python}.
  Packt Publishing,
  2016.

\bibitem{roc}
	Tom Fawcett, 
  \textit{An introduction to ROC analysis.}
  Pattern Recognition Letters 27,
  2005.

\bibitem{roccurves}
	ROC, \url{https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5} 
	Data dostępu: 15.02.2019

\bibitem{hmeasure}
	David J. Hand, 
  \textit{Measuring classifier performance: a coherent alternative to the area under the ROC curve}
  Machine Learning, 77:103–123, 2009.

\bibitem{roccritique}
	David J. Hand, 
  \textit{Evaluating diagnostic tests: the area under the ROC curve and the balance of errors.}
 Statistics in Medicine, 29:1502–1510, 2010

\bibitem{brier}
	Glenn W. Brier, 
  \textit{Verification of Forecasts Expressed in Terms of Probability}
  Monthly Weather Review, 78:1–3, 1950

\bibitem{train_test_split}
 Podział danych testowych \url{https://medium.com/@rinu.gour123/train-and-test-set-in-python-machine-learning-how-to-split-58029a0d657b}
 Data dostępu: 30.05.2019
 
 
\bibitem{train_test_split_time_series}
 Podział danych testowych metodą kroczącą \url{https://robjhyndman.com/hyndsight/tscv/}
 Data dostępu: 30.05.2019
 
\bibitem{svm}
	Bell, Jason, \textit{Machine Learning : Hands-On for Developers and Technical Professionals}  Indianapolis, IN, USA: John Wiley \& Sons, 2015. 139-160. Web.
	
\bibitem{wikisvm}
	SVM, \url{https://en.wikipedia.org/wiki/Support-vector_machine} 
	Data dostępu: 03.03.2019

\bibitem{neural-nets}
	Bell, Jason, \textit{Machine Learning : Hands-On for Developers and Technical Professionals}  Indianapolis, IN, USA: John Wiley \& Sons, 2015. 91-116. Web.


\bibitem{mlp}
	Angel Kuri-Morales, 
  \textit{Closed determination of the number of neurons in the hidden layer of a multi-layered perceptron network}
  Soft Computing, 21:597–609, 2017

\bibitem{mlpnn}
	Artificial neural network, \url{http://www.saedsayad.com/artificial_neural_network_bkp.htm} 
	Data dostępu: 04.03.2019

\bibitem{lstm}
	Fischer, and Krauss, 
  \textit{Deep Learning with Long Short-term Memory Networks for Financial Market Predictions.}
  European Journal of Operational Research 270.2 (2018): 654-69. Web.

\bibitem{lstm-scheme}
	Recurrent neural network, \url{https://en.wikipedia.org/wiki/Recurrent_neural_network} 
	Data dostępu: 04.03.2019

\bibitem{randforest}
	Breiman, L, 
  \textit{Random forests}
	MACHINE LEARNING  Volume: 45   Issue: 1   Pages: 5-32   Published: OCT 2001


\bibitem{wikidecisiontree}
	Decision tree learning, \url{https://www.wikiwand.com/en/Decision_tree_learning} 
	Data dostępu: 06.04.2019


\bibitem{lgbm}
Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang,Wei Chen, Weidong Ma, Qiwei Ye, Tie-Yan Liu
  \textit{LightGBM: A Highly Efficient Gradient Boosting Decision Tree}
	MACHINE LEARNING  Volume: 45   Issue: 1   Pages: 5-32   Published: OCT 2001

\bibitem{wikidecisiontree}
	Decision tree learning, \url{https://www.wikiwand.com/en/Decision_tree_learning} 
	Data dostępu: 06.04.2019

\bibitem{bib:sklearnsvm}
	Sklearn SVM, \url{https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC}
	Data dostępu: 23.06.2019


\end{thebibliography}

\section{Wykaz rysunków}

\section{Wykaz tabel}

\section{Charakterystyka aplikacji}

\end{document}